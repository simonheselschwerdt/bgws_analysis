{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fcb352-aecb-438c-9c68-b8bed66b5882",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CMIP6 Convert Units\n",
    "\n",
    "**Following steps are included in this script:**\n",
    "\n",
    "1. Load netCDF files\n",
    "2. Convert Units to Specified Format\n",
    "3. Save and replace netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caece056-697a-4d0f-96ae-386db8e174d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os\n",
    "from dask.delayed import delayed\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d73ace-b697-400e-9216-845af23d656d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded3dba1-df20-4bd1-bd21-7c3cb8e1517f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_log(ds, var, old_unit):\n",
    "        if 'log' in ds.attrs:\n",
    "            log_old = ds.attrs['log']\n",
    "            ds.attrs['log'] = f'Unit of {var} converted from {old_unit} to {ds[var].units}. // {log_old}'\n",
    "        else:\n",
    "            ds.attrs['log'] = f'Unit of {var} converted from {old_unit} to {ds[var].units}.'\n",
    "\n",
    "        print(f\"Unit of {var} converted from {old_unit} to {ds[var].units}.\")\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38054e77-b831-4603-a4dc-4ccc22c9ed3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_units(ds_dict, conv_units):\n",
    "    \"\"\"\n",
    "     Convert units for specified variables\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, (name, ds) in enumerate(ds_dict.items()):\n",
    "\n",
    "        for var in list(conv_units.keys()):\n",
    "\n",
    "            if var in ds.variables:\n",
    "                old_unit = ds[var].units\n",
    "                \n",
    "                if conv_units[var] == ds[var].units:\n",
    "                    print('Unit already in the requested format')\n",
    "                    \n",
    "                elif var == 'lai':\n",
    "                    # Keep existing attributes and only modify the units attribute\n",
    "                    attrs = ds[var].attrs\n",
    "                    attrs['units'] = conv_units[var]\n",
    "                    attrs['equation'] = 'leaf area / ground area'\n",
    "                    ds[var].attrs = attrs\n",
    "                    ds = create_log(ds, var, old_unit)\n",
    "\n",
    "\n",
    "                elif conv_units[var] == 'gC/m²/day':\n",
    "                    if ds[var].units == 'kg/m²/s' or 'kg m-2 s-1':\n",
    "                    \n",
    "                        # Keep existing attributes and only modify the units attribute\n",
    "                        attrs = ds[var].attrs\n",
    "                        attrs['units'] = conv_units[var]\n",
    "                        ds[var] = ds[var] * 1000 * 60 * 60 * 24 \n",
    "                        ds[var].attrs = attrs\n",
    "                        ds = create_log(ds, var, old_unit)\n",
    "                        \n",
    "                elif conv_units[var] == 'mm/day':\n",
    "                    if ds[var].units == 'kg/m²/s' or ds[var].units =='kg m-2 s-1':\n",
    "    \n",
    "                        # Keep existing attributes and only modify the units attribute\n",
    "                        attrs = ds[var].attrs\n",
    "                        attrs['units'] = conv_units[var]\n",
    "                        ds[var] = ds[var] * 60 * 60 * 24 \n",
    "                        ds[var].attrs = attrs\n",
    "                        ds = create_log(ds, var, old_unit)\n",
    "                \n",
    "                elif conv_units[var] == 'hPa':\n",
    "                    if ds[var].units == 'Pa':\n",
    "    \n",
    "                        # Keep existing attributes and only modify the units attribute\n",
    "                        attrs = ds[var].attrs\n",
    "                        attrs['units'] = conv_units[var]\n",
    "                        ds[var] = ds[var] / 100 \n",
    "                        ds[var].attrs = attrs\n",
    "                        ds = create_log(ds, var, old_unit)\n",
    "                        \n",
    "                elif conv_units[var] == 'ppm':\n",
    "                    if ds[var].units == 'kg':\n",
    "                        # Keep existing attributes and only modify the units attribute\n",
    "                        attrs = ds[var].attrs\n",
    "                        attrs['units'] = conv_units[var]\n",
    "                        attrs['long_name'] = 'CO2 concentration'\n",
    "                        # Constants\n",
    "                        molar_mass_co2 = 44.01  # Molar mass of CO2 in grams per mole (g/mol)\n",
    "                        moles_of_air = 2.13e20  # Volume of the atmosphere in moles (may vary, check CMIP6 documentation)\n",
    "                        # Convert co2mass from kg to moles\n",
    "                        ds[var] = ((ds[var] / molar_mass_co2) / moles_of_air) * 1e6\n",
    "                        ds[var].attrs = attrs\n",
    "                        ds = create_log(ds, var, old_unit)\n",
    "                            \n",
    "                elif conv_units[var] == '°C':\n",
    "                    if ds[var].units == 'K':\n",
    "                        # Keep existing attributes and only modify the units attribute\n",
    "                        attrs = ds[var].attrs\n",
    "                        attrs['units'] = conv_units[var]\n",
    "                        # Convert co2mass from kg to moles\n",
    "                        ds[var] = ds[var] - 273.15\n",
    "                        ds[var].attrs = attrs\n",
    "                        ds = create_log(ds, var, old_unit)\n",
    "                \n",
    "                elif conv_units[var] == 'mm':\n",
    "                    if ds[var].units == 'kg/m²':\n",
    "                        # Keep existing attributes and only modify the units attribute\n",
    "                        attrs = ds[var].attrs\n",
    "                        attrs['units'] = conv_units[var]\n",
    "                        # Convert co2mass from kg to moles\n",
    "                        ds[var] = ds[var] / 1e3  # This now represents mm of water\n",
    "                        ds[var].attrs = attrs\n",
    "                        ds = create_log(ds, var, old_unit)\n",
    "\n",
    "                else: \n",
    "                    raise ValueError(f\"No unit conversion for variable '{var}' specified.\")\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"No variable '{var}' in ds_dict.\")\n",
    "        \n",
    "        ds_dict[name] = ds\n",
    "                \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedf9b9d-b903-44b2-9554-d2bfa6399d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_file(save_file, folder, save_var=True):\n",
    "    \"\"\"\n",
    "    Save files as netCDF.\n",
    "\n",
    "    Args:\n",
    "        savefile (dict or dataset): Dictionary of xarray datasets or dataset.\n",
    "        folder (string): Name of folder data is saved in.\n",
    "        save_var (boolean): If True, data is saved separately for each variable. If false, one file is saved with all variables.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        nc_out: Path were data is saved in.\n",
    "    \"\"\"\n",
    "    \n",
    "    if save_var:\n",
    "        for key, ds in ds_dict.items():\n",
    "            for var in ds:\n",
    "                # Variable to keep\n",
    "                variable_to_keep = var\n",
    "                dimensions_to_keep = {'time', 'lat', 'lon'}\n",
    "                coordinates_to_keep = {'time', 'lat', 'lon'}\n",
    "\n",
    "                if any('depth' in ds[var].dims for var in ds.variables):\n",
    "                    dimensions_to_keep.add('depth')\n",
    "                    coordinates_to_keep.add('depth')\n",
    "\n",
    "                # Create a new dataset with only the desired variable\n",
    "                ds_var = ds[[variable_to_keep]]\n",
    "\n",
    "                # Keep only the desired dimensions\n",
    "                ds_var = ds_var.isel({dim: slice(None) for dim in dimensions_to_keep.intersection(ds_var.dims)})\n",
    "\n",
    "                # Set the desired coordinates\n",
    "                coords_to_set = set(ds_var.variables).intersection(coordinates_to_keep)\n",
    "                ds_var = ds_var.set_coords(list(coords_to_set))\n",
    "\n",
    "                savepath = f'../../data/CMIP6/{ds_var.experiment_id}/{folder}/{var}/'\n",
    "                filename = f'CMIP.{ds_var.source_id}.{ds_var.experiment_id}.{var}_regridded.nc'\n",
    "                nc_out = os.path.join(savepath, filename)\n",
    "                os.makedirs(savepath, exist_ok=True) \n",
    "                if os.path.exists(nc_out):\n",
    "                       # inp = input(f\"Delete old file {filename} (y/n):\")\n",
    "                       # if inp.lower() in [\"y\"]:\n",
    "                            os.remove(nc_out)\n",
    "                            print(f\"File  with path: {nc_out} removed\")\n",
    "                        #else:\n",
    "                        #    filename = \"temp_file.nc\"\n",
    "                        #    nc_out = os.path.join(savepath, filename)\n",
    "                        #    print(f\"Filename change to {filename}\")\n",
    "\n",
    "                # Save to netcdf file\n",
    "                with dask.config.set(scheduler='threads'):\n",
    "                    ds_var.to_netcdf(nc_out)\n",
    "                    print(f\"File with path: {nc_out} saved\")\n",
    "       \n",
    "    else:\n",
    "        for key in save_file.keys():\n",
    "            ds_in = save_file[key]\n",
    "            filename = f'CMIP.{ds_in.source_id}.{ds_in.experiment_id}.nc'\n",
    "            savepath = f'../../data/CMIP6/{ds_in.experiment_id}/{folder}'\n",
    "            nc_out = os.path.join(savepath, filename)\n",
    "            os.makedirs(savepath, exist_ok=True) \n",
    "            if os.path.exists(nc_out):\n",
    "                inp = input(f\"Delete old file {filename} (y/n):\")\n",
    "                if inp.lower() in [\"y\"]:\n",
    "                    os.remove(nc_out)\n",
    "                    print(f\"File  with path: {nc_out} removed\")\n",
    "                else:\n",
    "                    filename = \"temp_file.nc\"\n",
    "                    nc_out = os.path.join(savepath, filename)\n",
    "                    print(f\"Filename change to {filename}\")\n",
    "\n",
    "            # Save to netcdf file\n",
    "            with dask.config.set(scheduler='threads'):\n",
    "                ds_in.to_netcdf(nc_out)\n",
    "\n",
    "    return nc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04abf171-0393-4b06-84a7-cfde27f85b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Helper function to open the dataset ========\n",
    "def open_dataset(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1b42da-8039-4962-883d-0134fee8ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to open and merge datasets\n",
    "def open_and_merge_datasets(folder, model, experiment_id, variables):\n",
    "    filepaths = []\n",
    "    for var in variables:\n",
    "        path = f'../../data/CMIP6/{experiment_id}/{folder}/{var}'\n",
    "        fp = glob.glob(os.path.join(path, f'CMIP.{model}.{experiment_id}.{var}_regridded.nc'))\n",
    "        if fp:\n",
    "            filepaths.append(fp[0])\n",
    "        else:\n",
    "            #print(f\"No file found for variable '{var}' in model '{model}'.\")\n",
    "            print(fp)\n",
    "\n",
    "    datasets = [xr.open_dataset(fp) for fp in filepaths]\n",
    "    ds = xr.merge(datasets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a5eff-03ff-4da6-ac9c-28ec84837ca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Load netCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f681a2b5-24b1-44d5-a0f1-bebdcc46dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Define period, models and path ==============\n",
    "variables=['vpd', 'lmrso_1m', 'lmrso_2m']\n",
    "experiment_id = 'historical'\n",
    "source_id = ['CESM2-WACCM', 'NorESM2-MM', 'Ensemble mean', 'Ensemble median'] #\n",
    "#source_id = ['TaiESM1', 'BCC-CSM2-MR',  'CanESM5', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'IPSL-CM6A-LR', 'UKESM1-0-LL', 'MPI-ESM1-2-LR', 'CESM2-WACCM', 'NorESM2-MM', 'Ensemble mean', 'Ensemble median'] #\n",
    "\n",
    "folder='preprocessed'\n",
    "\n",
    "# ========= Use Dask to parallelize computations ==========\n",
    "dask.config.set(scheduler='processes')\n",
    "\n",
    "# Create dictionary using a dictionary comprehension and Dask\n",
    "ds_dict = dask.compute({model: open_and_merge_datasets(folder, model, experiment_id, variables) for model in source_id})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50ba599-a0a1-44d0-b0dc-0aa579da8abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CESM2-WACCM', 'NorESM2-MM', 'Ensemble mean', 'Ensemble median']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ========= Have a look into the dictionary =======\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(ds_dict\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m----> 3\u001b[0m ds_dict[\u001b[38;5;28mlist\u001b[39m(ds_dict\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m3\u001b[39m]][\u001b[43mvariable\u001b[49m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'variable' is not defined"
     ]
    }
   ],
   "source": [
    "# ========= Have a look into the dictionary =======\n",
    "print(list(ds_dict.keys()))\n",
    "ds_dict[list(ds_dict.keys())[3]][variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bbea2c-efd4-46ed-b195-a2e0637c2602",
   "metadata": {},
   "source": [
    "### 2. Convert units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598a9fe2-6670-4417-98bc-5416efb1f03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== Convert units ============\n",
    "\n",
    "# New unit conversion must be defined in function\n",
    "conv_units = {#'pr': 'mm/day',\n",
    "            #'evspsbl': 'mm/day',\n",
    "            #'evspsblsoi': 'mm/day', \n",
    "            #'evspsblveg': 'mm/day', \n",
    "            #'mrro': 'mm/day', \n",
    "            #'mrros': 'mm/day',\n",
    "            #'gpp': 'gC/m²/day', \n",
    "            #'npp': 'gC/m²/day',\n",
    "            #'tran': 'mm/day'\n",
    "            #'lai': ''\n",
    "            'vpd': 'hPa',\n",
    "            #'tas': '°C'\n",
    "            'lmrso_1m': 'mm',\n",
    "            'lmrso_2m': 'mm'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7eebc39-d258-4425-a1aa-9053d0924c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit of vpd converted from Pa to hPa.\n",
      "Unit already in the requested format\n",
      "Unit of lmrso_2m converted from kg/m² to mm.\n",
      "Unit of vpd converted from Pa to hPa.\n",
      "Unit already in the requested format\n",
      "Unit of lmrso_2m converted from kg/m² to mm.\n",
      "Unit of vpd converted from Pa to hPa.\n",
      "Unit of lmrso_1m converted from kg/m² to mm.\n",
      "Unit of lmrso_2m converted from kg/m² to mm.\n",
      "Unit of vpd converted from Pa to hPa.\n",
      "Unit of lmrso_1m converted from kg/m² to mm.\n",
      "Unit of lmrso_2m converted from kg/m² to mm.\n"
     ]
    }
   ],
   "source": [
    "ds_dict = set_units(ds_dict, conv_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496ef4b-4c7e-440c-bc72-e22c427845fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Save and replace netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e97f7140-a3c6-4616-9bf1-e898b1db15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.CESM2-WACCM.historical.vpd_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.CESM2-WACCM.historical.vpd_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.CESM2-WACCM.historical.lmrso_1m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.CESM2-WACCM.historical.lmrso_1m_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.CESM2-WACCM.historical.lmrso_2m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.CESM2-WACCM.historical.lmrso_2m_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.NorESM2-MM.historical.vpd_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.NorESM2-MM.historical.vpd_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.NorESM2-MM.historical.lmrso_1m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.NorESM2-MM.historical.lmrso_1m_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.NorESM2-MM.historical.lmrso_2m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.NorESM2-MM.historical.lmrso_2m_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.Ensemble mean.historical.vpd_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.Ensemble mean.historical.vpd_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.Ensemble mean.historical.lmrso_1m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.Ensemble mean.historical.lmrso_1m_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.Ensemble mean.historical.lmrso_2m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.Ensemble mean.historical.lmrso_2m_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.Ensemble median.historical.vpd_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/vpd/CMIP.Ensemble median.historical.vpd_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.Ensemble median.historical.lmrso_1m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_1m/CMIP.Ensemble median.historical.lmrso_1m_regridded.nc saved\n",
      "File  with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.Ensemble median.historical.lmrso_2m_regridded.nc removed\n",
      "File with path: ../../data/CMIP6/historical/preprocessed/lmrso_2m/CMIP.Ensemble median.historical.lmrso_2m_regridded.nc saved\n"
     ]
    }
   ],
   "source": [
    "# =========== Store file and remove any former one ==========\n",
    "nc_out = save_file(ds_dict, folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43681541-d876-4a70-a5f0-544e5f42fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Check stored file ==============\n",
    "xr.open_dataset(nc_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
