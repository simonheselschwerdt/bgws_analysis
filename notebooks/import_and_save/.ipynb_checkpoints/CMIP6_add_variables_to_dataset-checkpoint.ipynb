{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fcb352-aecb-438c-9c68-b8bed66b5882",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CMIP6 Add Variables to Dataset\n",
    "\n",
    "**Following steps are included in this script:**\n",
    "\n",
    "1. Open file\n",
    "2. Add Variables to Dataset\n",
    "3. Save data to netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0108914-eaef-4832-8fbd-2dc16ae7a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import xarray as xr\n",
    "import dask\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775b1a6-3cb0-4f1f-9a05-68d6cb3b42fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1f343-5b38-49a0-b194-0fa500db15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(save_file, folder, save_var=True):\n",
    "    \"\"\"\n",
    "    Save files as netCDF.\n",
    "\n",
    "    Args:\n",
    "        savefile (dict or dataset): Dictionary of xarray datasets or dataset.\n",
    "        folder (string): Name of folder data is saved in.\n",
    "        save_var (boolean): If True, data is saved separately for each variable. If false, one file is saved with all variables.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        nc_out: Path were data is saved in.\n",
    "    \"\"\"\n",
    "    \n",
    "    if save_var:\n",
    "        for key, ds in ds_dict.items():\n",
    "            for var in ds:\n",
    "                # Variable to keep\n",
    "                variable_to_keep = var\n",
    "                dimensions_to_keep = {'time', 'lat', 'lon'}\n",
    "                coordinates_to_keep = {'time', 'lat', 'lon'}\n",
    "\n",
    "                if any('depth' in ds[var].dims for var in ds.variables):\n",
    "                    dimensions_to_keep.add('depth')\n",
    "                    coordinates_to_keep.add('depth')\n",
    "\n",
    "                # Create a new dataset with only the desired variable\n",
    "                ds_var = ds[[variable_to_keep]]\n",
    "\n",
    "                # Keep only the desired dimensions\n",
    "                ds_var = ds_var.isel({dim: slice(None) for dim in dimensions_to_keep.intersection(ds_var.dims)})\n",
    "\n",
    "                # Set the desired coordinates\n",
    "                coords_to_set = set(ds_var.variables).intersection(coordinates_to_keep)\n",
    "                ds_var = ds_var.set_coords(list(coords_to_set))\n",
    "\n",
    "                savepath = f'../../data/CMIP6/{ds_var.experiment_id}/raw/{var}/'\n",
    "                filename = f'CMIP.{ds_var.source_id}.{ds_var.experiment_id}.{var}.nc'\n",
    "                nc_out = os.path.join(savepath, filename)\n",
    "                os.makedirs(savepath, exist_ok=True) \n",
    "                if os.path.exists(nc_out):\n",
    "                        inp = input(f\"Delete old file {filename} (y/n):\")\n",
    "                        if inp.lower() in [\"y\"]:\n",
    "                            os.remove(nc_out)\n",
    "                            print(f\"File with path: {nc_out} removed\")\n",
    "                        else:\n",
    "                            filename = \"temp_file.nc\"\n",
    "                            nc_out = os.path.join(savepath, filename)\n",
    "                            print(f\"Filename change to {filename}\")\n",
    "\n",
    "                # Save to netcdf file\n",
    "                with dask.config.set(scheduler='threads'):\n",
    "                    ds_var.to_netcdf(nc_out)\n",
    "                    print(f\"File with path: {nc_out} saved\")\n",
    "       \n",
    "    else:\n",
    "        for key in save_file.keys():\n",
    "            ds_in = save_file[key]\n",
    "            filename = f'CMIP.{ds_in.source_id}.{ds_in.experiment_id}.nc'\n",
    "            savepath = f'../data/CMIP6/{ds_in.experiment_id}/{folder}'\n",
    "            nc_out = os.path.join(savepath, filename)\n",
    "            os.makedirs(savepath, exist_ok=True) \n",
    "            if os.path.exists(nc_out):\n",
    "                inp = input(f\"Delete old file {filename} (y/n):\")\n",
    "                if inp.lower() in [\"y\"]:\n",
    "                    os.remove(nc_out)\n",
    "                    print(f\"File  with path: {nc_out} removed\")\n",
    "                else:\n",
    "                    filename = \"temp_file.nc\"\n",
    "                    nc_out = os.path.join(savepath, filename)\n",
    "                    print(f\"Filename change to {filename}\")\n",
    "\n",
    "            # Save to netcdf file\n",
    "            with dask.config.set(scheduler='threads'):\n",
    "                ds_in.to_netcdf(nc_out)\n",
    "\n",
    "    return nc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e9618-8715-41c3-bc01-8c1ab53d1665",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3799a7-108f-406a-ba12-6366b0656185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Load model which needs to be updated ==============\n",
    "experiment_id = 'historical'\n",
    "source_id = ['BCC-CSM2-MR']\n",
    "savepath = f'../../data/CMIP6/{experiment_id}/preprocessed'\n",
    "\n",
    "# ========= Use Dask to parallelize computations ==========\n",
    "dask.config.set(scheduler='processes')\n",
    "\n",
    "# ========= Create a helper function to open the dataset ========\n",
    "def open_dataset(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    return ds\n",
    "\n",
    "# ========= Create dictionary using a dictionary comprehension and Dask =======\n",
    "ds_dict, = dask.compute({model: open_dataset(os.path.join(savepath, f'CMIP.{model}.{experiment_id}.nc'))\n",
    "                        for model in source_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d24c25-0f26-43ed-850f-167187988320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========== Check dictionary =============\n",
    "print(ds_dict.keys())\n",
    "ds_dict[list(ds_dict.keys())[8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a50f8-ad50-467f-ad37-4982c063d4d9",
   "metadata": {},
   "source": [
    "### 2. Add new variable to dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa9e14-ddd4-45b6-b0d6-f5108430d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Create a dictionary with the computed monthly mean and the loaded model data ==========\n",
    "\n",
    "ds_dict_all = {}\n",
    "ds_dict_all['dataset_one'] = ds_dict[list(ds_dict.keys())[0]]\n",
    "ds_dict_all['dataset_two'] = ds_dict_[list(ds_dict_.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c14d8-9ca0-47d8-bb37-73cae975b9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========= Merge data ======================\n",
    "ds_dict_all = merge_source_id_data(ds_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e191e-3a5e-47b1-bb23-c76beacb1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Check dictionary =============\n",
    "print(ds_dict_all.keys())\n",
    "ds_dict_all[list(ds_dict_all.keys())[8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad37a4-0a42-40b4-8632-e1cba90922b7",
   "metadata": {},
   "source": [
    "### 3. Store netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf36f1-63d3-48e4-a66c-d584608a9f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========== Store file and remove any former one ==========\n",
    "nc_out = save_file(ds_dict_all, folder='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6a2e8-3e68-464a-a983-1d8bcb2c1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Check stored file ==============\n",
    "xr.open_dataset(nc_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
