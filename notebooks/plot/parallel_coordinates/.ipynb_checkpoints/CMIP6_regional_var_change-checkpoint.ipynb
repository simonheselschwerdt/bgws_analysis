{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7716ffb9-a564-44c7-87d4-2d4caeecdb1c",
   "metadata": {},
   "source": [
    "# CMIP6 Regional variable change\n",
    "\n",
    "**Following steps are included in this script:**\n",
    "\n",
    "1. Load netCDF files\n",
    "2. Compute regional variable change\n",
    "3. Plot change in reional parallel coordinate plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5a4f3-40bb-459a-88f0-f180c8b3ee8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854af429-43a1-489d-8513-dca8c1466663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import glob\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import copy\n",
    "import numpy as np\n",
    "import regionmask\n",
    "import math\n",
    "import cftime\n",
    "#import load_and_preprocess as lap \n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "plt.rcParams['text.usetex'] = False\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath, amssymb, textcomp}'\n",
    "\n",
    "# For color map\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74a0a3e-e91c-49cb-85f2-5990ea120f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check all possible fonts\n",
    "import matplotlib.font_manager\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def make_html(fontname):\n",
    "    return \"<p>{font}: <span style='font-family:{font}; font-size: 24px;'>{font}</p>\".format(font=fontname)\n",
    "\n",
    "code = \"\\n\".join([make_html(font) for font in sorted(set([f.name for f in matplotlib.font_manager.fontManager.ttflist]))])\n",
    "\n",
    "# Set the font\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Nimbus Sans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5daa16-4811-4773-b98d-6b69626ff6cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9148cef-f033-40ac-aeef-dec5ccdb277d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2. Subdivide Regions, Compute Mean and Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268d2c5-9778-48af-84ac-bfc2f93f8cbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f9e86-913e-4102-a26f-57f363dbdd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subdivide_region_and_compute_mean(ds_dict):\n",
    "    \n",
    "    ds_dict_regions = {}\n",
    "    \n",
    "    for scenario_name, scenario_dict in ds_dict.items():\n",
    "        ds_dict_regions[scenario_name] = apply_region_mask(scenario_dict, with_global=True)\n",
    "        ds_dict_regions[scenario_name] = calculate_spatial_mean( ds_dict_regions[scenario_name])\n",
    "   \n",
    "    return ds_dict_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad6a9f-173b-4e5b-b5b3-f7706018c916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_change_dict(ds_dict):\n",
    "    \"\"\"\n",
    "    Create a new dictionary that saves the changes of the scenarios to the historical period\n",
    "    for each model.\n",
    "\n",
    "    Parameters:\n",
    "    - ds_dict: Dictionary containing datasets for all scenarios and models, structured as ds_dict[scenario][model].\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with keys formatted as 'historical-<scenario>' for each scenario change\n",
    "      and each key containing a model-wise dictionary of changes.\n",
    "    \"\"\"\n",
    "    ds_dict_change = {}\n",
    "    scenarios = list(ds_dict.keys())\n",
    "    historical = scenarios[0]  # Assuming the first scenario is always 'historical'\n",
    "\n",
    "    # Iterate through scenarios (skipping the first 'historical' scenario)\n",
    "    for scenario in scenarios[1:]:\n",
    "        change_key = f'historical-{scenario}'\n",
    "        ds_dict_change[change_key] = {}\n",
    "\n",
    "        ds_base = ds_dict[historical]\n",
    "        ds_future = ds_dict[scenario]\n",
    "        ds_change = compute_change(ds_base, ds_future)\n",
    "\n",
    "        # Drop 'member_id' if present\n",
    "        if 'member_id' in ds_change:\n",
    "            ds_change = ds_change.drop('member_id')\n",
    "\n",
    "        ds_dict_change[change_key] = ds_change\n",
    "    \n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357aa01f-6265-42ef-a84f-cef6e4800e0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Apply region mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be2be2-e852-431d-a623-4ac7bc4ea92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_region_mask(ds_dict, with_global=False):\n",
    "    \"\"\"\n",
    "    Applies the AR6 land region mask to datasets in the provided dictionary, adds a region dimension,\n",
    "    and optionally includes a 'Global' aggregation.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets.\n",
    "        with_global (bool): If True, includes a 'Global' region with aggregated data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary where keys are the same as in the input dictionary,\n",
    "              and each value is an xarray Dataset with a region dimension added to each variable,\n",
    "              and optionally includes a 'Global' region.\n",
    "    \"\"\"\n",
    "\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    \n",
    "    if with_global:\n",
    "        global_mask = regionmask.defined_regions.natural_earth_v5_0_0.land_110\n",
    "    \n",
    "    ds_masked_dict = {}\n",
    "\n",
    "    for ds_name, ds in ds_dict.items():\n",
    "        ds_masked = xr.Dataset()  # Initiate an empty Dataset for the masked data\n",
    "        \n",
    "        # Get attributes\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        for var in ds:\n",
    "            # Get the binary mask\n",
    "            mask = land_regions.mask_3D(ds[var])\n",
    "            \n",
    "            var_attrs = ds[var].attrs\n",
    "\n",
    "            # Multiply the original data with the mask to get the masked data\n",
    "            masked_var = ds[var] * mask\n",
    "\n",
    "            # Replace 0s with NaNs, if desired\n",
    "            masked_var = masked_var.where(masked_var != 0)\n",
    "\n",
    "            if with_global:\n",
    "                # Convert the global mask to 3D to match the regional mask dimensions\n",
    "                glob_mask = global_mask.mask_3D(ds[var])\n",
    "                \n",
    "                global_masked_var = ds[var] * glob_mask\n",
    "                \n",
    "                # Replace 0s with NaNs, if desired\n",
    "                global_masked_var = global_masked_var.where(global_masked_var != 0)\n",
    "\n",
    "                # Combine masked data\n",
    "                masked_var = xr.concat([masked_var, global_masked_var], dim='region')\n",
    "                \n",
    "            # Add the masked variable to the output Dataset\n",
    "            ds_masked[var] = masked_var\n",
    "\n",
    "            ds_masked[var].attrs = var_attrs\n",
    "\n",
    "        # Copy dataset attributes\n",
    "        ds_masked.attrs.update(ds.attrs)\n",
    "        \n",
    "        correct_region_numbers = np.arange(0, ds_masked.dims['region'])\n",
    "\n",
    "        ds_masked = ds_masked.assign_coords(region=correct_region_numbers)\n",
    "\n",
    "        # Add the modified dataset to the dictionary\n",
    "        ds_masked_dict[ds_name] = ds_masked\n",
    "\n",
    "    return ds_masked_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d657f-da46-42ee-9e60-2076bc0dcac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate spatial mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b71e4e-b89b-4169-bac4-97f010c2f2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_spatial_mean(ds_dict):\n",
    "    ds_dict_mean = {}\n",
    "    \n",
    "    for key, ds in ds_dict.items():\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        # Initialize a new Dataset for this key\n",
    "        ds_dict_mean[key] = xr.Dataset()\n",
    "        \n",
    "        for var in list(ds.data_vars.keys()):\n",
    "            var_attrs = ds[var].attrs\n",
    "            \n",
    "            ds_dict_mean[key][var] = ds[var].mean(['lon', 'lat'])\n",
    "            ds_dict_mean[key][var].attrs = var_attrs\n",
    "        \n",
    "        ds_dict_mean[key].attrs = attrs\n",
    "        \n",
    "    return ds_dict_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5296d5-cb89-4a8d-b11e-e15e9ee0e06b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compute Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fedf68-0e05-43a4-a705-ba2e9b163a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_numeric(data):\n",
    "    try:\n",
    "        _ = data.astype(float)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def compute_change(ds_dict_hist, ds_dict_fut, var_rel_change=None):\n",
    "    ds_dict_change = {}\n",
    "\n",
    "    for name, ds_hist in ds_dict_hist.items():\n",
    "        if name in ds_dict_fut:\n",
    "            ds_future = ds_dict_fut[name]\n",
    "            common_vars = set(ds_hist.data_vars).intersection(ds_future.data_vars)\n",
    "\n",
    "            ds_change = ds_hist.copy(deep=True)\n",
    "            \n",
    "            if var_rel_change == 'all':\n",
    "                var_rel_change = common_vars\n",
    "                \n",
    "            for var in common_vars:\n",
    "                if is_numeric(ds_hist[var].data) and is_numeric(ds_future[var].data):\n",
    "                    # Always compute percentage change for 'mrso' as models have different depths\n",
    "                    if var == 'mrso':\n",
    "                        rel_change = (ds_future[var] - ds_hist[var]) / ds_hist[var].where(ds_hist[var] != 0) * 100\n",
    "                        ds_change[var].data = rel_change.data\n",
    "                        ds_change[var].attrs['units'] = '%'\n",
    "                    elif var_rel_change is not None and var in var_rel_change:\n",
    "                        # Compute relative change where ds_hist is not zero for specified variables\n",
    "                        rel_change = (ds_future[var] - ds_hist[var]) / ds_hist[var].where(ds_hist[var] != 0) * 100\n",
    "                        ds_change[var].data = rel_change.data\n",
    "                        ds_change[var].attrs['units'] = '%'\n",
    "                    else:\n",
    "                        # Compute absolute change for other variables\n",
    "                        abs_change = ds_future[var] - ds_hist[var]\n",
    "                        ds_change[var].data = abs_change.data\n",
    "\n",
    "            ds_change.attrs = ds_future.attrs\n",
    "            ds_dict_change[name] = ds_change\n",
    "\n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665eaeb-bb57-40e9-9292-ff5fad55aed7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Plot Variable Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9239dd6-1a3f-4a34-ae8c-da76464f4b90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Main plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c46f3-7bf2-4c5d-920d-f4032657dde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region_change(ds_dict_change, selected_indices, selected_vars=None, common_scale_for_mm_day=True, legend=True, save_fig=False, subdiv=False):\n",
    "    # Load Colormap\n",
    "    bgws_cm, norm = create_bgws_cm()\n",
    "    \n",
    "    # Compute Ensemble statisitc\n",
    "    ds_dict_change = compute_ensemble(ds_dict_change, 'mean')\n",
    "    ds_dict_change = compute_ensemble(ds_dict_change, 'median')\n",
    "    \n",
    "    # Get all model names\n",
    "    models = list(ds_dict_change.keys())\n",
    "    \n",
    "    # Get data info\n",
    "    variables, display_variables, experiment_id, description, months, yearly_sum, change_type, region_names = extract_variables(ds_dict_change, selected_vars)\n",
    "    \n",
    "    # Define regions to plot\n",
    "    selected_indices = ds_dict_change['Ensemble mean'].region.values.tolist() if selected_indices == \"ALL\" else selected_indices\n",
    "    \n",
    "    # Loop over regions to create single plot for each region\n",
    "    for region_idx in selected_indices:\n",
    "        \n",
    "        if subdiv:\n",
    "            for subdiv_idx in range(ds_dict_change['Ensemble mean'].dims['subdivision']):\n",
    "                print(subdiv_idx)\n",
    "                # Create figure and axes\n",
    "                fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "                # Create regional plot\n",
    "                plot_region(fig, axes, models, region_idx, ds_dict_change, variables, display_variables, change_type, bgws_cm, subdiv_idx, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "                # Add legend and colorbar\n",
    "                if legend:\n",
    "                    add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                if save_fig:\n",
    "                    save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, subdiv_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "                else:\n",
    "                    print('Figure not saved. If you want to save the figure add save_fig=True to the function call')\n",
    "\n",
    "        else:\n",
    "             # Create figure and axes\n",
    "            fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "            # Create regional plot\n",
    "            plot_region(fig, axes, models, region_idx, ds_dict_change, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "            # Add legend and colorbar\n",
    "            if legend:\n",
    "                add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            if save_fig:\n",
    "                save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "            else:\n",
    "                print('Figure not saved. If you want to save the figure add save_fig=True to the function call')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ff7c9-44b6-4d4a-a0d6-19c0ce25bebe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create Colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877ac72-13bb-4833-bcc1-cb249a86583b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bgws_cm():\n",
    "    # Define start and end colors for both gradients\n",
    "    deep_blue = (20/255, 110/255, 180/255)\n",
    "    light_blue = (180/255, 215/255, 255/255)\n",
    "    deep_green = (14/255, 119/255, 14/255)\n",
    "    light_green = (160/255, 220/255, 140/255)\n",
    "\n",
    "    # Create custom colormaps\n",
    "    blue_cmap = LinearSegmentedColormap.from_list(\"blue_cmap\", [light_blue, deep_blue], N=4)\n",
    "    green_cmap = LinearSegmentedColormap.from_list(\"green_cmap\", [deep_green, light_green], N=4)\n",
    "\n",
    "    # Sample colors from colormaps\n",
    "    blue_colors = [blue_cmap(i) for i in np.linspace(0, 1, 4)]\n",
    "    green_colors = [green_cmap(i) for i in np.linspace(0, 1, 4)]\n",
    "\n",
    "    # Combine both gradients\n",
    "    combined_grad = green_colors + blue_colors\n",
    "\n",
    "    # Define boundaries\n",
    "    boundaries = sorted([-0.1, -0.075, -0.05, -0.025, 0, 0.025, 0.05, 0.075, 0.1])\n",
    "    norm = BoundaryNorm(boundaries, len(combined_grad), clip=True)\n",
    "\n",
    "    cmap_name = 'BGWS colormap'\n",
    "    bgws_cm = LinearSegmentedColormap.from_list(cmap_name, combined_grad, N=len(combined_grad))\n",
    "\n",
    "    # Return the colormap and norm\n",
    "    return bgws_cm, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48efa96-946e-44de-a57b-683c668e6e36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Get Data Info for Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcba1a-0d52-4c81-928b-0b6d16b67f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_change_type(ds_dict):\n",
    "    \"\"\"\n",
    "    Determines the type of change (relative or absolute) based on the units of the first \n",
    "    variable found in the provided dataset dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    - ds_dict: A dictionary structured as ds_dict[scenario][model] containing xarray Dataset or DataArray objects.\n",
    "    \n",
    "    Returns:\n",
    "    - A string indicating the type of change: 'rel_change' for relative change (units in '%'), \n",
    "      otherwise 'abs_change' for absolute change.\n",
    "    \"\"\"\n",
    "    # Attempt to retrieve the first dataset from the dictionary\n",
    "    try:\n",
    "        first_scenario = list(ds_dict.keys())[0]\n",
    "        first_model = list(ds_dict[first_scenario].keys())[0]\n",
    "        first_dataset = ds_dict[first_scenario][first_model]\n",
    "        \n",
    "        # Depending on the structure, handle both Dataset and DataArray cases\n",
    "        if isinstance(first_dataset, xr.Dataset):\n",
    "            # For Dataset, find the first data variable\n",
    "            first_var_name = list(first_dataset.data_vars)[0]\n",
    "            units = first_dataset[first_var_name].attrs.get('units', '')\n",
    "        elif isinstance(first_dataset, xr.DataArray):\n",
    "            # For DataArray, directly access its units attribute\n",
    "            units = first_dataset.attrs.get('units', '')\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected data structure. Expected xarray Dataset or DataArray.\")\n",
    "        \n",
    "        # Determine change type based on units\n",
    "        return 'rel_change' if units == '%' else 'abs_change'\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining change type: {e}\")\n",
    "        return 'abs_change'  # Default to 'abs_change' in case of error or unexpected data structure\n",
    "\n",
    "def prepare_display_variables(variables):\n",
    "    var_map = {\n",
    "        'tas': ('T', 'Â°C'),\n",
    "        'vpd': ('VPD', 'hPa'),\n",
    "        'gpp': ('GPP', r'\\frac{\\frac{gC}{m^2}}{day}'),  \n",
    "        'pr': ('P', r'\\frac{mm}{day}'),\n",
    "        'mrro': ('R', r'\\frac{mm}{day}'),\n",
    "        'evspsbl': ('ET', r'\\frac{mm}{day}'),\n",
    "        'tran': ('Tran', r'\\frac{mm}{day}'),\n",
    "        'evapo': ('E', r'\\frac{mm}{day}'),\n",
    "        'lai': ('Lai', r'\\frac{m^2}{m^2}'),\n",
    "        'mrso': ('SM', '\\%'),\n",
    "        'rgtr': ('P/T', r'\\frac{GPP}{T}'),\n",
    "        'et_partitioning': ('EP', r'\\frac{E-Tran}{ET}'),\n",
    "        'growing_season_length_period': ('GSL', 'months'),\n",
    "        'RX5day': ('RX5d', 'mm'),\n",
    "        'growing_season_length_winter': ('GSL', 'months'),\n",
    "        'growing_season_length_summer': ('GSL', 'months'),\n",
    "        'growing_season_length_fall': ('GSL', 'months'),\n",
    "        'growing_season_length_spring': ('GSL', 'months'),\n",
    "        'wue': ('WUE', r'\\frac{GPP}{Tran}'),\n",
    "        'bgws': ('BGWS', r'\\frac{R-T}{P}')\n",
    "    }\n",
    "    display_variables = {}\n",
    "    for var in variables:\n",
    "        if var in var_map:\n",
    "            abbreviation, units = var_map[var]\n",
    "            # Enclose units in \\left[ and \\right] for automatic sizing\n",
    "            display_variables[var] = f\"${{\\Delta\\, \\mathrm{{\\it{{{abbreviation}}}}}}}$ \\n $\\\\left[{units}\\\\right]$\"\n",
    "        else:\n",
    "            print(f\"Variable '{var}' not found in var_map.\")\n",
    "            display_variables[var] = var  # Or handle this case as appropriate\n",
    "    return display_variables\n",
    "\n",
    "\n",
    "def extract_variables(ds_dict, selected_vars):\n",
    "    ensemble = ds_dict['Ensemble mean']\n",
    "    variables = [var for var in ensemble.data_vars.keys() if var not in ['bgws', 'region', 'abbrevs', 'names', 'member_id']] if selected_vars is None else [var for var in selected_vars if var in ensemble.data_vars.keys()]\n",
    "    experiment_id = ds_dict[list(ds_dict.keys())[0]].experiment_id\n",
    "    description = ds_dict[list(ds_dict.keys())[0]].description\n",
    "    months = ds_dict[list(ds_dict.keys())[0]].months\n",
    "    yearly_sum = ds_dict[list(ds_dict.keys())[0]].yearly_sum\n",
    "    display_variables = prepare_display_variables(variables)\n",
    "    change_type = determine_change_type(ds_dict)\n",
    "    region_names = ds_dict[list(ds_dict.keys())[0]].names\n",
    "    return variables, display_variables, experiment_id, description, months, yearly_sum, change_type, region_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5fa8bd-aecb-4bd6-ba26-df1da36464d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compute ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc9c41-e70b-40da-802d-c4fcb0bc4eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_ensemble(ds_dict_change, statistic):\n",
    "    \n",
    "    # Drop previously computed ensemble statistics\n",
    "    for key in [f'Ensemble {statistic}']:\n",
    "        if key in ds_dict_change:\n",
    "            ds_dict_change.pop(key)\n",
    "    \n",
    "    # Get attrs of the variables\n",
    "    var_attrs = {}\n",
    "    for var in ds_dict_change[list(ds_dict_change.keys())[0]].data_vars:\n",
    "        var_attrs[var] = ds_dict_change[list(ds_dict_change.keys())[0]][var].attrs\n",
    "            \n",
    "    \n",
    "    # Coompute ensemble mean\n",
    "    combined = xr.concat(ds_dict_change.values(), dim='ensemble')\n",
    "    ds_dict_change[f'Ensemble {statistic}'] = getattr(combined, statistic)(dim='ensemble')\n",
    "    \n",
    "    \n",
    "    # Add variable attrs\n",
    "    for var in ds_dict_change[f'Ensemble {statistic}'].data_vars:\n",
    "        ds_dict_change[f'Ensemble {statistic}'][var].attrs = var_attrs[var] \n",
    "        \n",
    "    ssp = ds_dict_change[list(ds_dict_change.keys())[0]].experiment_id\n",
    "    \n",
    "    # Add ensemble attr\n",
    "    ds_dict_change[f'Ensemble {statistic}'].attrs = {'experiment_id': f'{ssp}-historical',\n",
    "                                                    'source_id': f'Ensemble {statistic}',\n",
    "                                                    'months': 'whole_year',\n",
    "                                                    'yearly_sum': 'monthly_mean',\n",
    "                                                    }\n",
    "            \n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47817e6-23bc-4bda-8451-cd928e57bfd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Legend and colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cffa0-9150-4827-9abf-b9dc3125b30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_legend_and_colorbar(fig, ax, models, norm, bgws_cm, description, region_names, selected_region):\n",
    "    # Caption and figure saving\n",
    "    region_name = region_names.isel(region=selected_region).item()\n",
    "    caption = region_name\n",
    "    fig.text(0.6, 0.93, caption, ha='center', va='top', fontsize=22, wrap=True)\n",
    "    \n",
    "    # Layout adjustments\n",
    "    #plt.subplots_adjust(wspace=1, hspace=0.7)\n",
    "    \n",
    "    # Upper Legend (Ensemble mean, median, and line styles)\n",
    "    upper_legend_position = [0.975, 0.61, 0.1, 0.125]  # Adjust position as needed\n",
    "    upper_legend_ax = fig.add_axes(upper_legend_position, frame_on=False)\n",
    "    upper_legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='D', markeredgecolor='red', markerfacecolor='none', label='Ensemble mean', markersize=10, linestyle='None', lw=2),\n",
    "        plt.Line2D([0], [0], marker='o', mec='orange', mfc='none', label='Ensemble median', markersize=14, linestyle='None', mew=2),\n",
    "        plt.Line2D([0], [0], color='black', label='+ $\\Delta$ BGWS', linestyle='-', linewidth=2),\n",
    "        plt.Line2D([0], [0], color='black', label='- $\\Delta$ BGWS', linestyle='--', linewidth=2)  \n",
    "    ]\n",
    "    upper_legend = upper_legend_ax.legend(handles=upper_legend_elements, fontsize=18, loc='center', ncol=2,\n",
    "                                          columnspacing=1, handletextpad=0.5, borderaxespad=0.5)\n",
    "    upper_legend_ax.axis('off')\n",
    "    upper_legend.get_frame().set_facecolor('none')\n",
    "    upper_legend.get_frame().set_edgecolor('none')\n",
    "    \n",
    "    # Define starting position and spacing for the model name annotations\n",
    "    start_x = 0.92  # Right side of the figure; adjust as needed\n",
    "    start_y = 0.597  # Starting height; adjust as needed\n",
    "    spacing_y = 0.0315  # Vertical spacing between model names; adjust as needed\n",
    "    num_columns = 2  # Number of columns for model names\n",
    "    column_width = 0.117  # Horizontal space between columns\n",
    "\n",
    "    # Filter out the ensemble mean and median for the model names annotation\n",
    "    model_names = [model for model in models if model not in [\"Ensemble mean\", \"Ensemble median\"]]\n",
    "\n",
    "    # Calculate how many names per column\n",
    "    names_per_column = len(model_names) // num_columns + (len(model_names) % num_columns > 0)\n",
    "\n",
    "    # Loop through the model names to place them as text annotations\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        column = idx // names_per_column\n",
    "        row = idx % names_per_column\n",
    "        x_position = start_x + column * column_width  # Adjust x based on column\n",
    "        y_position = start_y - row * spacing_y  # Adjust y based on row\n",
    "\n",
    "        # Place text annotation\n",
    "        fig.text(x_position, y_position, f\"{idx + 1}: {model_name}\", fontsize=18, transform=fig.transFigure, ha='left', va='top')\n",
    " \n",
    "    # Add the colorbar below the lower legend\n",
    "    colorbar_position = [0.92, 0.3, 0.2, 0.03]  # right, up, length, width\n",
    "    cbar_ax = fig.add_axes(colorbar_position)\n",
    "    cbar = fig.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=bgws_cm), cax=cbar_ax, orientation='horizontal', extend='both')\n",
    "    cbar.set_label(\"$\\Delta$ Blue-Green Water Share\", fontsize=18, weight='bold')\n",
    "    cbar.set_ticks([-0.1, -0.075, -0.05, -0.025, 0, 0.025, 0.05, 0.075, 0.1])\n",
    "    cbar.set_ticklabels([\"-10\", \"\", \"-5\", \"\", \"0\", \"\", \"5\", \"\", \"10\"])\n",
    "    cbar.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04430a5a-bfc8-4e72-bfd0-a6b5bdc8f58e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e052c87-c715-4a6c-b475-adae8f1b0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_based_on_position(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    abs_x = abs(x)\n",
    "    if abs_x >= 10:\n",
    "        # For numbers >= 10, round up to the next integer\n",
    "        return math.ceil(x)\n",
    "    elif abs_x >= 1:\n",
    "        # For numbers < 10 and >= 1, round up to the nearest 0.5 or the next integer\n",
    "        return max(1.5, math.ceil(x * 2) / 2)\n",
    "    else:\n",
    "        # For numbers < 1, round up in a way that increases the first significant digit\n",
    "        digit_pos = -int(math.floor(math.log10(abs_x)))  # Position of first significant digit\n",
    "        increment = 10 ** (-digit_pos)\n",
    "        return math.ceil(x / increment) * increment\n",
    "\n",
    "def adjust_array(arr):\n",
    "    abs_max_val = np.max(np.abs(arr))\n",
    "    new_max = round_based_on_position(abs_max_val)\n",
    "    \n",
    "    # The adjustment logic above ensures we're rounding up correctly\n",
    "    # Construct the new array with the calculated new maximum\n",
    "    new_arr = np.array([-new_max, -new_max / 2, 0, new_max / 2, new_max])\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a94ac-d69a-4823-b161-52fad0000671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region(fig, axes, models, selected_region, ds_dict_change, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=True):\n",
    "    # Iterate over models and variables to plot\n",
    "    for i, model_name in enumerate(models, start=1):\n",
    "        ds = ds_dict_change[model_name]  # Get the dataset for the current model\n",
    "        prev_xy = None\n",
    "\n",
    "        for j, variable in enumerate(variables):\n",
    "            if variable in ds.data_vars:\n",
    "                selected_data = ds[variable].sel(region=selected_region).values.item()  # Get the single value for the selected region\n",
    "                        \n",
    "                bgws_value = ds['bgws'].sel(region=selected_region).values.item()  # Get bgws value for linestyle decision\n",
    "\n",
    "                # Normalize bgws value for color mapping\n",
    "                color = bgws_cm((bgws_value - -0.1) / (0.1 - -0.1))\n",
    "\n",
    "                current_xy = (j, value)\n",
    "                #print(model_name, variable, value)\n",
    "                \n",
    "                if np.isnan(value):\n",
    "                    prev_xy = None\n",
    "                    continue\n",
    "\n",
    "                if model_name.lower() == \"ensemble mean\":\n",
    "                    axes[j].plot(j, value, 'D', mec='red', mfc='none', markersize=22, mew=2, zorder=5)\n",
    "                elif model_name.lower() == \"ensemble median\":\n",
    "                    axes[j].plot(j, value, 'o', mec='orange', mfc='none', markersize=28, mew=2, zorder=4)\n",
    "                else:\n",
    "                    if j % 2 == 0:\n",
    "                        dot_color = '#f0f0f0'\n",
    "                    else: \n",
    "                        dot_color = 'white'\n",
    "                    axes[j].plot(j, value, 'o', color=dot_color, markersize=38, zorder=1)\n",
    "                    axes[j].annotate(str(i), xy=current_xy, xytext=(0, 0), textcoords='offset points',\n",
    "                                     fontsize=38, weight='bold', color=color,\n",
    "                                     ha='center', va='center', zorder=2)\n",
    "\n",
    "                if prev_xy is not None:\n",
    "                    linestyle = '--' if bgws_value < 0 else '-'\n",
    "                    con = ConnectionPatch(xyA=prev_xy, xyB=current_xy, coordsA=\"data\", coordsB=\"data\",\n",
    "                                          axesA=axes[j-1], axesB=axes[j],\n",
    "                                          linestyle=linestyle, shrinkA=17, shrinkB=17, color=color, linewidth=2)  \n",
    "                    fig.add_artist(con)\n",
    "\n",
    "                prev_xy = current_xy\n",
    "            else:\n",
    "                prev_xy = None\n",
    "    \n",
    "    \n",
    "     # Identify \"mm/day\" variables\n",
    "    mm_day_variables = ['pr', 'mrro', 'evspsbl', 'tran', 'evapo'] \n",
    "\n",
    "    if use_common_scale_for_mm_day:\n",
    "        # Calculate the max absolute value for \"mm/day\" variables across all models\n",
    "        max_abs_mm_day = 0\n",
    "        for var in mm_day_variables:\n",
    "            for model_name, ds in ds_dict_change.items():\n",
    "                if var in ds.data_vars:\n",
    "                    abs_values = np.abs(ds[var].sel(region=selected_region).values)\n",
    "                    max_abs_mm_day = max(max_abs_mm_day, np.nanmax(abs_values))\n",
    "        common_ylim = max_abs_mm_day * 1.05  # Common y-axis limit for \"mm/day\" variables, scaled up slightly for visual margin\n",
    "    else:\n",
    "        common_ylim = None  # This will signify not to use a common y-limit for \"mm/day\" variables\n",
    "\n",
    "    # Calculate maximum absolute value for each variable across all models for the selected region\n",
    "    max_abs_values = {}\n",
    "    for var in variables:\n",
    "        if var not in mm_day_variables or not use_common_scale_for_mm_day:\n",
    "            max_values = []\n",
    "            for model_name, ds in ds_dict_change.items():\n",
    "                if var in ds.data_vars:\n",
    "                    value = abs(ds[var].sel(region=selected_region).values.item())\n",
    "                    if np.isnan(value):\n",
    "                        continue\n",
    "                    max_values.append(value)\n",
    "            max_abs_values[var] = max(max_values) if max_values else 0\n",
    "        else:\n",
    "            # Use common y-axis limit for \"mm/day\" variables if flag is set\n",
    "            max_abs_values[var] = common_ylim\n",
    "\n",
    "    # Adjust axes properties and add variable names\n",
    "    for j, var in enumerate(variables):\n",
    "        # Set x-axis ticks and labels with improved formatting\n",
    "        axes[j].set_xlim(j - 1, j + 1)\n",
    "        axes[j].set_xticks([j])\n",
    "        axes[j].spines['top'].set_visible(False)\n",
    "        axes[j].spines['bottom'].set_visible(False)\n",
    "        axes[j].spines['right'].set_visible(False)\n",
    "        axes[j].set_xticklabels([display_variables[var]], fontdict={'size': 25})\n",
    "       \n",
    "        axes[j].tick_params(axis='x', length=10, color='white')#,  labelrotation=90)   # Adjust x-axis tick label size\n",
    "            \n",
    "        # Add horizontal line at y=0\n",
    "        axes[j].axhline(y=0, color='gray', linestyle='-', linewidth=1)  \n",
    "\n",
    "        # Set y-axis ticks and labels with improved formatting\n",
    "        # Calculate the maximum absolute value for the variable\n",
    "        max_abs_value = max_abs_values[var] * 1.05\n",
    "        ticks = adjust_array(np.linspace(-max_abs_value, max_abs_value, num=5))\n",
    "        #print(max_abs_value, ticks)\n",
    "        # Set the y-axis limits to ensure 0 is always in the middle\n",
    "        axes[j].set_ylim(ticks[0], ticks[-1])\n",
    "        axes[j].set_yticks(ticks)\n",
    "        axes[j].spines['left'].set_bounds(ticks[0], ticks[-1]) # Set bounds for left spine\n",
    "        axes[j].tick_params(axis='y', labelsize=18)  # Adjust y-axis tick label size\n",
    "        \n",
    "        # Coloring every second subplot's background\n",
    "        if j % 2 == 0:  # This checks if the index is odd, applying the color to every second subplot\n",
    "            axes[j].set_facecolor('#f0f0f0')  # Light gray background\n",
    "    \n",
    "        if j == 0:\n",
    "            # This is the first subplot, so add a y-axis label here\n",
    "            axes[j].set_ylabel(\"End-of-century response\", fontsize=25)\n",
    "    \n",
    "        # Improved tick label formatting to remove unnecessary trailing zeros\n",
    "        if j > 0:  # Check if not the first axis\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' and tick != 0 else '' for tick in ticks])\n",
    "            ticks = axes[j].yaxis.get_major_ticks() \n",
    "            # Modify properties of the first tick\n",
    "            tick_to_modify = 2  # Index of the tick to modify\n",
    "            ticks[tick_to_modify].tick1line.set_markersize(50)\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgecolor('gray')\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgewidth(1)\n",
    "\n",
    "        else:\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' else f'{tick:.2f}' for tick in ticks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de918c-fcba-4cad-9668-1097875e72ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a3e1c-07d0-4491-9203-7636d735b243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_figure(fig, change, experiment_id, months, yearly_sum, region_names, region_idx, subdiv_idx, legend, common_scale_for_mm_day):\n",
    "    # Caption and figure saving\n",
    "    region_name = (region_names.isel(region=region_idx).item()).replace(\"/\", \"_\")\n",
    "    savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'regional_var_change', region_name)\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "    if legend:\n",
    "        if common_scale_for_mm_day:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}.pdf'\n",
    "        else:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}_no_common_y_scale.pdf' \n",
    "    else:\n",
    "        if common_scale_for_mm_day:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}_without_legend.pdf' \n",
    "\n",
    "        else:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}_without_legend_no_common_y_scale.pdf' \n",
    "    filepath = os.path.join(savepath, filename)\n",
    "    fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    print(f'Figure saved under {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173177e7-1327-46be-9952-4ba5d9d45155",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e8e5b-a170-48a1-99ab-f6403c0db466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restore the load and preprocess function\n",
    "\n",
    "#This is what it need to do:\n",
    "season=None # None, 'spring', summer, fall, winter\n",
    "ds_dict = lap.load_and_preprocess(vars='all', scenarios=['historical', 'ssp370'], models='all', period=season, yearly_sum=False, period_statistic='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5c9f8-edc7-46e4-a848-f5affe9d20a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02975c-6fbd-4097-9cc9-89d416b80f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0c936e-1317-4f16-9138-6aa7465b09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d469d6-5c9f-4804-8c92-6db8cef15b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath('')), '../../../../common/src'))\n",
    "import data_handling.load_preprocessed_data as lpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44805cb7-af6b-43f5-90ac-fb0721031f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries for preprocessed datasets\n",
    "ds_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d0ac36-08d4-4ea2-b384-e485d9d731ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source models (IDs)\n",
    "source_ids = ['BCC-CSM2-MR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf98452-2bea-4046-ac0f-482ee0fee414",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = ['historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4cdba-b389-4011-b633-22f17b975b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each scenario\n",
    "for scenario in experiment_ids:\n",
    "    print(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b256bb2b-da9c-4593-8d51-172305ac0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_temp = {}\n",
    "ds_dict[scenario] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbc801e-036b-4d25-b129-6f058c96158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_variables(vars_selected, period):\n",
    "    # Define categories based on temporal resolution\n",
    "    monthly_variables = ['tas', 'pr', 'vpd', 'mrro', 'mrso', 'tran', 'lai', 'gpp', 'evspsbl', 'evapo']\n",
    "    yearly_variables = ['RX5day']\n",
    "    \n",
    "    # Adjust the handling of period\n",
    "    if period is not None:\n",
    "        period_variables = [f'growing_season_length_{period}']  # Use the specific period if provided\n",
    "        yearly = period  # The default yearly category name\n",
    "    else:\n",
    "        period_variables = ['growing_season_length_period']  # Use a general name if no specific period is provided\n",
    "        yearly = 'year'  # The default yearly category name\n",
    "        period = 'period'  # Use 'period' as the category name if no specific period is provided\n",
    "    \n",
    "    # Initialize categories\n",
    "    categories = {\n",
    "        'month': [],\n",
    "        yearly: [],\n",
    "        period: []\n",
    "    }\n",
    "\n",
    "    # Check the selection and categorize\n",
    "    if vars_selected == 'all':\n",
    "        categories['month'].extend(monthly_variables)\n",
    "        categories[yearly].extend(yearly_variables)\n",
    "        categories[period].extend(period_variables)\n",
    "    else:\n",
    "        for var in vars_selected:\n",
    "            if var in monthly_variables:\n",
    "                categories['month'].append(var)\n",
    "            elif var in yearly_variables:\n",
    "                categories[yearly].append(var)\n",
    "            elif var == 'growing_season_length':  # Use a general check for the variable name\n",
    "                categories[period].append(var if period is None else f'growing_season_length_{period}')\n",
    "            else:\n",
    "                print(f\"Warning: Variable '{var}' not recognized.\")\n",
    "                \n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265b310b-b7b6-40b8-b697-c6d6feb2b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize variables based on temporal resolution\n",
    "categorized_variables = categorize_variables('all', period=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785b1f2-8519-4ad9-b22d-eb39aa2b46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(scenario, models, data_state, temporal_resolution, variables):\n",
    "    # Initialize the dictionary to store datasets\n",
    "    ds_dict = {}\n",
    "\n",
    "    \n",
    "                ds = open_and_merge_datasets(folder, model, experiment_id, temp_res, variables)\n",
    "                ds_dict[experiment_id][model] = ds\n",
    "            except ValueError as e:\n",
    "                print(f\"Failed to load data for model {model} in scenario {experiment_id}: {e}\")\n",
    "\n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c68d2de-c115-4f53-9f2f-c396b933b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239e9c5-2734-4c4a-826c-af220b9107d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_default_settings(models='all'):\n",
    "    source_ids = ['BCC-CSM2-MR', 'CAMS-CSM1-0', 'CanESM5-CanOE', 'CanESM5', 'CESM2-WACCM', 'CNRM-CM6-1', \n",
    "                  'CNRM-ESM2-1', 'GFDL-ESM4', 'GISS-E2-1-G', 'MIROC-ES2L', 'MPI-ESM1-2-LR', \n",
    "                  'NorESM2-MM', 'TaiESM1', 'UKESM1-0-LL'] if models == 'all' else models\n",
    "    source_ids_rx5day = ['BCC-CSM2-MR', 'CAMS-CSM1-0', 'CanESM5', 'CESM2-WACCM', 'CNRM-CM6-1', \n",
    "                         'CNRM-ESM2-1', 'GFDL-ESM4', 'MIROC-ES2L', 'MPI-ESM1-2-LR', \n",
    "                         'NorESM2-MM', 'UKESM1-0-LL'] if models == 'all' else models\n",
    "    return source_ids, source_ids_rx5day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa3d34-f735-4610-b128-d6a52c44cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_variables(vars_selected, period):\n",
    "    # Define categories based on temporal resolution\n",
    "    monthly_variables = ['tas', 'pr', 'vpd', 'mrro', 'mrso', 'tran', 'lai', 'gpp', 'evspsbl', 'evapo']\n",
    "    yearly_variables = ['RX5day']\n",
    "    \n",
    "    # Adjust the handling of period\n",
    "    if period is not None:\n",
    "        period_variables = [f'growing_season_length_{period}']  # Use the specific period if provided\n",
    "        yearly = period  # The default yearly category name\n",
    "    else:\n",
    "        period_variables = ['growing_season_length_period']  # Use a general name if no specific period is provided\n",
    "        yearly = 'year'  # The default yearly category name\n",
    "        period = 'period'  # Use 'period' as the category name if no specific period is provided\n",
    "    \n",
    "    # Initialize categories\n",
    "    categories = {\n",
    "        'month': [],\n",
    "        yearly: [],\n",
    "        period: []\n",
    "    }\n",
    "\n",
    "    # Check the selection and categorize\n",
    "    if vars_selected == 'all':\n",
    "        categories['month'].extend(monthly_variables)\n",
    "        categories[yearly].extend(yearly_variables)\n",
    "        categories[period].extend(period_variables)\n",
    "    else:\n",
    "        for var in vars_selected:\n",
    "            if var in monthly_variables:\n",
    "                categories['month'].append(var)\n",
    "            elif var in yearly_variables:\n",
    "                categories[yearly].append(var)\n",
    "            elif var == 'growing_season_length':  # Use a general check for the variable name\n",
    "                categories[period].append(var if period is None else f'growing_season_length_{period}')\n",
    "            else:\n",
    "                print(f\"Warning: Variable '{var}' not recognized.\")\n",
    "                \n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447b4f5-c1ef-4a4c-a772-5838aa38f368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c70fc0-2c67-4dc8-bc6c-964dff8687fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85fe284a-7981-4c51-a94c-09b34992d087",
   "metadata": {},
   "source": [
    "## load_preprocessed_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b56c67f6-1ef6-4321-bbe5-12c2d27df4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import sys\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "import importlib\n",
    "import regionmask\n",
    "\n",
    "# Define the full path to the data_handling directory and the config file\n",
    "data_handling_dir = '/work/ch0636/g300115/phd_project/common/src/data_handling'\n",
    "config_dir = '/work/ch0636/g300115/phd_project/common/src'\n",
    "\n",
    "# Add the directories to sys.path\n",
    "sys.path.append(data_handling_dir)\n",
    "sys.path.append(config_dir)\n",
    "\n",
    "# Now import the functions from load_preprocessed_data.py and config\n",
    "import load_data as load_dat\n",
    "import process_data as pro_dat\n",
    "import compute_statistics as comp_stats\n",
    "import save_data_as_nc as sd\n",
    "from config import BASE_DIR, DEFAULT_MODEL, DEFAULT_VARIABLE, DEFAULT_TEMPORAL_RES, DEFAULT_EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85687a21-2bfc-46f1-8d86-98934a291fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'compute_statistics' from '/work/ch0636/g300115/phd_project/common/src/data_handling/compute_statistics.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(load_dat)\n",
    "importlib.reload(pro_dat)\n",
    "importlib.reload(comp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e548294a-9a9c-41c9-a16a-5b312006f170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'month' resolution variables ['tas', 'pr', 'vpd', 'evspsbl', 'evapo', 'tran', 'mrro', 'mrso', 'lai', 'gpp'] for experiment 'historical'...\n",
      "No file found for variable 'vpd' in model 'CAMS-CSM1-0'.\n",
      "No file found for variable 'gpp' in model 'CAMS-CSM1-0'.\n",
      "Model 'CAMS-CSM1-0' is missing variables: vpd, gpp\n",
      "Selecting period 1985-2014 for 'month' variables in experiment 'historical'...\n",
      "Computing period mean for 'month' variables in experiment 'historical'...\n",
      "Loading 'year' resolution variable 'RX5day' for experiment 'historical'...\n",
      "No file found for variable 'RX5day' in model 'GISS-E2-1-G'.\n",
      "Model 'GISS-E2-1-G' is missing variables: RX5day\n",
      "No file found for variable 'RX5day' in model 'TaiESM1'.\n",
      "Model 'TaiESM1' is missing variables: RX5day\n",
      "Computing period mean for 'year' variable in experiment 'historical'...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Neither 'time' nor 'year' dimension found in the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/work/ch0636/g300115/.conda/envs/mypy3/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/work/ch0636/g300115/.conda/envs/mypy3/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"/work/ch0636/g300115/phd_project/common/src/data_handling/compute_statistics.py\", line 38, in compute_statistic_per_model\n    return compute_temporal_statistic(ds, statistic)\n  File \"/work/ch0636/g300115/phd_project/common/src/data_handling/compute_statistics.py\", line 61, in compute_temporal_statistic\n    raise ValueError(\"Neither 'time' nor 'year' dimension found in the dataset\")\nValueError: Neither 'time' nor 'year' dimension found in the dataset\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Execute load function with Dask\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m---> 11\u001b[0m     ds_dict \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mcompute(\u001b[43mload_dat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_period_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_product\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecific_months_or_seasons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/work/ch0636/g300115/phd_project/common/src/data_handling/load_data.py:225\u001b[0m, in \u001b[0;36mload_period_mean\u001b[0;34m(BASE_DIR, data_state, data_product, experiments, models, variables, specific_months_or_seasons)\u001b[0m\n\u001b[1;32m    222\u001b[0m     ds_year \u001b[38;5;241m=\u001b[39m load_multiple_models_and_experiments(BASE_DIR, data_state, data_product, [experiment], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, models, [year_variable])\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing period mean for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m variable in experiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 225\u001b[0m     ds_dict[experiment][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_stats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_temporal_or_spatial_statistic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_year\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemporal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Process period_mean variable\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m period_mean_variable:\n",
      "File \u001b[0;32m/work/ch0636/g300115/phd_project/common/src/data_handling/compute_statistics.py:115\u001b[0m, in \u001b[0;36mcompute_temporal_or_spatial_statistic\u001b[0;34m(ds_dict, dimension, statistic)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Compute statistic for each model using parallel processing\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool() \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 115\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_statistic_per_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatistic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mds_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(ds_dict\u001b[38;5;241m.\u001b[39mkeys(), results))\n",
      "File \u001b[0;32m/work/ch0636/g300115/.conda/envs/mypy3/lib/python3.10/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/ch0636/g300115/.conda/envs/mypy3/lib/python3.10/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/work/ch0636/g300115/.conda/envs/mypy3/lib/python3.10/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[0;32m/work/ch0636/g300115/.conda/envs/mypy3/lib/python3.10/multiprocessing/pool.py:51\u001b[0m, in \u001b[0;36mstarmapstar\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmapstar\u001b[39m(args):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mstarmap(args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m/work/ch0636/g300115/phd_project/common/src/data_handling/compute_statistics.py:38\u001b[0m, in \u001b[0;36mcompute_statistic_per_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mComputes a specified statistic for a single xarray dataset.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m- xarray Dataset with the computed statistic.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dimension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compute_temporal_statistic(ds, statistic)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dimension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compute_spatial_statistic(ds, statistic)\n",
      "File \u001b[0;32m/work/ch0636/g300115/phd_project/common/src/data_handling/compute_statistics.py:61\u001b[0m, in \u001b[0;36mcompute_temporal_statistic\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m nor \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m dimension found in the dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Compute the statistic\u001b[39;00m\n\u001b[1;32m     64\u001b[0m stat_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ds, statistic)(dimension, keep_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Neither 'time' nor 'year' dimension found in the dataset"
     ]
    }
   ],
   "source": [
    "# ========= Define period, models and path ==============\n",
    "data_state = 'processed'\n",
    "data_product = 'CMIP6'\n",
    "experiments = ['historical', 'ssp370']\n",
    "temp_res = 'month'\n",
    "models = ['BCC-CSM2-MR', 'CAMS-CSM1-0', 'CESM2-WACCM', 'CNRM-ESM2-1', 'GISS-E2-1-G', 'MIROC-ES2L', 'NorESM2-MM', 'UKESM1-0-LL', 'CanESM5', 'CNRM-CM6-1', 'GFDL-ESM4', 'MPI-ESM1-2-LR', 'TaiESM1']\n",
    "variables=['tas', 'pr', 'vpd', 'evspsbl', 'evapo', 'tran', 'mrro', 'mrso', 'lai', 'gpp', 'wue', 'RX5day', 'gsl'] \n",
    "           \n",
    "# Execute load function with Dask\n",
    "with ProgressBar():\n",
    "    ds_dict = dask.compute(load_dat.load_period_mean(BASE_DIR, data_state, data_product, experiments, models, variables, specific_months_or_seasons=None))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52394aa0-cae2-4bcc-97a3-cfd4d8cec48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3732a8-e00f-402c-9bfe-065c3aa90ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca002a-a11c-4a80-86cf-85ac31eea92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d39fd-03ab-4d87-b629-4f9b57f49ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ab7ca47-05c1-4664-89f2-33cab20a6cbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Subdivide Regions, Compute Mean and Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c3215-7e82-4f74-91cd-6c4553799225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ds_dict_regions = lap.subdivide_region_and_compute_mean(ds_dict, with_global=True, spatial_mean=False) #Only compute spatial mean here if you want to assess a single period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d2102-969b-4901-8e23-9249957091fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_dict_change = lap.compute_change_dict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d0558-8d5a-4ba7-a6f6-470c51e6e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change['ssp370-historical'] = lap.compute_bgws(ds_dict_change['ssp370-historical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db3c1c-c0a6-48b1-8471-49ebd83b761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change_regions_mean = lap.subdivide_region_and_compute_mean(ds_dict_change, with_global=True, spatial_mean=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1edea7-7229-4975-880f-effa5894ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change_regions_mean['ssp370-historical'] = compute_ensemble(ds_dict_change_regions_mean['ssp370-historical'], 'mean')\n",
    "ds_dict_change_regions_mean['ssp370-historical'] = compute_ensemble(ds_dict_change_regions_mean['ssp370-historical'], 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a5a41-845d-4d22-a9b7-af428c5df482",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Compute Subdivisions and Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0a6d9-382d-4822-ad7e-c098615c7d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_with_subdivisions(ds_current, ds_change, variable='bgws'):\n",
    "    # Masks for current dataset\n",
    "    mask_bgws_positive = ds_current[variable] > 0\n",
    "    mask_bgws_negative = ds_current[variable] < 0\n",
    "\n",
    "    # Masks for change dataset\n",
    "    mask_change_positive = ds_change[variable] > 0\n",
    "    mask_change_negative = ds_change[variable] < 0\n",
    "\n",
    "    # Create the subdivision masks\n",
    "    subdivisions_masks = xr.DataArray(\n",
    "        np.array([\n",
    "            mask_bgws_positive & mask_change_negative,\n",
    "            mask_bgws_positive & mask_change_positive,\n",
    "            mask_bgws_negative & mask_change_negative,\n",
    "            mask_bgws_negative & mask_change_positive\n",
    "        ]),\n",
    "        dims=['subdivision', 'lat', 'lon', 'region'],\n",
    "        coords={\n",
    "            'subdivision': [0, 1, 2, 3],\n",
    "            'lat': ds_current.lat,\n",
    "            'lon': ds_current.lon,\n",
    "            'region': ds_current.region\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Expand datasets by broadcasting with subdivision masks\n",
    "    def expand_dataset(ds):\n",
    "        expanded_vars = {}\n",
    "        for name, var in ds.data_vars.items():\n",
    "            # Use the .where() method to mask the data based on the subdivision mask\n",
    "            expanded_var = var.expand_dims({'subdivision': subdivisions_masks['subdivision'].sizes['subdivision']}).where(subdivisions_masks)\n",
    "            expanded_vars[name] = expanded_var\n",
    "        \n",
    "        # Create new dataset with expanded variables\n",
    "        expanded_ds = xr.Dataset(expanded_vars, coords={**ds.coords, 'subdivision': subdivisions_masks['subdivision']})\n",
    "        return expanded_ds\n",
    "\n",
    "    ds_change_expanded = expand_dataset(ds_change)\n",
    "    \n",
    "    ds_change_expanded.attrs = ds_change.attrs\n",
    "\n",
    "    return ds_change_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ef028-60ad-4033-a426-93648910f238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change_subdiv = {}\n",
    "\n",
    "for model, ds in ds_dict_regions_change[list(ds_dict_regions_change.keys())[0]].items():\n",
    "    ds_dict_regions_change_subdiv[model] = expand_with_subdivisions(ds_dict_regions['historical'][model], ds, variable='bgws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccc122-dd5a-4c69-b230-085bac1d83e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a dictionary to hold the mean datasets for each model\n",
    "ds_dict_regional_mean_change_subdiv = {}\n",
    "\n",
    "# Assuming 'ds_dict_regions_change_subdiv' contains your datasets indexed by model names\n",
    "for model, ds in ds_dict_regions_change_subdiv.items():\n",
    "    # Retrieve the total number of regions and subdivisions\n",
    "    num_regions = len(ds.coords['region'])\n",
    "    num_subdivisions = len(ds.coords['subdivision'])\n",
    "    \n",
    "    # Prepare dimensions and coordinates for the new dataset\n",
    "    new_coords = {\n",
    "        'region': ds.coords['region'],\n",
    "        'subdivision': ds.coords['subdivision'],\n",
    "        'abbrevs': ('region', ds.coords['abbrevs'].values),\n",
    "        'names': ('region', ds.coords['names'].values)\n",
    "    }\n",
    "    \n",
    "    # Create a dictionary to store variables with (region, subdivision) dimensions\n",
    "    data_vars = {}\n",
    "\n",
    "    # Loop through each data variable\n",
    "    for var in ds.data_vars:\n",
    "        mean_values = xr.DataArray(\n",
    "            data=np.zeros((num_regions, num_subdivisions)),\n",
    "            dims=['region', 'subdivision'],\n",
    "            coords=new_coords\n",
    "        )\n",
    "\n",
    "        # Loop through each region and subdivision\n",
    "        for region_idx in range(num_regions):\n",
    "            for subdiv_idx in range(num_subdivisions):\n",
    "                # Select data for the current region and subdivision\n",
    "                selected_data = ds[var].isel(region=region_idx, subdivision=subdiv_idx)\n",
    "                \n",
    "                # Compute mean across 'lat' and 'lon' dimensions only\n",
    "                mean_value = selected_data.mean(dim=['lat', 'lon'], skipna=True)\n",
    "                \n",
    "                # Assign the computed mean value to the correct position in the DataArray\n",
    "                mean_values[region_idx, subdiv_idx] = mean_value\n",
    "                \n",
    "        # Copy the attributes from the original variable\n",
    "        mean_values.attrs = ds[var].attrs\n",
    "\n",
    "        # Add the populated DataArray to the data_vars dictionary\n",
    "        data_vars[var] = mean_values\n",
    "\n",
    "    # Create the new dataset with all the variables and coordinates\n",
    "    new_ds = xr.Dataset(data_vars, coords=new_coords)\n",
    "\n",
    "    # Copy all attributes from the original dataset\n",
    "    new_ds.attrs = ds.attrs\n",
    "\n",
    "    # Store the new dataset in the main dictionary\n",
    "    ds_dict_regional_mean_change_subdiv[model] = new_ds\n",
    "\n",
    "# After this loop, ds_dict_regional_mean_change_subdiv will have all the models with their new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fe753-03c8-4ed7-91db-38fab26249ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change_subdiv['BCC-CSM2-MR'].growing_season_length_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f2cca-072c-4a7a-8b96-c372026018ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change_subdiv['BCC-CSM2-MR'].bgws.isel(subdivision=0, region=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabecc0-4852-4f3a-b6c2-e0b43432dcb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Plot regional var change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b3492-d83d-4545-b50a-c509e2d4fd40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if season == None:\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_period', 'bgws']\n",
    "elif season == 'winter':\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_winter', 'bgws']\n",
    "elif season == 'spring':\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_spring', 'bgws']\n",
    "elif season == 'summer':\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_summer', 'bgws']\n",
    "else:\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_fall', 'bgws']\n",
    "print(selected_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd68f6-09c9-46c8-adf3-25f77c8b8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region_change(ddict_change_regions_mean, selected_indices, selected_vars=None, common_scale_for_mm_day=True, legend=True, save_fig=False, subdiv=False):\n",
    "    # Load Colormap\n",
    "    bgws_cm, norm = create_bgws_cm()\n",
    "    \n",
    "    # Get all model names\n",
    "    models = list(ds_dict_change.keys())\n",
    "    \n",
    "    # Get data info\n",
    "    variables, display_variables, experiment_id, description, months, yearly_sum, change_type, region_names = extract_variables(ddict_change_regions_mean, selected_vars)\n",
    "    \n",
    "    # Define regions to plot\n",
    "    selected_indices = ddict_change_regions_mean['Ensemble mean'].region.values.tolist() if selected_indices == \"ALL\" else selected_indices\n",
    "    \n",
    "    # Loop over regions to create single plot for each region\n",
    "    for region_idx in selected_indices:\n",
    "        \n",
    "        if subdiv:\n",
    "            for subdiv_idx in range(ddict_change_regions_mean['Ensemble mean'].dims['subdivision']):\n",
    "                # Create figure and axes\n",
    "                fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "                # Create regional plot\n",
    "                plot_region_subd(fig, axes, models, region_idx, ddict_change_regions_mean, variables, display_variables, change_type, bgws_cm, subdiv_idx, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "                # Add legend and colorbar\n",
    "                if legend:\n",
    "                    add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                if save_fig:\n",
    "                    save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, subdiv_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "                else:\n",
    "                    print('Figure not saved. If you want to save the figure add save_fig=True to the function call')\n",
    "\n",
    "        else:\n",
    "             # Create figure and axes\n",
    "            fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "            # Create regional plot\n",
    "            plot_region(fig, axes, models, region_idx, ddict_change_regions_mean, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "            # Add legend and colorbar\n",
    "            if legend:\n",
    "                add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            if save_fig:\n",
    "                save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "            else:\n",
    "                print('Figure not saved. If you want to save the figure add save_fig=True to the function call')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6033b0-e361-47c6-959b-abc9ca93bc47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region(fig, axes, models, selected_region, ddict_change_regions_mean, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=True):\n",
    "    # Fetch region and subdivision names for the title\n",
    "    region_name = ddict_change_regions_mean[list(ddict_change_regions_mean.keys())[0]].coords['names'].sel(region=selected_region).item()\n",
    "\n",
    "    # Set the overall title for the plot\n",
    "    plot_title = f\"{region_name}\"\n",
    "    fig.suptitle(plot_title, fontsize=32)\n",
    "\n",
    "    # Identify \"mm/day\" variables\n",
    "    mm_day_variables = ['pr', 'mrro', 'evspsbl', 'tran', 'evapo'] \n",
    "\n",
    "    # Calculate global max and min values for each variable across all subdivisions\n",
    "    global_max_min_values = {}\n",
    "    global_mm_max = -np.inf\n",
    "    global_mm_min = np.inf\n",
    "\n",
    "    for var in variables:\n",
    "        global_max = -np.inf\n",
    "        global_min = np.inf\n",
    "        for model_name, ds in ddict_change_regions_mean.items():\n",
    "            if var in ds.data_vars:\n",
    "                selected_data = ds[var].sel(region=selected_region)\n",
    "                if selected_data.size == 1:\n",
    "                    value = selected_data.values.item()\n",
    "                    if not np.isnan(value):\n",
    "                        if var in mm_day_variables:\n",
    "                            global_mm_max = max(global_mm_max, np.abs(value))\n",
    "                            global_mm_min = min(global_mm_min, -np.abs(value))\n",
    "                        global_max = max(global_max, value)\n",
    "                        global_min = min(global_min, value)\n",
    "                else:\n",
    "                    print(f\"Skipping region {selected_region} for model {model_name} and variable {var} due to multiple values or NaNs\")\n",
    "                    continue\n",
    "        global_max_min_values[var] = (global_min, global_max)\n",
    "\n",
    "    # Adjust axes properties and add variable names\n",
    "    for j, var in enumerate(variables):\n",
    "        if var in mm_day_variables and use_common_scale_for_mm_day:\n",
    "            max_abs_value = max(abs(global_mm_min), abs(global_mm_max)) * 1.05\n",
    "        else:\n",
    "            max_abs_value = max(abs(global_max_min_values[var][0]), abs(global_max_min_values[var][1])) * 1.05\n",
    "\n",
    "        if np.isnan(max_abs_value):\n",
    "            continue\n",
    "        \n",
    "        # Calculate ticks\n",
    "        ticks = adjust_array(np.linspace(-max_abs_value, max_abs_value, num=5))\n",
    "        \n",
    "        # Set the y-axis limits to ensure 0 is always in the middle\n",
    "        axes[j].set_ylim(ticks[0], ticks[-1])\n",
    "        axes[j].set_yticks(ticks)\n",
    "        axes[j].spines['left'].set_bounds(ticks[0], ticks[-1]) # Set bounds for left spine\n",
    "        axes[j].tick_params(axis='y', labelsize=18)  # Adjust y-axis tick label size\n",
    "\n",
    "        # Set x-axis ticks and labels with improved formatting\n",
    "        axes[j].set_xlim(j - 1, j + 1)\n",
    "        axes[j].set_xticks([j])\n",
    "        axes[j].spines['top'].set_visible(False)\n",
    "        axes[j].spines['bottom'].set_visible(False)\n",
    "        axes[j].spines['right'].set_visible(False)\n",
    "        axes[j].set_xticklabels([display_variables[var]], fontdict={'size': 25})\n",
    "        axes[j].tick_params(axis='x', length=10, color='white')  # Adjust x-axis tick label size\n",
    "        \n",
    "        # Add horizontal line at y=0\n",
    "        axes[j].axhline(y=0, color='gray', linestyle='-', linewidth=1)  \n",
    "\n",
    "        # Coloring every second subplot's background\n",
    "        if j % 2 == 0:  # This checks if the index is odd, applying the color to every second subplot\n",
    "            axes[j].set_facecolor('#f0f0f0')  # Light gray background\n",
    "\n",
    "        if j == 0:\n",
    "            # This is the first subplot, so add a y-axis label here\n",
    "            axes[j].set_ylabel(\"End-of-century response\", fontsize=25)\n",
    "    \n",
    "        # Improved tick label formatting to remove unnecessary trailing zeros\n",
    "        if j > 0:  # Check if not the first axis\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' and tick != 0 else '' for tick in ticks])\n",
    "            ticks = axes[j].yaxis.get_major_ticks() \n",
    "            # Modify properties of the first tick\n",
    "            tick_to_modify = 2  # Index of the tick to modify\n",
    "            ticks[tick_to_modify].tick1line.set_markersize(50)\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgecolor('gray')\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgewidth(1)\n",
    "\n",
    "        else:\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' else f'{tick:.2f}' for tick in ticks])\n",
    "\n",
    "    # Set up fixed normalization range from -50 to 50\n",
    "    norm = Normalize(vmin=-50, vmax=50)\n",
    "    \n",
    "    # Iterate over models and variables to plot\n",
    "    for i, model_name in enumerate(models, start=1):\n",
    "        ds = ddict_change_regions_mean[model_name]  # Get the dataset for the current model\n",
    "        prev_xy = None\n",
    "\n",
    "        for j, variable in enumerate(variables):\n",
    "            if variable in ds.data_vars:\n",
    "                value = ds[variable].sel(region=selected_region).values.item()\n",
    "                bgws_value = ds['bgws'].sel(region=selected_region).values.item()\n",
    "                \n",
    "                # Normalize bgws value for color mapping\n",
    "                color = bgws_cm(norm(bgws_value))\n",
    "\n",
    "                current_xy = (j, value)\n",
    "                \n",
    "                if np.isnan(value):\n",
    "                    prev_xy = None\n",
    "                    continue\n",
    "\n",
    "                if model_name.lower() == \"ensemble mean\":\n",
    "                    axes[j].plot(j, value, 'D', mec='red', mfc='none', markersize=22, mew=2, zorder=5)\n",
    "                elif model_name.lower() == \"ensemble median\":\n",
    "                    axes[j].plot(j, value, 'o', mec='orange', mfc='none', markersize=28, mew=2, zorder=4)\n",
    "                else:\n",
    "                    if j % 2 == 0:\n",
    "                        dot_color = '#f0f0f0'\n",
    "                    else: \n",
    "                        dot_color = 'white'\n",
    "                    axes[j].plot(j, value, 'o', color=dot_color, markersize=38, zorder=1)\n",
    "                    axes[j].annotate(str(i), xy=current_xy, xytext=(0, 0), textcoords='offset points',\n",
    "                                     fontsize=38, weight='bold', color=color,\n",
    "                                     ha='center', va='center', zorder=2)\n",
    "\n",
    "                if prev_xy is not None:\n",
    "                    linestyle = '--' if bgws_value < 0 else '-'\n",
    "                    con = ConnectionPatch(xyA=prev_xy, xyB=current_xy, coordsA=\"data\", coordsB=\"data\",\n",
    "                                          axesA=axes[j-1], axesB=axes[j],\n",
    "                                          linestyle=linestyle, shrinkA=17, shrinkB=17, color=color, linewidth=2)  \n",
    "                    fig.add_artist(con)\n",
    "\n",
    "                prev_xy = current_xy\n",
    "            else:\n",
    "                prev_xy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ba7f7-6c3e-4694-aefb-68cbc2ca4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].pr.isel(region=18).values.item()\n",
    "print(f'Precipitation change: {dpr}')\n",
    "dmrro = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].mrro.isel(region=18).values.item()\n",
    "print(f'Runoff change: {dmrro}')\n",
    "dtran = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].tran.isel(region=18).values.item()\n",
    "print(f'Transpiration change: {dtran}')\n",
    "dbgws = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].bgws.isel(region=18).values.item()\n",
    "print(f'delta BGWS: {dbgws}')\n",
    "#Compute BGWS change based on variables\n",
    "bgws_d = ((dmrro - dtran)/dpr) * 100\n",
    "print(f'BGWS_delta: {dbgws}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe38c05-9465-4807-b06a-74a8f96b42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_change(ds_dict_change_regions_mean['ssp370-historical'], \n",
    "                   selected_indices=[18] , # 'ALL' \n",
    "                   selected_vars=selected_variables, \n",
    "                   common_scale_for_mm_day=True,\n",
    "                   legend=False,\n",
    "                   save_fig=False,\n",
    "                   subdiv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55faa03-4294-41a8-9eb4-3c47be6b1f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region_subd(fig, axes, models, selected_region, ds_dict_change, variables, display_variables, change_type, bgws_cm, subdiv_idx, use_common_scale_for_mm_day=True):\n",
    "    # Fetch region and subdivision names for the title\n",
    "    region_name = ds_dict_change[list(ds_dict_change.keys())[0]].coords['names'].sel(region=selected_region).item()\n",
    "    subdivision_name = str(ds_dict_change[list(ds_dict_change.keys())[0]].coords['subdivision'][subdiv_idx].item())\n",
    "\n",
    "    # Set the overall title for the plot\n",
    "    plot_title = f\"{region_name} - Subdivision {subdivision_name}\"\n",
    "    fig.suptitle(plot_title, fontsize=32)\n",
    "\n",
    "    # Identify \"mm/day\" variables\n",
    "    mm_day_variables = ['pr', 'mrro', 'evspsbl', 'tran', 'evapo'] \n",
    "\n",
    "    # Calculate global max and min values for each variable across all subdivisions\n",
    "    global_max_min_values = {}\n",
    "    for var in variables:\n",
    "        global_max = -np.inf\n",
    "        global_min = np.inf\n",
    "        for model_name, ds in ds_dict_change.items():\n",
    "            for subdiv in ds.coords['subdivision']:\n",
    "                if var in ds.data_vars:\n",
    "                    value = ds[var].sel(region=selected_region, subdivision=subdiv).values.item()\n",
    "                    if not np.isnan(value):\n",
    "                        if use_common_scale_for_mm_day and var in mm_day_variables:\n",
    "                            global_max = max(global_max, np.abs(value))\n",
    "                            global_min = min(global_min, -np.abs(value))\n",
    "                        else:\n",
    "                            global_max = max(global_max, value)\n",
    "                            global_min = min(global_min, value)\n",
    "        if use_common_scale_for_mm_day and var in mm_day_variables:\n",
    "            global_max_min_values[var] = (global_min, global_max)\n",
    "        else:\n",
    "            global_max_min_values[var] = (global_min, global_max)\n",
    "\n",
    "    # Adjust axes properties and add variable names\n",
    "    for j, var in enumerate(variables):\n",
    "        # Calculate the maximum absolute value for the variable\n",
    "        if var in global_max_min_values:\n",
    "            max_abs_value = max(abs(global_max_min_values[var][0]), abs(global_max_min_values[var][1])) * 1.05\n",
    "        else:\n",
    "            max_abs_value = 0\n",
    "        \n",
    "        # Calculate ticks\n",
    "        ticks = adjust_array(np.linspace(-max_abs_value, max_abs_value, num=5))\n",
    "        \n",
    "        # Set the y-axis limits to ensure 0 is always in the middle\n",
    "        axes[j].set_ylim(ticks[0], ticks[-1])\n",
    "        axes[j].set_yticks(ticks)\n",
    "        axes[j].spines['left'].set_bounds(ticks[0], ticks[-1]) # Set bounds for left spine\n",
    "        axes[j].tick_params(axis='y', labelsize=18)  # Adjust y-axis tick label size\n",
    "\n",
    "        # Set x-axis ticks and labels with improved formatting\n",
    "        axes[j].set_xlim(j - 1, j + 1)\n",
    "        axes[j].set_xticks([j])\n",
    "        axes[j].spines['top'].set_visible(False)\n",
    "        axes[j].spines['bottom'].set_visible(False)\n",
    "        axes[j].spines['right'].set_visible(False)\n",
    "        axes[j].set_xticklabels([display_variables[var]], fontdict={'size': 25})\n",
    "        axes[j].tick_params(axis='x', length=10, color='white')  # Adjust x-axis tick label size\n",
    "        \n",
    "        # Add horizontal line at y=0\n",
    "        axes[j].axhline(y=0, color='gray', linestyle='-', linewidth=1)  \n",
    "\n",
    "        # Coloring every second subplot's background\n",
    "        if j % 2 == 0:  # This checks if the index is odd, applying the color to every second subplot\n",
    "            axes[j].set_facecolor('#f0f0f0')  # Light gray background\n",
    "\n",
    "        if j == 0:\n",
    "            # This is the first subplot, so add a y-axis label here\n",
    "            axes[j].set_ylabel(\"End-of-century response\", fontsize=25)\n",
    "    \n",
    "        # Improved tick label formatting to remove unnecessary trailing zeros\n",
    "        if j > 0:  # Check if not the first axis\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' and tick != 0 else '' for tick in ticks])\n",
    "            ticks = axes[j].yaxis.get_major_ticks() \n",
    "            # Modify properties of the first tick\n",
    "            tick_to_modify = 2  # Index of the tick to modify\n",
    "            ticks[tick_to_modify].tick1line.set_markersize(50)\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgecolor('gray')\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgewidth(1)\n",
    "\n",
    "        else:\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' else f'{tick:.2f}' for tick in ticks])\n",
    "    \n",
    "    # Iterate over models and variables to plot\n",
    "    for i, model_name in enumerate(models, start=1):\n",
    "        ds = ds_dict_change[model_name]  # Get the dataset for the current model\n",
    "        prev_xy = None\n",
    "\n",
    "        for j, variable in enumerate(variables):\n",
    "            if variable in ds.data_vars:\n",
    "                value = ds[variable].sel(region=selected_region, subdivision=subdiv_idx).values.item()\n",
    "                bgws_value = ds['bgws'].sel(region=selected_region, subdivision=subdiv_idx).values.item()\n",
    "                \n",
    "                # Normalize bgws value for color mapping\n",
    "                color = bgws_cm((bgws_value - -0.1) / (0.1 - -0.1))\n",
    "\n",
    "                current_xy = (j, value)\n",
    "                \n",
    "                if np.isnan(value):\n",
    "                    prev_xy = None\n",
    "                    continue\n",
    "\n",
    "                if model_name.lower() == \"ensemble mean\":\n",
    "                    axes[j].plot(j, value, 'D', mec='red', mfc='none', markersize=22, mew=2, zorder=5)\n",
    "                elif model_name.lower() == \"ensemble median\":\n",
    "                    axes[j].plot(j, value, 'o', mec='orange', mfc='none', markersize=28, mew=2, zorder=4)\n",
    "                else:\n",
    "                    if j % 2 == 0:\n",
    "                        dot_color = '#f0f0f0'\n",
    "                    else: \n",
    "                        dot_color = 'white'\n",
    "                    axes[j].plot(j, value, 'o', color=dot_color, markersize=38, zorder=1)\n",
    "                    axes[j].annotate(str(i), xy=current_xy, xytext=(0, 0), textcoords='offset points',\n",
    "                                     fontsize=38, weight='bold', color=color,\n",
    "                                     ha='center', va='center', zorder=2)\n",
    "\n",
    "                if prev_xy is not None:\n",
    "                    linestyle = '--' if bgws_value < 0 else '-'\n",
    "                    con = ConnectionPatch(xyA=prev_xy, xyB=current_xy, coordsA=\"data\", coordsB=\"data\",\n",
    "                                          axesA=axes[j-1], axesB=axes[j],\n",
    "                                          linestyle=linestyle, shrinkA=17, shrinkB=17, color=color, linewidth=2)  \n",
    "                    fig.add_artist(con)\n",
    "\n",
    "                prev_xy = current_xy\n",
    "            else:\n",
    "                prev_xy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222fb72-a624-4353-a369-03f176ef19a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_region_change(ds_dict_regional_mean_change_subdiv, \n",
    "                   selected_indices='ALL', \n",
    "                   selected_vars=selected_variables, \n",
    "                   common_scale_for_mm_day=False,\n",
    "                   legend=False,\n",
    "                   save_fig=True,\n",
    "                   subdiv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185b456-4d55-4c13-b912-cf5b504af7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_change(ds_dict_regions_change[list(ds_dict_regions_change.keys())[0]], \n",
    "                   selected_indices='ALL', \n",
    "                   selected_vars=selected_variables, \n",
    "                   common_scale_for_mm_day=False,\n",
    "                   legend=False,\n",
    "                   save_fig=False,\n",
    "                   subdiv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961ddef-9abc-4057-8e59-728a112bf921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes:\n",
    "# Legend smaller, units and x-axis in generak bigger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
