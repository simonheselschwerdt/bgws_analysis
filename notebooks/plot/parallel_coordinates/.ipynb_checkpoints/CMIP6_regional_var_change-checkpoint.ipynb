{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7716ffb9-a564-44c7-87d4-2d4caeecdb1c",
   "metadata": {},
   "source": [
    "# CMIP6 Regional variable change\n",
    "\n",
    "**Following steps are included in this script:**\n",
    "\n",
    "1. Load netCDF files\n",
    "2. Compute regional variable change\n",
    "3. Plot change in reional parallel coordinate plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5a4f3-40bb-459a-88f0-f180c8b3ee8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854af429-43a1-489d-8513-dca8c1466663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import glob\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import copy\n",
    "import numpy as np\n",
    "import regionmask\n",
    "import math\n",
    "import cftime\n",
    "#import load_and_preprocess as lap \n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "plt.rcParams['text.usetex'] = False\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath, amssymb, textcomp}'\n",
    "\n",
    "# For color map\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74a0a3e-e91c-49cb-85f2-5990ea120f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check all possible fonts\n",
    "import matplotlib.font_manager\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def make_html(fontname):\n",
    "    return \"<p>{font}: <span style='font-family:{font}; font-size: 24px;'>{font}</p>\".format(font=fontname)\n",
    "\n",
    "code = \"\\n\".join([make_html(font) for font in sorted(set([f.name for f in matplotlib.font_manager.fontManager.ttflist]))])\n",
    "\n",
    "# Set the font\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Nimbus Sans\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5daa16-4811-4773-b98d-6b69626ff6cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9148cef-f033-40ac-aeef-dec5ccdb277d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2. Subdivide Regions, Compute Mean and Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268d2c5-9778-48af-84ac-bfc2f93f8cbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f9e86-913e-4102-a26f-57f363dbdd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subdivide_region_and_compute_mean(ds_dict):\n",
    "    \n",
    "    ds_dict_regions = {}\n",
    "    \n",
    "    for scenario_name, scenario_dict in ds_dict.items():\n",
    "        ds_dict_regions[scenario_name] = apply_region_mask(scenario_dict, with_global=True)\n",
    "        ds_dict_regions[scenario_name] = calculate_spatial_mean( ds_dict_regions[scenario_name])\n",
    "   \n",
    "    return ds_dict_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad6a9f-173b-4e5b-b5b3-f7706018c916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_change_dict(ds_dict):\n",
    "    \"\"\"\n",
    "    Create a new dictionary that saves the changes of the scenarios to the historical period\n",
    "    for each model.\n",
    "\n",
    "    Parameters:\n",
    "    - ds_dict: Dictionary containing datasets for all scenarios and models, structured as ds_dict[scenario][model].\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with keys formatted as 'historical-<scenario>' for each scenario change\n",
    "      and each key containing a model-wise dictionary of changes.\n",
    "    \"\"\"\n",
    "    ds_dict_change = {}\n",
    "    scenarios = list(ds_dict.keys())\n",
    "    historical = scenarios[0]  # Assuming the first scenario is always 'historical'\n",
    "\n",
    "    # Iterate through scenarios (skipping the first 'historical' scenario)\n",
    "    for scenario in scenarios[1:]:\n",
    "        change_key = f'historical-{scenario}'\n",
    "        ds_dict_change[change_key] = {}\n",
    "\n",
    "        ds_base = ds_dict[historical]\n",
    "        ds_future = ds_dict[scenario]\n",
    "        ds_change = compute_change(ds_base, ds_future)\n",
    "\n",
    "        # Drop 'member_id' if present\n",
    "        if 'member_id' in ds_change:\n",
    "            ds_change = ds_change.drop('member_id')\n",
    "\n",
    "        ds_dict_change[change_key] = ds_change\n",
    "    \n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357aa01f-6265-42ef-a84f-cef6e4800e0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Apply region mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be2be2-e852-431d-a623-4ac7bc4ea92f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_region_mask(ds_dict, with_global=False):\n",
    "    \"\"\"\n",
    "    Applies the AR6 land region mask to datasets in the provided dictionary, adds a region dimension,\n",
    "    and optionally includes a 'Global' aggregation.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets.\n",
    "        with_global (bool): If True, includes a 'Global' region with aggregated data.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary where keys are the same as in the input dictionary,\n",
    "              and each value is an xarray Dataset with a region dimension added to each variable,\n",
    "              and optionally includes a 'Global' region.\n",
    "    \"\"\"\n",
    "\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    \n",
    "    if with_global:\n",
    "        global_mask = regionmask.defined_regions.natural_earth_v5_0_0.land_110\n",
    "    \n",
    "    ds_masked_dict = {}\n",
    "\n",
    "    for ds_name, ds in ds_dict.items():\n",
    "        ds_masked = xr.Dataset()  # Initiate an empty Dataset for the masked data\n",
    "        \n",
    "        # Get attributes\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        for var in ds:\n",
    "            # Get the binary mask\n",
    "            mask = land_regions.mask_3D(ds[var])\n",
    "            \n",
    "            var_attrs = ds[var].attrs\n",
    "\n",
    "            # Multiply the original data with the mask to get the masked data\n",
    "            masked_var = ds[var] * mask\n",
    "\n",
    "            # Replace 0s with NaNs, if desired\n",
    "            masked_var = masked_var.where(masked_var != 0)\n",
    "\n",
    "            if with_global:\n",
    "                # Convert the global mask to 3D to match the regional mask dimensions\n",
    "                glob_mask = global_mask.mask_3D(ds[var])\n",
    "                \n",
    "                global_masked_var = ds[var] * glob_mask\n",
    "                \n",
    "                # Replace 0s with NaNs, if desired\n",
    "                global_masked_var = global_masked_var.where(global_masked_var != 0)\n",
    "\n",
    "                # Combine masked data\n",
    "                masked_var = xr.concat([masked_var, global_masked_var], dim='region')\n",
    "                \n",
    "            # Add the masked variable to the output Dataset\n",
    "            ds_masked[var] = masked_var\n",
    "\n",
    "            ds_masked[var].attrs = var_attrs\n",
    "\n",
    "        # Copy dataset attributes\n",
    "        ds_masked.attrs.update(ds.attrs)\n",
    "        \n",
    "        correct_region_numbers = np.arange(0, ds_masked.dims['region'])\n",
    "\n",
    "        ds_masked = ds_masked.assign_coords(region=correct_region_numbers)\n",
    "\n",
    "        # Add the modified dataset to the dictionary\n",
    "        ds_masked_dict[ds_name] = ds_masked\n",
    "\n",
    "    return ds_masked_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d657f-da46-42ee-9e60-2076bc0dcac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Calculate spatial mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b71e4e-b89b-4169-bac4-97f010c2f2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_spatial_mean(ds_dict):\n",
    "    ds_dict_mean = {}\n",
    "    \n",
    "    for key, ds in ds_dict.items():\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        # Initialize a new Dataset for this key\n",
    "        ds_dict_mean[key] = xr.Dataset()\n",
    "        \n",
    "        for var in list(ds.data_vars.keys()):\n",
    "            var_attrs = ds[var].attrs\n",
    "            \n",
    "            ds_dict_mean[key][var] = ds[var].mean(['lon', 'lat'])\n",
    "            ds_dict_mean[key][var].attrs = var_attrs\n",
    "        \n",
    "        ds_dict_mean[key].attrs = attrs\n",
    "        \n",
    "    return ds_dict_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5296d5-cb89-4a8d-b11e-e15e9ee0e06b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compute Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fedf68-0e05-43a4-a705-ba2e9b163a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_numeric(data):\n",
    "    try:\n",
    "        _ = data.astype(float)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def compute_change(ds_dict_hist, ds_dict_fut, var_rel_change=None):\n",
    "    ds_dict_change = {}\n",
    "\n",
    "    for name, ds_hist in ds_dict_hist.items():\n",
    "        if name in ds_dict_fut:\n",
    "            ds_future = ds_dict_fut[name]\n",
    "            common_vars = set(ds_hist.data_vars).intersection(ds_future.data_vars)\n",
    "\n",
    "            ds_change = ds_hist.copy(deep=True)\n",
    "            \n",
    "            if var_rel_change == 'all':\n",
    "                var_rel_change = common_vars\n",
    "                \n",
    "            for var in common_vars:\n",
    "                if is_numeric(ds_hist[var].data) and is_numeric(ds_future[var].data):\n",
    "                    # Always compute percentage change for 'mrso' as models have different depths\n",
    "                    if var == 'mrso':\n",
    "                        rel_change = (ds_future[var] - ds_hist[var]) / ds_hist[var].where(ds_hist[var] != 0) * 100\n",
    "                        ds_change[var].data = rel_change.data\n",
    "                        ds_change[var].attrs['units'] = '%'\n",
    "                    elif var_rel_change is not None and var in var_rel_change:\n",
    "                        # Compute relative change where ds_hist is not zero for specified variables\n",
    "                        rel_change = (ds_future[var] - ds_hist[var]) / ds_hist[var].where(ds_hist[var] != 0) * 100\n",
    "                        ds_change[var].data = rel_change.data\n",
    "                        ds_change[var].attrs['units'] = '%'\n",
    "                    else:\n",
    "                        # Compute absolute change for other variables\n",
    "                        abs_change = ds_future[var] - ds_hist[var]\n",
    "                        ds_change[var].data = abs_change.data\n",
    "\n",
    "            ds_change.attrs = ds_future.attrs\n",
    "            ds_dict_change[name] = ds_change\n",
    "\n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665eaeb-bb57-40e9-9292-ff5fad55aed7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Plot Variable Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9239dd6-1a3f-4a34-ae8c-da76464f4b90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Main plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c46f3-7bf2-4c5d-920d-f4032657dde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region_change(ds_dict_change, selected_indices, selected_vars=None, common_scale_for_mm_day=True, legend=True, save_fig=False, subdiv=False):\n",
    "    # Load Colormap\n",
    "    bgws_cm, norm = create_bgws_cm()\n",
    "    \n",
    "    # Compute Ensemble statisitc\n",
    "    ds_dict_change = compute_ensemble(ds_dict_change, 'mean')\n",
    "    ds_dict_change = compute_ensemble(ds_dict_change, 'median')\n",
    "    \n",
    "    # Get all model names\n",
    "    models = list(ds_dict_change.keys())\n",
    "    \n",
    "    # Get data info\n",
    "    variables, display_variables, experiment_id, description, months, yearly_sum, change_type, region_names = extract_variables(ds_dict_change, selected_vars)\n",
    "    \n",
    "    # Define regions to plot\n",
    "    selected_indices = ds_dict_change['Ensemble mean'].region.values.tolist() if selected_indices == \"ALL\" else selected_indices\n",
    "    \n",
    "    # Loop over regions to create single plot for each region\n",
    "    for region_idx in selected_indices:\n",
    "        \n",
    "        if subdiv:\n",
    "            for subdiv_idx in range(ds_dict_change['Ensemble mean'].dims['subdivision']):\n",
    "                print(subdiv_idx)\n",
    "                # Create figure and axes\n",
    "                fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "                # Create regional plot\n",
    "                plot_region(fig, axes, models, region_idx, ds_dict_change, variables, display_variables, change_type, bgws_cm, subdiv_idx, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "                # Add legend and colorbar\n",
    "                if legend:\n",
    "                    add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                if save_fig:\n",
    "                    save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, subdiv_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "                else:\n",
    "                    print('Figure not saved. If you want to save the figure add save_fig=True to the function call')\n",
    "\n",
    "        else:\n",
    "             # Create figure and axes\n",
    "            fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "            # Create regional plot\n",
    "            plot_region(fig, axes, models, region_idx, ds_dict_change, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "            # Add legend and colorbar\n",
    "            if legend:\n",
    "                add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            if save_fig:\n",
    "                save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "            else:\n",
    "                print('Figure not saved. If you want to save the figure add save_fig=True to the function call')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ff7c9-44b6-4d4a-a0d6-19c0ce25bebe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create Colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877ac72-13bb-4833-bcc1-cb249a86583b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_bgws_cm():\n",
    "    # Define start and end colors for both gradients\n",
    "    deep_blue = (20/255, 110/255, 180/255)\n",
    "    light_blue = (180/255, 215/255, 255/255)\n",
    "    deep_green = (14/255, 119/255, 14/255)\n",
    "    light_green = (160/255, 220/255, 140/255)\n",
    "\n",
    "    # Create custom colormaps\n",
    "    blue_cmap = LinearSegmentedColormap.from_list(\"blue_cmap\", [light_blue, deep_blue], N=4)\n",
    "    green_cmap = LinearSegmentedColormap.from_list(\"green_cmap\", [deep_green, light_green], N=4)\n",
    "\n",
    "    # Sample colors from colormaps\n",
    "    blue_colors = [blue_cmap(i) for i in np.linspace(0, 1, 4)]\n",
    "    green_colors = [green_cmap(i) for i in np.linspace(0, 1, 4)]\n",
    "\n",
    "    # Combine both gradients\n",
    "    combined_grad = green_colors + blue_colors\n",
    "\n",
    "    # Define boundaries\n",
    "    boundaries = sorted([-0.1, -0.075, -0.05, -0.025, 0, 0.025, 0.05, 0.075, 0.1])\n",
    "    norm = BoundaryNorm(boundaries, len(combined_grad), clip=True)\n",
    "\n",
    "    cmap_name = 'BGWS colormap'\n",
    "    bgws_cm = LinearSegmentedColormap.from_list(cmap_name, combined_grad, N=len(combined_grad))\n",
    "\n",
    "    # Return the colormap and norm\n",
    "    return bgws_cm, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48efa96-946e-44de-a57b-683c668e6e36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Get Data Info for Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcba1a-0d52-4c81-928b-0b6d16b67f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_change_type(ds_dict):\n",
    "    \"\"\"\n",
    "    Determines the type of change (relative or absolute) based on the units of the first \n",
    "    variable found in the provided dataset dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    - ds_dict: A dictionary structured as ds_dict[scenario][model] containing xarray Dataset or DataArray objects.\n",
    "    \n",
    "    Returns:\n",
    "    - A string indicating the type of change: 'rel_change' for relative change (units in '%'), \n",
    "      otherwise 'abs_change' for absolute change.\n",
    "    \"\"\"\n",
    "    # Attempt to retrieve the first dataset from the dictionary\n",
    "    try:\n",
    "        first_scenario = list(ds_dict.keys())[0]\n",
    "        first_model = list(ds_dict[first_scenario].keys())[0]\n",
    "        first_dataset = ds_dict[first_scenario][first_model]\n",
    "        \n",
    "        # Depending on the structure, handle both Dataset and DataArray cases\n",
    "        if isinstance(first_dataset, xr.Dataset):\n",
    "            # For Dataset, find the first data variable\n",
    "            first_var_name = list(first_dataset.data_vars)[0]\n",
    "            units = first_dataset[first_var_name].attrs.get('units', '')\n",
    "        elif isinstance(first_dataset, xr.DataArray):\n",
    "            # For DataArray, directly access its units attribute\n",
    "            units = first_dataset.attrs.get('units', '')\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected data structure. Expected xarray Dataset or DataArray.\")\n",
    "        \n",
    "        # Determine change type based on units\n",
    "        return 'rel_change' if units == '%' else 'abs_change'\n",
    "    except Exception as e:\n",
    "        print(f\"Error determining change type: {e}\")\n",
    "        return 'abs_change'  # Default to 'abs_change' in case of error or unexpected data structure\n",
    "\n",
    "def prepare_display_variables(variables):\n",
    "    var_map = {\n",
    "        'tas': ('T', 'Â°C'),\n",
    "        'vpd': ('VPD', 'hPa'),\n",
    "        'gpp': ('GPP', r'\\frac{\\frac{gC}{m^2}}{day}'),  \n",
    "        'pr': ('P', r'\\frac{mm}{day}'),\n",
    "        'mrro': ('R', r'\\frac{mm}{day}'),\n",
    "        'evspsbl': ('ET', r'\\frac{mm}{day}'),\n",
    "        'tran': ('Tran', r'\\frac{mm}{day}'),\n",
    "        'evapo': ('E', r'\\frac{mm}{day}'),\n",
    "        'lai': ('Lai', r'\\frac{m^2}{m^2}'),\n",
    "        'mrso': ('SM', '\\%'),\n",
    "        'rgtr': ('P/T', r'\\frac{GPP}{T}'),\n",
    "        'et_partitioning': ('EP', r'\\frac{E-Tran}{ET}'),\n",
    "        'growing_season_length_period': ('GSL', 'months'),\n",
    "        'RX5day': ('RX5d', 'mm'),\n",
    "        'growing_season_length_winter': ('GSL', 'months'),\n",
    "        'growing_season_length_summer': ('GSL', 'months'),\n",
    "        'growing_season_length_fall': ('GSL', 'months'),\n",
    "        'growing_season_length_spring': ('GSL', 'months'),\n",
    "        'wue': ('WUE', r'\\frac{GPP}{Tran}'),\n",
    "        'bgws': ('BGWS', r'\\frac{R-T}{P}')\n",
    "    }\n",
    "    display_variables = {}\n",
    "    for var in variables:\n",
    "        if var in var_map:\n",
    "            abbreviation, units = var_map[var]\n",
    "            # Enclose units in \\left[ and \\right] for automatic sizing\n",
    "            display_variables[var] = f\"${{\\Delta\\, \\mathrm{{\\it{{{abbreviation}}}}}}}$ \\n $\\\\left[{units}\\\\right]$\"\n",
    "        else:\n",
    "            print(f\"Variable '{var}' not found in var_map.\")\n",
    "            display_variables[var] = var  # Or handle this case as appropriate\n",
    "    return display_variables\n",
    "\n",
    "\n",
    "def extract_variables(ds_dict, selected_vars):\n",
    "    ensemble = ds_dict['Ensemble mean']\n",
    "    variables = [var for var in ensemble.data_vars.keys() if var not in ['bgws', 'region', 'abbrevs', 'names', 'member_id']] if selected_vars is None else [var for var in selected_vars if var in ensemble.data_vars.keys()]\n",
    "    experiment_id = ds_dict[list(ds_dict.keys())[0]].experiment_id\n",
    "    description = ds_dict[list(ds_dict.keys())[0]].description\n",
    "    months = ds_dict[list(ds_dict.keys())[0]].months\n",
    "    yearly_sum = ds_dict[list(ds_dict.keys())[0]].yearly_sum\n",
    "    display_variables = prepare_display_variables(variables)\n",
    "    change_type = determine_change_type(ds_dict)\n",
    "    region_names = ds_dict[list(ds_dict.keys())[0]].names\n",
    "    return variables, display_variables, experiment_id, description, months, yearly_sum, change_type, region_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5fa8bd-aecb-4bd6-ba26-df1da36464d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compute ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc9c41-e70b-40da-802d-c4fcb0bc4eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_ensemble(ds_dict_change, statistic):\n",
    "    \n",
    "    # Drop previously computed ensemble statistics\n",
    "    for key in [f'Ensemble {statistic}']:\n",
    "        if key in ds_dict_change:\n",
    "            ds_dict_change.pop(key)\n",
    "    \n",
    "    # Get attrs of the variables\n",
    "    var_attrs = {}\n",
    "    for var in ds_dict_change[list(ds_dict_change.keys())[0]].data_vars:\n",
    "        var_attrs[var] = ds_dict_change[list(ds_dict_change.keys())[0]][var].attrs\n",
    "            \n",
    "    \n",
    "    # Coompute ensemble mean\n",
    "    combined = xr.concat(ds_dict_change.values(), dim='ensemble')\n",
    "    ds_dict_change[f'Ensemble {statistic}'] = getattr(combined, statistic)(dim='ensemble')\n",
    "    \n",
    "    \n",
    "    # Add variable attrs\n",
    "    for var in ds_dict_change[f'Ensemble {statistic}'].data_vars:\n",
    "        ds_dict_change[f'Ensemble {statistic}'][var].attrs = var_attrs[var] \n",
    "        \n",
    "    ssp = ds_dict_change[list(ds_dict_change.keys())[0]].experiment_id\n",
    "    \n",
    "    # Add ensemble attr\n",
    "    ds_dict_change[f'Ensemble {statistic}'].attrs = {'experiment_id': f'{ssp}-historical',\n",
    "                                                    'source_id': f'Ensemble {statistic}',\n",
    "                                                    'months': 'whole_year',\n",
    "                                                    'yearly_sum': 'monthly_mean',\n",
    "                                                    }\n",
    "            \n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47817e6-23bc-4bda-8451-cd928e57bfd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Legend and colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cffa0-9150-4827-9abf-b9dc3125b30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_legend_and_colorbar(fig, ax, models, norm, bgws_cm, description, region_names, selected_region):\n",
    "    # Caption and figure saving\n",
    "    region_name = region_names.isel(region=selected_region).item()\n",
    "    caption = region_name\n",
    "    fig.text(0.6, 0.93, caption, ha='center', va='top', fontsize=22, wrap=True)\n",
    "    \n",
    "    # Layout adjustments\n",
    "    #plt.subplots_adjust(wspace=1, hspace=0.7)\n",
    "    \n",
    "    # Upper Legend (Ensemble mean, median, and line styles)\n",
    "    upper_legend_position = [0.975, 0.61, 0.1, 0.125]  # Adjust position as needed\n",
    "    upper_legend_ax = fig.add_axes(upper_legend_position, frame_on=False)\n",
    "    upper_legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='D', markeredgecolor='red', markerfacecolor='none', label='Ensemble mean', markersize=10, linestyle='None', lw=2),\n",
    "        plt.Line2D([0], [0], marker='o', mec='orange', mfc='none', label='Ensemble median', markersize=14, linestyle='None', mew=2),\n",
    "        plt.Line2D([0], [0], color='black', label='+ $\\Delta$ BGWS', linestyle='-', linewidth=2),\n",
    "        plt.Line2D([0], [0], color='black', label='- $\\Delta$ BGWS', linestyle='--', linewidth=2)  \n",
    "    ]\n",
    "    upper_legend = upper_legend_ax.legend(handles=upper_legend_elements, fontsize=18, loc='center', ncol=2,\n",
    "                                          columnspacing=1, handletextpad=0.5, borderaxespad=0.5)\n",
    "    upper_legend_ax.axis('off')\n",
    "    upper_legend.get_frame().set_facecolor('none')\n",
    "    upper_legend.get_frame().set_edgecolor('none')\n",
    "    \n",
    "    # Define starting position and spacing for the model name annotations\n",
    "    start_x = 0.92  # Right side of the figure; adjust as needed\n",
    "    start_y = 0.597  # Starting height; adjust as needed\n",
    "    spacing_y = 0.0315  # Vertical spacing between model names; adjust as needed\n",
    "    num_columns = 2  # Number of columns for model names\n",
    "    column_width = 0.117  # Horizontal space between columns\n",
    "\n",
    "    # Filter out the ensemble mean and median for the model names annotation\n",
    "    model_names = [model for model in models if model not in [\"Ensemble mean\", \"Ensemble median\"]]\n",
    "\n",
    "    # Calculate how many names per column\n",
    "    names_per_column = len(model_names) // num_columns + (len(model_names) % num_columns > 0)\n",
    "\n",
    "    # Loop through the model names to place them as text annotations\n",
    "    for idx, model_name in enumerate(model_names):\n",
    "        column = idx // names_per_column\n",
    "        row = idx % names_per_column\n",
    "        x_position = start_x + column * column_width  # Adjust x based on column\n",
    "        y_position = start_y - row * spacing_y  # Adjust y based on row\n",
    "\n",
    "        # Place text annotation\n",
    "        fig.text(x_position, y_position, f\"{idx + 1}: {model_name}\", fontsize=18, transform=fig.transFigure, ha='left', va='top')\n",
    " \n",
    "    # Add the colorbar below the lower legend\n",
    "    colorbar_position = [0.92, 0.3, 0.2, 0.03]  # right, up, length, width\n",
    "    cbar_ax = fig.add_axes(colorbar_position)\n",
    "    cbar = fig.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=bgws_cm), cax=cbar_ax, orientation='horizontal', extend='both')\n",
    "    cbar.set_label(\"$\\Delta$ Blue-Green Water Share\", fontsize=18, weight='bold')\n",
    "    cbar.set_ticks([-0.1, -0.075, -0.05, -0.025, 0, 0.025, 0.05, 0.075, 0.1])\n",
    "    cbar.set_ticklabels([\"-10\", \"\", \"-5\", \"\", \"0\", \"\", \"5\", \"\", \"10\"])\n",
    "    cbar.ax.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04430a5a-bfc8-4e72-bfd0-a6b5bdc8f58e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e052c87-c715-4a6c-b475-adae8f1b0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_based_on_position(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    abs_x = abs(x)\n",
    "    if abs_x >= 10:\n",
    "        # For numbers >= 10, round up to the next integer\n",
    "        return math.ceil(x)\n",
    "    elif abs_x >= 1:\n",
    "        # For numbers < 10 and >= 1, round up to the nearest 0.5 or the next integer\n",
    "        return max(1.5, math.ceil(x * 2) / 2)\n",
    "    else:\n",
    "        # For numbers < 1, round up in a way that increases the first significant digit\n",
    "        digit_pos = -int(math.floor(math.log10(abs_x)))  # Position of first significant digit\n",
    "        increment = 10 ** (-digit_pos)\n",
    "        return math.ceil(x / increment) * increment\n",
    "\n",
    "def adjust_array(arr):\n",
    "    abs_max_val = np.max(np.abs(arr))\n",
    "    new_max = round_based_on_position(abs_max_val)\n",
    "    \n",
    "    # The adjustment logic above ensures we're rounding up correctly\n",
    "    # Construct the new array with the calculated new maximum\n",
    "    new_arr = np.array([-new_max, -new_max / 2, 0, new_max / 2, new_max])\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a94ac-d69a-4823-b161-52fad0000671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region(fig, axes, models, selected_region, ds_dict_change, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=True):\n",
    "    # Iterate over models and variables to plot\n",
    "    for i, model_name in enumerate(models, start=1):\n",
    "        ds = ds_dict_change[model_name]  # Get the dataset for the current model\n",
    "        prev_xy = None\n",
    "\n",
    "        for j, variable in enumerate(variables):\n",
    "            if variable in ds.data_vars:\n",
    "                selected_data = ds[variable].sel(region=selected_region).values.item()  # Get the single value for the selected region\n",
    "                        \n",
    "                bgws_value = ds['bgws'].sel(region=selected_region).values.item()  # Get bgws value for linestyle decision\n",
    "\n",
    "                # Normalize bgws value for color mapping\n",
    "                color = bgws_cm((bgws_value - -0.1) / (0.1 - -0.1))\n",
    "\n",
    "                current_xy = (j, value)\n",
    "                #print(model_name, variable, value)\n",
    "                \n",
    "                if np.isnan(value):\n",
    "                    prev_xy = None\n",
    "                    continue\n",
    "\n",
    "                if model_name.lower() == \"ensemble mean\":\n",
    "                    axes[j].plot(j, value, 'D', mec='red', mfc='none', markersize=22, mew=2, zorder=5)\n",
    "                elif model_name.lower() == \"ensemble median\":\n",
    "                    axes[j].plot(j, value, 'o', mec='orange', mfc='none', markersize=28, mew=2, zorder=4)\n",
    "                else:\n",
    "                    if j % 2 == 0:\n",
    "                        dot_color = '#f0f0f0'\n",
    "                    else: \n",
    "                        dot_color = 'white'\n",
    "                    axes[j].plot(j, value, 'o', color=dot_color, markersize=38, zorder=1)\n",
    "                    axes[j].annotate(str(i), xy=current_xy, xytext=(0, 0), textcoords='offset points',\n",
    "                                     fontsize=38, weight='bold', color=color,\n",
    "                                     ha='center', va='center', zorder=2)\n",
    "\n",
    "                if prev_xy is not None:\n",
    "                    linestyle = '--' if bgws_value < 0 else '-'\n",
    "                    con = ConnectionPatch(xyA=prev_xy, xyB=current_xy, coordsA=\"data\", coordsB=\"data\",\n",
    "                                          axesA=axes[j-1], axesB=axes[j],\n",
    "                                          linestyle=linestyle, shrinkA=17, shrinkB=17, color=color, linewidth=2)  \n",
    "                    fig.add_artist(con)\n",
    "\n",
    "                prev_xy = current_xy\n",
    "            else:\n",
    "                prev_xy = None\n",
    "    \n",
    "    \n",
    "     # Identify \"mm/day\" variables\n",
    "    mm_day_variables = ['pr', 'mrro', 'evspsbl', 'tran', 'evapo'] \n",
    "\n",
    "    if use_common_scale_for_mm_day:\n",
    "        # Calculate the max absolute value for \"mm/day\" variables across all models\n",
    "        max_abs_mm_day = 0\n",
    "        for var in mm_day_variables:\n",
    "            for model_name, ds in ds_dict_change.items():\n",
    "                if var in ds.data_vars:\n",
    "                    abs_values = np.abs(ds[var].sel(region=selected_region).values)\n",
    "                    max_abs_mm_day = max(max_abs_mm_day, np.nanmax(abs_values))\n",
    "        common_ylim = max_abs_mm_day * 1.05  # Common y-axis limit for \"mm/day\" variables, scaled up slightly for visual margin\n",
    "    else:\n",
    "        common_ylim = None  # This will signify not to use a common y-limit for \"mm/day\" variables\n",
    "\n",
    "    # Calculate maximum absolute value for each variable across all models for the selected region\n",
    "    max_abs_values = {}\n",
    "    for var in variables:\n",
    "        if var not in mm_day_variables or not use_common_scale_for_mm_day:\n",
    "            max_values = []\n",
    "            for model_name, ds in ds_dict_change.items():\n",
    "                if var in ds.data_vars:\n",
    "                    value = abs(ds[var].sel(region=selected_region).values.item())\n",
    "                    if np.isnan(value):\n",
    "                        continue\n",
    "                    max_values.append(value)\n",
    "            max_abs_values[var] = max(max_values) if max_values else 0\n",
    "        else:\n",
    "            # Use common y-axis limit for \"mm/day\" variables if flag is set\n",
    "            max_abs_values[var] = common_ylim\n",
    "\n",
    "    # Adjust axes properties and add variable names\n",
    "    for j, var in enumerate(variables):\n",
    "        # Set x-axis ticks and labels with improved formatting\n",
    "        axes[j].set_xlim(j - 1, j + 1)\n",
    "        axes[j].set_xticks([j])\n",
    "        axes[j].spines['top'].set_visible(False)\n",
    "        axes[j].spines['bottom'].set_visible(False)\n",
    "        axes[j].spines['right'].set_visible(False)\n",
    "        axes[j].set_xticklabels([display_variables[var]], fontdict={'size': 25})\n",
    "       \n",
    "        axes[j].tick_params(axis='x', length=10, color='white')#,  labelrotation=90)   # Adjust x-axis tick label size\n",
    "            \n",
    "        # Add horizontal line at y=0\n",
    "        axes[j].axhline(y=0, color='gray', linestyle='-', linewidth=1)  \n",
    "\n",
    "        # Set y-axis ticks and labels with improved formatting\n",
    "        # Calculate the maximum absolute value for the variable\n",
    "        max_abs_value = max_abs_values[var] * 1.05\n",
    "        ticks = adjust_array(np.linspace(-max_abs_value, max_abs_value, num=5))\n",
    "        #print(max_abs_value, ticks)\n",
    "        # Set the y-axis limits to ensure 0 is always in the middle\n",
    "        axes[j].set_ylim(ticks[0], ticks[-1])\n",
    "        axes[j].set_yticks(ticks)\n",
    "        axes[j].spines['left'].set_bounds(ticks[0], ticks[-1]) # Set bounds for left spine\n",
    "        axes[j].tick_params(axis='y', labelsize=18)  # Adjust y-axis tick label size\n",
    "        \n",
    "        # Coloring every second subplot's background\n",
    "        if j % 2 == 0:  # This checks if the index is odd, applying the color to every second subplot\n",
    "            axes[j].set_facecolor('#f0f0f0')  # Light gray background\n",
    "    \n",
    "        if j == 0:\n",
    "            # This is the first subplot, so add a y-axis label here\n",
    "            axes[j].set_ylabel(\"End-of-century response\", fontsize=25)\n",
    "    \n",
    "        # Improved tick label formatting to remove unnecessary trailing zeros\n",
    "        if j > 0:  # Check if not the first axis\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' and tick != 0 else '' for tick in ticks])\n",
    "            ticks = axes[j].yaxis.get_major_ticks() \n",
    "            # Modify properties of the first tick\n",
    "            tick_to_modify = 2  # Index of the tick to modify\n",
    "            ticks[tick_to_modify].tick1line.set_markersize(50)\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgecolor('gray')\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgewidth(1)\n",
    "\n",
    "        else:\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' else f'{tick:.2f}' for tick in ticks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de918c-fcba-4cad-9668-1097875e72ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a3e1c-07d0-4491-9203-7636d735b243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_figure(fig, change, experiment_id, months, yearly_sum, region_names, region_idx, subdiv_idx, legend, common_scale_for_mm_day):\n",
    "    # Caption and figure saving\n",
    "    region_name = (region_names.isel(region=region_idx).item()).replace(\"/\", \"_\")\n",
    "    savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'regional_var_change', region_name)\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "    if legend:\n",
    "        if common_scale_for_mm_day:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}.pdf'\n",
    "        else:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}_no_common_y_scale.pdf' \n",
    "    else:\n",
    "        if common_scale_for_mm_day:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}_without_legend.pdf' \n",
    "\n",
    "        else:\n",
    "            filename = f'{region_name}_{subdiv_idx}_regional_var_{change}_{experiment_id}_{months}_{yearly_sum}_without_legend_no_common_y_scale.pdf' \n",
    "    filepath = os.path.join(savepath, filename)\n",
    "    fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    print(f'Figure saved under {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173177e7-1327-46be-9952-4ba5d9d45155",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e8e5b-a170-48a1-99ab-f6403c0db466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restore the load and preprocess function\n",
    "\n",
    "#This is what it need to do:\n",
    "season=None # None, 'spring', summer, fall, winter\n",
    "ds_dict = lap.load_and_preprocess(vars='all', scenarios=['historical', 'ssp370'], models='all', period=season, yearly_sum=False, period_statistic='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5c9f8-edc7-46e4-a848-f5affe9d20a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02975c-6fbd-4097-9cc9-89d416b80f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0c936e-1317-4f16-9138-6aa7465b09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d469d6-5c9f-4804-8c92-6db8cef15b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath('')), '../../../../common/src'))\n",
    "import data_handling.load_preprocessed_data as lpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44805cb7-af6b-43f5-90ac-fb0721031f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries for preprocessed datasets\n",
    "ds_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d0ac36-08d4-4ea2-b384-e485d9d731ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source models (IDs)\n",
    "source_ids = ['BCC-CSM2-MR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf98452-2bea-4046-ac0f-482ee0fee414",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = ['historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4cdba-b389-4011-b633-22f17b975b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each scenario\n",
    "for scenario in experiment_ids:\n",
    "    print(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b256bb2b-da9c-4593-8d51-172305ac0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_temp = {}\n",
    "ds_dict[scenario] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbc801e-036b-4d25-b129-6f058c96158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_variables(vars_selected, period):\n",
    "    # Define categories based on temporal resolution\n",
    "    monthly_variables = ['tas', 'pr', 'vpd', 'mrro', 'mrso', 'tran', 'lai', 'gpp', 'evspsbl', 'evapo']\n",
    "    yearly_variables = ['RX5day']\n",
    "    \n",
    "    # Adjust the handling of period\n",
    "    if period is not None:\n",
    "        period_variables = [f'growing_season_length_{period}']  # Use the specific period if provided\n",
    "        yearly = period  # The default yearly category name\n",
    "    else:\n",
    "        period_variables = ['growing_season_length_period']  # Use a general name if no specific period is provided\n",
    "        yearly = 'year'  # The default yearly category name\n",
    "        period = 'period'  # Use 'period' as the category name if no specific period is provided\n",
    "    \n",
    "    # Initialize categories\n",
    "    categories = {\n",
    "        'month': [],\n",
    "        yearly: [],\n",
    "        period: []\n",
    "    }\n",
    "\n",
    "    # Check the selection and categorize\n",
    "    if vars_selected == 'all':\n",
    "        categories['month'].extend(monthly_variables)\n",
    "        categories[yearly].extend(yearly_variables)\n",
    "        categories[period].extend(period_variables)\n",
    "    else:\n",
    "        for var in vars_selected:\n",
    "            if var in monthly_variables:\n",
    "                categories['month'].append(var)\n",
    "            elif var in yearly_variables:\n",
    "                categories[yearly].append(var)\n",
    "            elif var == 'growing_season_length':  # Use a general check for the variable name\n",
    "                categories[period].append(var if period is None else f'growing_season_length_{period}')\n",
    "            else:\n",
    "                print(f\"Warning: Variable '{var}' not recognized.\")\n",
    "                \n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265b310b-b7b6-40b8-b697-c6d6feb2b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize variables based on temporal resolution\n",
    "categorized_variables = categorize_variables('all', period=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785b1f2-8519-4ad9-b22d-eb39aa2b46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(scenario, models, data_state, temporal_resolution, variables):\n",
    "    # Initialize the dictionary to store datasets\n",
    "    ds_dict = {}\n",
    "\n",
    "    \n",
    "                ds = open_and_merge_datasets(folder, model, experiment_id, temp_res, variables)\n",
    "                ds_dict[experiment_id][model] = ds\n",
    "            except ValueError as e:\n",
    "                print(f\"Failed to load data for model {model} in scenario {experiment_id}: {e}\")\n",
    "\n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c68d2de-c115-4f53-9f2f-c396b933b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa3d34-f735-4610-b128-d6a52c44cbc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447b4f5-c1ef-4a4c-a772-5838aa38f368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c70fc0-2c67-4dc8-bc6c-964dff8687fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85fe284a-7981-4c51-a94c-09b34992d087",
   "metadata": {},
   "source": [
    "## New load preprocessed data script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "794b0a77-c247-4393-b4d2-3b01e583990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libaries\n",
    "\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9746447b-4b2c-464a-92d0-432d8268207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input\n",
    "\n",
    "\"\"\"\n",
    "data_product = e.g. CMIP6 ERA5 CMIP5 CORDEX\n",
    "experiment = e.g. historical ssp370 \n",
    "temp_res = e.g. day month year\n",
    "var = e.g. pr lai tas\n",
    "\"\"\"\n",
    "BASE_DIR = '/work/ch0636/g300115/phd_project/common/data/processed'\n",
    "data_product = 'CMIP6'\n",
    "experiment = 'historical'\n",
    "experiments = ['historical', 'ssp370']\n",
    "temp_res = 'season' # 'period' 'year'\n",
    "season_name = 'spring'\n",
    "if temp_res == 'season':\n",
    "    temp_res = f'season/{season_name}'\n",
    "variables = ['gsl', 'RX5day']#['pr', 'lai']\n",
    "models = ['BCC-CSM2-MR', 'CAMS-CSM1-0'] #CESM2-WACCM CNRM-ESM2-1 GISS-E2-1-G MIROC-ES2L NorESM2-MM UKESM1-0-LL CanESM5 CNRM-CM6-1 GFDL-ESM4 IPSL-CM6A-LR MPI-ESM1-2-LR TaiESM1\n",
    "model = 'BCC-CSM2-MR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de32c0d-36ae-4f70-b711-d2e6225b4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Open dataset based on input filepath.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath: Path to file with filename.\n",
    "\n",
    "    Returns:\n",
    "    - A dataset with loaded file.\n",
    "    \"\"\"\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e17b1180-84a7-4410-873d-57cadddd6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_models_variables(BASE_DIR, data_product, experiment, temp_res, model, variables):\n",
    "    \"\"\"\n",
    "    Open dataset of one model for different variables and merge them to one common xarray dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data_product: e.g. CMIP6 ERA5 CMIP5 CORDEX\n",
    "    - experiment: e.g. historical ssp370 \n",
    "    - temp_res: e.g. day month season year period\n",
    "    - model: e.g. CAMS-CSM1-0 CESM2-WACCM CNRM-ESM2-1 GISS-E2-1-G MIROC-ES2L NorESM2-MM\n",
    "    - variables: List of different variables e.g. [pr, lai, tas]\n",
    "\n",
    "    Returns:\n",
    "    - A dataset with all variables of one model loaded in one xarray dataset.\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "    for var in variables:\n",
    "        file = f'{data_product}/{experiment}/{temp_res}/{var}/{model}.nc'\n",
    "        file_path = os.path.join(BASE_DIR, file)\n",
    "        if file_path:\n",
    "            filepaths.append(file_path)\n",
    "        else:\n",
    "            print(f\"No file found for variable '{var}' in model '{model}'.\")\n",
    "            print(fp)\n",
    "\n",
    "    datasets = [xr.open_dataset(fp) for fp in filepaths]\n",
    "    ds = xr.merge(datasets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4995b893-1a6b-4b39-9e0a-3628c883b614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: 'âº';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: 'â¼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:                       (lat: 149, lon: 360, time: 30)\n",
       "Coordinates:\n",
       "  * lat                           (lat) int64 -59 -58 -57 -56 ... 86 87 88 89\n",
       "  * lon                           (lon) int64 -180 -179 -178 ... 177 178 179\n",
       "  * time                          (time) object 1985-03-01 00:00:00 ... 2014-...\n",
       "Data variables:\n",
       "    growing_season_length_spring  (lat, lon) float64 ...\n",
       "    RX5day                        (time, lat, lon) float32 ...\n",
       "Attributes: (12/69)\n",
       "    Conventions:                      CF-1.7 CMIP-6.2\n",
       "    activity_id:                      CMIP\n",
       "    branch_method:                    Standard\n",
       "    branch_time_in_child:             0.0\n",
       "    branch_time_in_parent:            2289.0\n",
       "    comment:                          The model integration starts from the p...\n",
       "    ...                               ...\n",
       "    intake_esm_attrs:_data_format_:   netcdf\n",
       "    intake_esm_dataset_key:           CMIP.BCC-CSM2-MR.historical.Lmon.gn\n",
       "    log:                              Unit of mrso converted from kg/mÂ² to mm...\n",
       "    regrid_method:                    conservative\n",
       "    months:                           whole_year\n",
       "    yearly_sum:                       monthly_mean</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-e5ad5b3d-45e4-45cb-bd4e-4513a4b7e3bc' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-e5ad5b3d-45e4-45cb-bd4e-4513a4b7e3bc' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lat</span>: 149</li><li><span class='xr-has-index'>lon</span>: 360</li><li><span class='xr-has-index'>time</span>: 30</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-1ed9e506-d6ec-41a5-812a-3f0dc25e6277' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1ed9e506-d6ec-41a5-812a-3f0dc25e6277' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>-59 -58 -57 -56 -55 ... 86 87 88 89</div><input id='attrs-48c66ee2-7cbb-4638-bdd8-d98560a36e5a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-48c66ee2-7cbb-4638-bdd8-d98560a36e5a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8f2031e7-49e5-4041-b812-438a55606726' class='xr-var-data-in' type='checkbox'><label for='data-8f2031e7-49e5-4041-b812-438a55606726' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46,\n",
       "       -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32,\n",
       "       -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18,\n",
       "       -17, -16, -15, -14, -13, -12, -11, -10,  -9,  -8,  -7,  -6,  -5,  -4,\n",
       "        -3,  -2,  -1,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "        11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
       "        25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
       "        81,  82,  83,  84,  85,  86,  87,  88,  89])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>-180 -179 -178 -177 ... 177 178 179</div><input id='attrs-8ba44d4b-159f-480e-ad61-b19fc596847b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8ba44d4b-159f-480e-ad61-b19fc596847b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-885ac532-7a17-468f-84cc-a03953024474' class='xr-var-data-in' type='checkbox'><label for='data-885ac532-7a17-468f-84cc-a03953024474' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-180, -179, -178, ...,  177,  178,  179])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>1985-03-01 00:00:00 ... 2014-03-...</div><input id='attrs-e1c5bf8e-dbaa-46b6-a6c3-f96fe9493ae9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e1c5bf8e-dbaa-46b6-a6c3-f96fe9493ae9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-dcd21b06-5ee9-4301-9f42-1120c01f701d' class='xr-var-data-in' type='checkbox'><label for='data-dcd21b06-5ee9-4301-9f42-1120c01f701d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([cftime.DatetimeNoLeap(1985, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1986, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1987, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1988, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1989, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1990, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1991, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1992, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1993, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1994, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1995, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1996, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1997, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1998, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(1999, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2000, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2001, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2002, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2003, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2004, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2005, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2006, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2007, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2008, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2009, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2010, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2011, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2012, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2013, 3, 1, 0, 0, 0, 0, has_year_zero=True),\n",
       "       cftime.DatetimeNoLeap(2014, 3, 1, 0, 0, 0, 0, has_year_zero=True)],\n",
       "      dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-87b49075-0b4d-4717-9843-501a2c4643e4' class='xr-section-summary-in' type='checkbox'  checked><label for='section-87b49075-0b4d-4717-9843-501a2c4643e4' class='xr-section-summary' >Data variables: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>growing_season_length_spring</span></div><div class='xr-var-dims'>(lat, lon)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b50b3dc1-305a-49ab-9ba4-0875434729eb' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b50b3dc1-305a-49ab-9ba4-0875434729eb' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2604b0c4-11e8-4bd0-a803-f5251951882a' class='xr-var-data-in' type='checkbox'><label for='data-2604b0c4-11e8-4bd0-a803-f5251951882a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Length of the growing season in months for spring</dd><dt><span>calculated_from :</span></dt><dd>LAI</dd><dt><span>season :</span></dt><dd>spring</dd><dt><span>units :</span></dt><dd></dd><dt><span>long_name :</span></dt><dd>Growing Season Length</dd></dl></div><div class='xr-var-data'><pre>[53640 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>RX5day</span></div><div class='xr-var-dims'>(time, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-41e2de7d-f636-4d73-9ad0-43a4a09543ab' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-41e2de7d-f636-4d73-9ad0-43a4a09543ab' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-506d61f1-18c3-4682-a3cb-6da1692bab36' class='xr-var-data-in' type='checkbox'><label for='data-506d61f1-18c3-4682-a3cb-6da1692bab36' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>mm</dd><dt><span>cell_methods :</span></dt><dd>area: time: mean (interval: 5 minutes) time: maximum over days</dd><dt><span>history :</span></dt><dd>[2024-02-20 16:59:26] RX5day compute_RX5day_seasonal (pr=pr, freq=spring)</dd><dt><span>long_name :</span></dt><dd>Highest 5-day precipitation amount</dd><dt><span>standard_name :</span></dt><dd>lwe_thickness_of_precipitation_amount</dd><dt><span>description :</span></dt><dd>Annual maximum 5-day total precipitation amount.</dd></dl></div><div class='xr-var-data'><pre>[1609200 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-c4c48e64-dc50-410a-82f7-e8b6cb5e0629' class='xr-section-summary-in' type='checkbox'  ><label for='section-c4c48e64-dc50-410a-82f7-e8b6cb5e0629' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-6d7388b5-73e7-4d2b-94cb-ac27a2a97251' class='xr-index-data-in' type='checkbox'/><label for='index-6d7388b5-73e7-4d2b-94cb-ac27a2a97251' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Int64Index([-59, -58, -57, -56, -55, -54, -53, -52, -51, -50,\n",
       "            ...\n",
       "             80,  81,  82,  83,  84,  85,  86,  87,  88,  89],\n",
       "           dtype=&#x27;int64&#x27;, name=&#x27;lat&#x27;, length=149))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-52a48244-e3cc-471f-bd0e-42fa76ea8fb9' class='xr-index-data-in' type='checkbox'/><label for='index-52a48244-e3cc-471f-bd0e-42fa76ea8fb9' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Int64Index([-180, -179, -178, -177, -176, -175, -174, -173, -172, -171,\n",
       "            ...\n",
       "             170,  171,  172,  173,  174,  175,  176,  177,  178,  179],\n",
       "           dtype=&#x27;int64&#x27;, name=&#x27;lon&#x27;, length=360))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-ba9013f6-67da-4095-bfb9-dde3a193d123' class='xr-index-data-in' type='checkbox'/><label for='index-ba9013f6-67da-4095-bfb9-dde3a193d123' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(CFTimeIndex([1985-03-01 00:00:00, 1986-03-01 00:00:00, 1987-03-01 00:00:00,\n",
       "             1988-03-01 00:00:00, 1989-03-01 00:00:00, 1990-03-01 00:00:00,\n",
       "             1991-03-01 00:00:00, 1992-03-01 00:00:00, 1993-03-01 00:00:00,\n",
       "             1994-03-01 00:00:00, 1995-03-01 00:00:00, 1996-03-01 00:00:00,\n",
       "             1997-03-01 00:00:00, 1998-03-01 00:00:00, 1999-03-01 00:00:00,\n",
       "             2000-03-01 00:00:00, 2001-03-01 00:00:00, 2002-03-01 00:00:00,\n",
       "             2003-03-01 00:00:00, 2004-03-01 00:00:00, 2005-03-01 00:00:00,\n",
       "             2006-03-01 00:00:00, 2007-03-01 00:00:00, 2008-03-01 00:00:00,\n",
       "             2009-03-01 00:00:00, 2010-03-01 00:00:00, 2011-03-01 00:00:00,\n",
       "             2012-03-01 00:00:00, 2013-03-01 00:00:00, 2014-03-01 00:00:00],\n",
       "            dtype=&#x27;object&#x27;, length=30, calendar=&#x27;noleap&#x27;, freq=&#x27;AS-MAR&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-39958884-fb68-4b1e-abff-b1300edca747' class='xr-section-summary-in' type='checkbox'  ><label for='section-39958884-fb68-4b1e-abff-b1300edca747' class='xr-section-summary' >Attributes: <span>(69)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>Conventions :</span></dt><dd>CF-1.7 CMIP-6.2</dd><dt><span>activity_id :</span></dt><dd>CMIP</dd><dt><span>branch_method :</span></dt><dd>Standard</dd><dt><span>branch_time_in_child :</span></dt><dd>0.0</dd><dt><span>branch_time_in_parent :</span></dt><dd>2289.0</dd><dt><span>comment :</span></dt><dd>The model integration starts from the piControl experiment equilibrium state (1st Jan. of the year 2289)</dd><dt><span>contact :</span></dt><dd>Dr. Tongwen Wu(twwu@cma.gov.cn)</dd><dt><span>data_specs_version :</span></dt><dd>01.00.27</dd><dt><span>description :</span></dt><dd>DECK: historical</dd><dt><span>experiment :</span></dt><dd>all-forcing simulation of the recent past</dd><dt><span>experiment_id :</span></dt><dd>historical</dd><dt><span>external_variables :</span></dt><dd>areacella</dd><dt><span>forcing_index :</span></dt><dd>1</dd><dt><span>frequency :</span></dt><dd>mon</dd><dt><span>further_info_url :</span></dt><dd>https://furtherinfo.es-doc.org/CMIP6.BCC.BCC-CSM2-MR.historical.none.r1i1p1f1</dd><dt><span>grid :</span></dt><dd>T106</dd><dt><span>grid_label :</span></dt><dd>gn</dd><dt><span>history :</span></dt><dd>2018-11-14T10:07:41Z ; CMOR rewrote data to be consistent with CMIP6, CF-1.7 CMIP-6.2 and CF standards.;\n",
       "N/A</dd><dt><span>initialization_index :</span></dt><dd>1</dd><dt><span>institution :</span></dt><dd>Beijing Climate Center, Beijing 100081, China</dd><dt><span>institution_id :</span></dt><dd>BCC</dd><dt><span>mip_era :</span></dt><dd>CMIP6</dd><dt><span>nominal_resolution :</span></dt><dd>100 km</dd><dt><span>parent_activity_id :</span></dt><dd>CMIP</dd><dt><span>parent_experiment_id :</span></dt><dd>piControl</dd><dt><span>parent_mip_era :</span></dt><dd>CMIP6</dd><dt><span>parent_source_id :</span></dt><dd>BCC-CSM2-MR</dd><dt><span>parent_time_units :</span></dt><dd>days since 1850-01-01</dd><dt><span>parent_variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>physics_index :</span></dt><dd>1</dd><dt><span>product :</span></dt><dd>model-output</dd><dt><span>realization_index :</span></dt><dd>1</dd><dt><span>realm :</span></dt><dd>land</dd><dt><span>references :</span></dt><dd>Model described by Tongwen Wu et al. (JGR 2013; JMR 2014; submmitted to GMD,2018). Also see http://forecast.bcccsm.ncc-cma.net/htm</dd><dt><span>run_variant :</span></dt><dd>forcing: greenhouse gases,solar constant,aerosol,volcano mass,land use,ozone</dd><dt><span>source :</span></dt><dd>BCC-CSM 2 MR (2017):   aerosol: none  atmos: BCC_AGCM3_MR (T106; 320 x 160 longitude/latitude; 46 levels; top level 1.46 hPa)  atmosChem: none  land: BCC_AVIM2  landIce: none  ocean: MOM4 (1/3 deg 10S-10N, 1/3-1 deg 10-30 N/S, and 1 deg in high latitudes; 360 x 232 longitude/latitude; 40 levels; top grid cell 0-10 m)  ocnBgchem: none  seaIce: SIS2</dd><dt><span>source_id :</span></dt><dd>BCC-CSM2-MR</dd><dt><span>source_type :</span></dt><dd>AOGCM</dd><dt><span>sub_experiment :</span></dt><dd>none</dd><dt><span>sub_experiment_id :</span></dt><dd>none</dd><dt><span>table_id :</span></dt><dd>spring</dd><dt><span>table_info :</span></dt><dd>Creation Date:(30 July 2018) MD5:e53ff52009d0b97d9d867dc12b6096c7</dd><dt><span>title :</span></dt><dd>BCC-CSM2-MR output prepared for CMIP6</dd><dt><span>variant_label :</span></dt><dd>r1i1p1f1</dd><dt><span>license :</span></dt><dd>CMIP6 model data produced by BCC is licensed under a Creative Commons Attribution ShareAlike 4.0 International License (https://creativecommons.org/licenses). Consult https://pcmdi.llnl.gov/CMIP6/TermsOfUse for terms of use governing CMIP6 output, including citation requirements and proper acknowledgment. Further information about this data, including some limitations, can be found via the further_info_url (recorded as a global attribute in this file) and at https:///pcmdi.llnl.gov/. The data producers and data providers make no warranty, either express or implied, including, but not limited to, warranties of merchantability and fitness for a particular purpose. All liabilities arising from the supply of the information (including any liability arising in negligence) are excluded to the fullest extent permitted by law.</dd><dt><span>cmor_version :</span></dt><dd>3.3.2</dd><dt><span>intake_esm_attrs:activity_id :</span></dt><dd>CMIP</dd><dt><span>intake_esm_attrs:institution_id :</span></dt><dd>BCC</dd><dt><span>intake_esm_attrs:source_id :</span></dt><dd>BCC-CSM2-MR</dd><dt><span>intake_esm_attrs:experiment_id :</span></dt><dd>historical</dd><dt><span>intake_esm_attrs:member_id :</span></dt><dd>r1i1p1f1</dd><dt><span>intake_esm_attrs:table_id :</span></dt><dd>Lmon</dd><dt><span>intake_esm_attrs:grid_label :</span></dt><dd>gn</dd><dt><span>intake_esm_attrs:version :</span></dt><dd>v20181114</dd><dt><span>intake_esm_attrs:time_range :</span></dt><dd>185001-201412</dd><dt><span>intake_esm_attrs:project :</span></dt><dd>CMIP6</dd><dt><span>intake_esm_attrs:simulation_id :</span></dt><dd>r1i1p1f1</dd><dt><span>intake_esm_attrs:grid_id :</span></dt><dd>No entry</dd><dt><span>intake_esm_attrs:frequency :</span></dt><dd>mon</dd><dt><span>intake_esm_attrs:time_reduction :</span></dt><dd> mean</dd><dt><span>intake_esm_attrs:realm :</span></dt><dd>land</dd><dt><span>intake_esm_attrs:time_min :</span></dt><dd>185001.0</dd><dt><span>intake_esm_attrs:time_max :</span></dt><dd>201412</dd><dt><span>intake_esm_attrs:_data_format_ :</span></dt><dd>netcdf</dd><dt><span>intake_esm_dataset_key :</span></dt><dd>CMIP.BCC-CSM2-MR.historical.Lmon.gn</dd><dt><span>log :</span></dt><dd>Unit of mrso converted from kg/mÂ² to mm. // Unit of tas converted from K to Â°C. // Unit of vpd converted from Pa to hPa. // Unit of tran converted from kg/mÂ²/s to mm/day. // Unit of mrro converted from kg/mÂ²/s to mm/day. // Unit of pr converted from kg/mÂ²/s to mm/day. // Unit of mrso converted from kg/mÂ² to mm. // Unit of tas converted from K to Â°C. // Unit of vpd converted from Pa to hPa. // Unit of tran converted from kg/mÂ²/s to mm/day. // Unit of gpp converted from kg/mÂ²/s to gC/mÂ²/day. // Unit of mrro converted from kg/mÂ²/s to mm/day. // Unit of evspsbl converted from kg/mÂ²/s to mm/day. // Unit of pr converted from kg/mÂ²/s to mm/day. // Dataset sliced along lat 60 to remove Antartica. // Dataset sliced along lat 60 to remove Antartica. // IMERG Land-Sea Mask NetCDF 25%-landmask applied. // Regridded to 1x1Â° lonxlat grid using conservative interpolation. // Dropped: member_id. // Dropped: dcpp_init_year. // Dropped: time_bnds. // Dropped: lon_bnds. // Dropped: lat_bnds. // Dropped: bnds.</dd><dt><span>regrid_method :</span></dt><dd>conservative</dd><dt><span>months :</span></dt><dd>whole_year</dd><dt><span>yearly_sum :</span></dt><dd>monthly_mean</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                       (lat: 149, lon: 360, time: 30)\n",
       "Coordinates:\n",
       "  * lat                           (lat) int64 -59 -58 -57 -56 ... 86 87 88 89\n",
       "  * lon                           (lon) int64 -180 -179 -178 ... 177 178 179\n",
       "  * time                          (time) object 1985-03-01 00:00:00 ... 2014-...\n",
       "Data variables:\n",
       "    growing_season_length_spring  (lat, lon) float64 ...\n",
       "    RX5day                        (time, lat, lon) float32 ...\n",
       "Attributes: (12/69)\n",
       "    Conventions:                      CF-1.7 CMIP-6.2\n",
       "    activity_id:                      CMIP\n",
       "    branch_method:                    Standard\n",
       "    branch_time_in_child:             0.0\n",
       "    branch_time_in_parent:            2289.0\n",
       "    comment:                          The model integration starts from the p...\n",
       "    ...                               ...\n",
       "    intake_esm_attrs:_data_format_:   netcdf\n",
       "    intake_esm_dataset_key:           CMIP.BCC-CSM2-MR.historical.Lmon.gn\n",
       "    log:                              Unit of mrso converted from kg/mÂ² to mm...\n",
       "    regrid_method:                    conservative\n",
       "    months:                           whole_year\n",
       "    yearly_sum:                       monthly_mean"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test open_models_variables\n",
    "ds = open_models_variables(BASE_DIR, data_product, experiment, temp_res, model, variables)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f263465-d9c4-4772-a41e-60bb3e98b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_models_and_experiments(BASE_DIR, data_product, experiments, temp_res, models, variables):\n",
    "    \"\"\"\n",
    "    Open datasets for mutiple models and experiments in one xarray dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - BASE_DIR: Path to base directory to pass it to open function.\n",
    "    - data_product: Data product e.g. CMIP6 to pass it to open function.\n",
    "    - experiments: List of experiments to load e.g. historical ssp370.\n",
    "    - temp_res: e.g. day month season year period\n",
    "    - models: List of models to load.\n",
    "    - variables: List of variables to load.\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "    - A xarray dictionary containig the models with all vairables for each experiment respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the dictionary to store datasets\n",
    "    ds_dict = {}\n",
    "\n",
    "    # Loop over each experiment and model name to load and merge datasets\n",
    "    for experiment in experiments:\n",
    "        ds_dict[experiment] = {}\n",
    "        for model_name in models:\n",
    "            try:\n",
    "                ds = open_models_variables(BASE_DIR, data_product, experiment, temp_res, model_name, variables)\n",
    "                ds_dict[experiment][model_name] = ds\n",
    "            except ValueError as e:\n",
    "                print(f\"Failed to load data for model {model_name} in scenario {experiment}: {e}\")\n",
    "\n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6a59f5d-d710-4048-be5d-e1f7923f936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['historical', 'ssp370'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['BCC-CSM2-MR', 'CAMS-CSM1-0'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test load_multiple_models\n",
    "ds_dict = load_multiple_models_and_experiments(BASE_DIR, data_product, experiments, temp_res, models, variables)\n",
    "print(ds_dict.keys())\n",
    "ds_dict[list(ds_dict.keys())[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d84c55-5224-48e5-95ea-3f5451b9a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_period(ds_dict, start_year=None, end_year=None, period=None, yearly_sum=False):\n",
    "    '''\n",
    "    Function to select periods and optionally compute yearly sums.\n",
    "    \n",
    "    Parameters:\n",
    "    - ds_dict (dict): Dictionary with xarray datasets.\n",
    "    - start_year (int): The start year of the period.\n",
    "    - end_year (int): The end year of the period.\n",
    "    - period (int, list, str, None): Single month (int), list of months (list), multiple seasons (str) to select,\n",
    "                                   or None to not select any specific period.\n",
    "    - yearly_sum (bool): If True, compute the yearly sum over the selected period.\n",
    "\n",
    "    Returns:\n",
    "    - A xarray dictionary containig a copy of the original dictionary with data only for the selected period.\n",
    "    '''\n",
    "    \n",
    "    # Create a deep copy of the original ds_dict to avoid modifying it directly\n",
    "    ds_dict_copy = copy.deepcopy(ds_dict)\n",
    "\n",
    "    # Define season to month mapping for northern hemisphere\n",
    "    seasons_to_months = {\n",
    "        'nh_winter': [12, 1, 2],\n",
    "        'nh_spring': [3, 4, 5],\n",
    "        'nh_summer': [6, 7, 8],\n",
    "        'nh_fall': [9, 10, 11]\n",
    "    }\n",
    "    \n",
    "    # Define month name mapping\n",
    "    month_names = {\n",
    "        1: 'J', 2: 'F', 3: 'M', 4: 'A', 5: 'M', 6: 'J',\n",
    "        7: 'J', 8: 'A', 9: 'S', 10: 'O', 11: 'N', 12: 'D'\n",
    "    }\n",
    "\n",
    "    # Define number of days per month\n",
    "    days_per_month = {\n",
    "        1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30,\n",
    "        7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31\n",
    "    }\n",
    "\n",
    "    months = []\n",
    "\n",
    "    # If no specific period is selected, all data will be used.\n",
    "    if period is None:\n",
    "        period_name = 'whole_year'\n",
    "        months = list(range(1, 13))  # All months\n",
    "    elif isinstance(period, int):\n",
    "        period_name = month_names[period]\n",
    "        months = [period]\n",
    "    elif isinstance(period, str):\n",
    "        # Check if the input is a single season or multiple seasons\n",
    "        if 'and' in period:\n",
    "            seasons = period.lower().split('and')\n",
    "            period_name = ''\n",
    "            for season in seasons:\n",
    "                season = season.strip()\n",
    "                months.extend(seasons_to_months.get(season, []))\n",
    "                period_name += ''.join(month_names[m] for m in seasons_to_months.get(season, []))\n",
    "        else:\n",
    "            months = seasons_to_months.get(period.lower(), [])\n",
    "            period_name = ''.join(month_names[m] for m in months)\n",
    "    elif isinstance(period, list):\n",
    "        period_name = ''.join(month_names[m] for m in period if m in month_names)\n",
    "        months = period\n",
    "    else:\n",
    "        raise ValueError(\"Period must be None, an integer, a string representing a single season, \"\n",
    "                         \"a string with multiple seasons separated by 'and', or a list of integers.\")\n",
    "\n",
    "    for k, ds in ds_dict_copy.items():\n",
    "        if start_year and end_year:\n",
    "            start_date = f'{start_year}-01-01'\n",
    "            end_date = f'{end_year}-12-31'\n",
    "            ds = ds.sel(time=slice(start_date, end_date))\n",
    "\n",
    "        # If months are specified, select those months\n",
    "        if months:\n",
    "            month_mask = ds['time.month'].isin(months)\n",
    "            ds = ds.where(month_mask, drop=True)\n",
    "\n",
    "        # Store the original attributes of each variable\n",
    "        original_attrs = {var: ds[var].attrs for var in ds.data_vars}\n",
    "\n",
    "        # If yearly_sum is True, sum over 'time' dimension to get yearly sum\n",
    "        if yearly_sum: # does only make sense for accumulative variables e.g. pr or tran\n",
    "            attrs = ds.attrs\n",
    "            # Multiply each value by the number of days in the respective month\n",
    "            days = ds['time'].dt.days_in_month\n",
    "            ds = (ds * days).resample(time='AS').sum(dim='time')\n",
    "            sum_type = 'yearly_sum'\n",
    "            ds.attrs = attrs\n",
    "        else:\n",
    "            sum_type = 'monthly_mean'\n",
    "\n",
    "        # Reassign the original attributes back to each variable\n",
    "        for var in ds.data_vars:\n",
    "            ds[var].attrs = original_attrs[var]\n",
    "\n",
    "        ds_dict_copy[k] = ds\n",
    "        ds_dict_copy[k].attrs['months'] = period_name\n",
    "        ds_dict_copy[k].attrs['yearly_sum'] = sum_type\n",
    "\n",
    "    return ds_dict_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "046df61b-29b8-4c44-9367-95fc1669c186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'historical'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12faa550-d623-4972-8abf-7063291637f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_period(ds_dict['historical'], start_year=1985 \n",
    "            if scenario == 'historical' else 2071, end_year=2014 if scenario == 'historical' else 2100, period=period, yearly_sum=yearly_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cd282-6d98-409d-a5d4-5e51e7d2cdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0c1f2-6121-4687-9a7b-e51ed1c99cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d39fd-03ab-4d87-b629-4f9b57f49ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68291c70-f6ae-4db7-84c0-d9e8bd845871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    return ds\n",
    "\n",
    "def open_and_merge_datasets(folder, model, experiment_id, temp_res, variables):\n",
    "    filepaths = []\n",
    "    for var in variables:\n",
    "        path = f'../../data/CMIP6/{experiment_id}/{folder}/{temp_res}/{var}'\n",
    "        fp = glob.glob(os.path.join(path, f'CMIP.{model}.{experiment_id}.{var}.regridded.nc'))\n",
    "        if fp:\n",
    "            filepaths.append(fp[0])\n",
    "        else:\n",
    "            print(f\"No file found for variable '{var}' in model '{model}'.\")\n",
    "            print(fp)\n",
    "\n",
    "    datasets = [xr.open_dataset(fp) for fp in filepaths]\n",
    "    ds = xr.merge(datasets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "993c5300-0612-483b-b781-8f15b0e7d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month ['tas', 'pr', 'vpd', 'mrro', 'mrso', 'tran', 'lai', 'gpp', 'evspsbl', 'evapo']\n",
      "year ['RX5day']\n",
      "period ['growing_season_length_period']\n"
     ]
    }
   ],
   "source": [
    "for temp_res, vars_in_res in categorized_variables.items():\n",
    "    print(temp_res, vars_in_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea202c30-8eec-4c5f-9360-c3a96314f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_res, vars_in_res in categorized_variables.items():\n",
    "    if vars_in_res == ['RX5day']:\n",
    "            ds_dict_temp[f'{temp_res}'] = load_data(scenario, source_ids_rx5day, 'preprocessed', vars_in_res, temp_res)\n",
    "    else:\n",
    "            ds_dict_temp[f'{temp_res}'] = load_data(scenario, source_ids, 'preprocessed', vars_in_res, temp_res)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb5331-e388-4658-88a3-cda7cf26ff18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291bed2-fd84-4a90-afef-1d9efc6b83e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b771c0d-76bb-456a-b18b-643a8b1d26a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34378a5-da2e-448e-8c2b-00ddd39f91a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e12ac-3bed-4ce1-bcfe-2f45449188db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b4b66-23eb-42ea-9df1-8718d3d560a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19846fd3-a3d1-42e4-85f5-9fa09e753fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ee632-7efe-4442-bfde-a956d0ddfaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabea58-0967-472e-a47a-f961334ac5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6ff7c-660c-46cc-9b9f-094f2f93d882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07bdda-fdeb-4051-bee0-3221a1bb2fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ce2ad-7de7-4c4e-91df-5702bd8a645b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "season=None # None, 'spring', summer, fall, winter\n",
    "ds_dict = lap.load_and_preprocess(vars='all', scenarios=['historical', 'ssp370'], models='all', period=season, yearly_sum=False, period_statistic='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7ca47-05c1-4664-89f2-33cab20a6cbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Subdivide Regions, Compute Mean and Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c3215-7e82-4f74-91cd-6c4553799225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ds_dict_regions = lap.subdivide_region_and_compute_mean(ds_dict, with_global=True, spatial_mean=False) #Only compute spatial mean here if you want to assess a single period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d2102-969b-4901-8e23-9249957091fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_dict_change = lap.compute_change_dict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d0558-8d5a-4ba7-a6f6-470c51e6e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change['ssp370-historical'] = lap.compute_bgws(ds_dict_change['ssp370-historical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db3c1c-c0a6-48b1-8471-49ebd83b761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change_regions_mean = lap.subdivide_region_and_compute_mean(ds_dict_change, with_global=True, spatial_mean=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1edea7-7229-4975-880f-effa5894ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change_regions_mean['ssp370-historical'] = compute_ensemble(ds_dict_change_regions_mean['ssp370-historical'], 'mean')\n",
    "ds_dict_change_regions_mean['ssp370-historical'] = compute_ensemble(ds_dict_change_regions_mean['ssp370-historical'], 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a5a41-845d-4d22-a9b7-af428c5df482",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Compute Subdivisions and Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0a6d9-382d-4822-ad7e-c098615c7d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_with_subdivisions(ds_current, ds_change, variable='bgws'):\n",
    "    # Masks for current dataset\n",
    "    mask_bgws_positive = ds_current[variable] > 0\n",
    "    mask_bgws_negative = ds_current[variable] < 0\n",
    "\n",
    "    # Masks for change dataset\n",
    "    mask_change_positive = ds_change[variable] > 0\n",
    "    mask_change_negative = ds_change[variable] < 0\n",
    "\n",
    "    # Create the subdivision masks\n",
    "    subdivisions_masks = xr.DataArray(\n",
    "        np.array([\n",
    "            mask_bgws_positive & mask_change_negative,\n",
    "            mask_bgws_positive & mask_change_positive,\n",
    "            mask_bgws_negative & mask_change_negative,\n",
    "            mask_bgws_negative & mask_change_positive\n",
    "        ]),\n",
    "        dims=['subdivision', 'lat', 'lon', 'region'],\n",
    "        coords={\n",
    "            'subdivision': [0, 1, 2, 3],\n",
    "            'lat': ds_current.lat,\n",
    "            'lon': ds_current.lon,\n",
    "            'region': ds_current.region\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Expand datasets by broadcasting with subdivision masks\n",
    "    def expand_dataset(ds):\n",
    "        expanded_vars = {}\n",
    "        for name, var in ds.data_vars.items():\n",
    "            # Use the .where() method to mask the data based on the subdivision mask\n",
    "            expanded_var = var.expand_dims({'subdivision': subdivisions_masks['subdivision'].sizes['subdivision']}).where(subdivisions_masks)\n",
    "            expanded_vars[name] = expanded_var\n",
    "        \n",
    "        # Create new dataset with expanded variables\n",
    "        expanded_ds = xr.Dataset(expanded_vars, coords={**ds.coords, 'subdivision': subdivisions_masks['subdivision']})\n",
    "        return expanded_ds\n",
    "\n",
    "    ds_change_expanded = expand_dataset(ds_change)\n",
    "    \n",
    "    ds_change_expanded.attrs = ds_change.attrs\n",
    "\n",
    "    return ds_change_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ef028-60ad-4033-a426-93648910f238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change_subdiv = {}\n",
    "\n",
    "for model, ds in ds_dict_regions_change[list(ds_dict_regions_change.keys())[0]].items():\n",
    "    ds_dict_regions_change_subdiv[model] = expand_with_subdivisions(ds_dict_regions['historical'][model], ds, variable='bgws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccc122-dd5a-4c69-b230-085bac1d83e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a dictionary to hold the mean datasets for each model\n",
    "ds_dict_regional_mean_change_subdiv = {}\n",
    "\n",
    "# Assuming 'ds_dict_regions_change_subdiv' contains your datasets indexed by model names\n",
    "for model, ds in ds_dict_regions_change_subdiv.items():\n",
    "    # Retrieve the total number of regions and subdivisions\n",
    "    num_regions = len(ds.coords['region'])\n",
    "    num_subdivisions = len(ds.coords['subdivision'])\n",
    "    \n",
    "    # Prepare dimensions and coordinates for the new dataset\n",
    "    new_coords = {\n",
    "        'region': ds.coords['region'],\n",
    "        'subdivision': ds.coords['subdivision'],\n",
    "        'abbrevs': ('region', ds.coords['abbrevs'].values),\n",
    "        'names': ('region', ds.coords['names'].values)\n",
    "    }\n",
    "    \n",
    "    # Create a dictionary to store variables with (region, subdivision) dimensions\n",
    "    data_vars = {}\n",
    "\n",
    "    # Loop through each data variable\n",
    "    for var in ds.data_vars:\n",
    "        mean_values = xr.DataArray(\n",
    "            data=np.zeros((num_regions, num_subdivisions)),\n",
    "            dims=['region', 'subdivision'],\n",
    "            coords=new_coords\n",
    "        )\n",
    "\n",
    "        # Loop through each region and subdivision\n",
    "        for region_idx in range(num_regions):\n",
    "            for subdiv_idx in range(num_subdivisions):\n",
    "                # Select data for the current region and subdivision\n",
    "                selected_data = ds[var].isel(region=region_idx, subdivision=subdiv_idx)\n",
    "                \n",
    "                # Compute mean across 'lat' and 'lon' dimensions only\n",
    "                mean_value = selected_data.mean(dim=['lat', 'lon'], skipna=True)\n",
    "                \n",
    "                # Assign the computed mean value to the correct position in the DataArray\n",
    "                mean_values[region_idx, subdiv_idx] = mean_value\n",
    "                \n",
    "        # Copy the attributes from the original variable\n",
    "        mean_values.attrs = ds[var].attrs\n",
    "\n",
    "        # Add the populated DataArray to the data_vars dictionary\n",
    "        data_vars[var] = mean_values\n",
    "\n",
    "    # Create the new dataset with all the variables and coordinates\n",
    "    new_ds = xr.Dataset(data_vars, coords=new_coords)\n",
    "\n",
    "    # Copy all attributes from the original dataset\n",
    "    new_ds.attrs = ds.attrs\n",
    "\n",
    "    # Store the new dataset in the main dictionary\n",
    "    ds_dict_regional_mean_change_subdiv[model] = new_ds\n",
    "\n",
    "# After this loop, ds_dict_regional_mean_change_subdiv will have all the models with their new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916fe753-03c8-4ed7-91db-38fab26249ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change_subdiv['BCC-CSM2-MR'].growing_season_length_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f2cca-072c-4a7a-8b96-c372026018ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change_subdiv['BCC-CSM2-MR'].bgws.isel(subdivision=0, region=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabecc0-4852-4f3a-b6c2-e0b43432dcb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Plot regional var change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b3492-d83d-4545-b50a-c509e2d4fd40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if season == None:\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_period', 'bgws']\n",
    "elif season == 'winter':\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_winter', 'bgws']\n",
    "elif season == 'spring':\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_spring', 'bgws']\n",
    "elif season == 'summer':\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_summer', 'bgws']\n",
    "else:\n",
    "    selected_variables = ['tas', 'vpd', 'RX5day', 'pr', 'mrro', 'tran', 'evapo', \n",
    "                          'evspsbl', 'mrso', 'lai', 'gpp', 'wue', \n",
    "                          'growing_season_length_fall', 'bgws']\n",
    "print(selected_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd68f6-09c9-46c8-adf3-25f77c8b8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region_change(ddict_change_regions_mean, selected_indices, selected_vars=None, common_scale_for_mm_day=True, legend=True, save_fig=False, subdiv=False):\n",
    "    # Load Colormap\n",
    "    bgws_cm, norm = create_bgws_cm()\n",
    "    \n",
    "    # Get all model names\n",
    "    models = list(ds_dict_change.keys())\n",
    "    \n",
    "    # Get data info\n",
    "    variables, display_variables, experiment_id, description, months, yearly_sum, change_type, region_names = extract_variables(ddict_change_regions_mean, selected_vars)\n",
    "    \n",
    "    # Define regions to plot\n",
    "    selected_indices = ddict_change_regions_mean['Ensemble mean'].region.values.tolist() if selected_indices == \"ALL\" else selected_indices\n",
    "    \n",
    "    # Loop over regions to create single plot for each region\n",
    "    for region_idx in selected_indices:\n",
    "        \n",
    "        if subdiv:\n",
    "            for subdiv_idx in range(ddict_change_regions_mean['Ensemble mean'].dims['subdivision']):\n",
    "                # Create figure and axes\n",
    "                fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "                # Create regional plot\n",
    "                plot_region_subd(fig, axes, models, region_idx, ddict_change_regions_mean, variables, display_variables, change_type, bgws_cm, subdiv_idx, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "                # Add legend and colorbar\n",
    "                if legend:\n",
    "                    add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                if save_fig:\n",
    "                    save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, subdiv_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "                else:\n",
    "                    print('Figure not saved. If you want to save the figure add save_fig=True to the function call')\n",
    "\n",
    "        else:\n",
    "             # Create figure and axes\n",
    "            fig, axes = plt.subplots(1, len(variables), sharey=False, figsize=(20, 12))\n",
    "\n",
    "            # Create regional plot\n",
    "            plot_region(fig, axes, models, region_idx, ddict_change_regions_mean, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=common_scale_for_mm_day) \n",
    "\n",
    "            # Add legend and colorbar\n",
    "            if legend:\n",
    "                add_legend_and_colorbar(fig, axes, models, norm, bgws_cm, description, region_names, region_idx)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            if save_fig:\n",
    "                save_figure(fig, change_type, experiment_id, months, yearly_sum, region_names, region_idx, legend=legend, common_scale_for_mm_day=common_scale_for_mm_day)\n",
    "            else:\n",
    "                print('Figure not saved. If you want to save the figure add save_fig=True to the function call')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6033b0-e361-47c6-959b-abc9ca93bc47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region(fig, axes, models, selected_region, ddict_change_regions_mean, variables, display_variables, change_type, bgws_cm, use_common_scale_for_mm_day=True):\n",
    "    # Fetch region and subdivision names for the title\n",
    "    region_name = ddict_change_regions_mean[list(ddict_change_regions_mean.keys())[0]].coords['names'].sel(region=selected_region).item()\n",
    "\n",
    "    # Set the overall title for the plot\n",
    "    plot_title = f\"{region_name}\"\n",
    "    fig.suptitle(plot_title, fontsize=32)\n",
    "\n",
    "    # Identify \"mm/day\" variables\n",
    "    mm_day_variables = ['pr', 'mrro', 'evspsbl', 'tran', 'evapo'] \n",
    "\n",
    "    # Calculate global max and min values for each variable across all subdivisions\n",
    "    global_max_min_values = {}\n",
    "    global_mm_max = -np.inf\n",
    "    global_mm_min = np.inf\n",
    "\n",
    "    for var in variables:\n",
    "        global_max = -np.inf\n",
    "        global_min = np.inf\n",
    "        for model_name, ds in ddict_change_regions_mean.items():\n",
    "            if var in ds.data_vars:\n",
    "                selected_data = ds[var].sel(region=selected_region)\n",
    "                if selected_data.size == 1:\n",
    "                    value = selected_data.values.item()\n",
    "                    if not np.isnan(value):\n",
    "                        if var in mm_day_variables:\n",
    "                            global_mm_max = max(global_mm_max, np.abs(value))\n",
    "                            global_mm_min = min(global_mm_min, -np.abs(value))\n",
    "                        global_max = max(global_max, value)\n",
    "                        global_min = min(global_min, value)\n",
    "                else:\n",
    "                    print(f\"Skipping region {selected_region} for model {model_name} and variable {var} due to multiple values or NaNs\")\n",
    "                    continue\n",
    "        global_max_min_values[var] = (global_min, global_max)\n",
    "\n",
    "    # Adjust axes properties and add variable names\n",
    "    for j, var in enumerate(variables):\n",
    "        if var in mm_day_variables and use_common_scale_for_mm_day:\n",
    "            max_abs_value = max(abs(global_mm_min), abs(global_mm_max)) * 1.05\n",
    "        else:\n",
    "            max_abs_value = max(abs(global_max_min_values[var][0]), abs(global_max_min_values[var][1])) * 1.05\n",
    "\n",
    "        if np.isnan(max_abs_value):\n",
    "            continue\n",
    "        \n",
    "        # Calculate ticks\n",
    "        ticks = adjust_array(np.linspace(-max_abs_value, max_abs_value, num=5))\n",
    "        \n",
    "        # Set the y-axis limits to ensure 0 is always in the middle\n",
    "        axes[j].set_ylim(ticks[0], ticks[-1])\n",
    "        axes[j].set_yticks(ticks)\n",
    "        axes[j].spines['left'].set_bounds(ticks[0], ticks[-1]) # Set bounds for left spine\n",
    "        axes[j].tick_params(axis='y', labelsize=18)  # Adjust y-axis tick label size\n",
    "\n",
    "        # Set x-axis ticks and labels with improved formatting\n",
    "        axes[j].set_xlim(j - 1, j + 1)\n",
    "        axes[j].set_xticks([j])\n",
    "        axes[j].spines['top'].set_visible(False)\n",
    "        axes[j].spines['bottom'].set_visible(False)\n",
    "        axes[j].spines['right'].set_visible(False)\n",
    "        axes[j].set_xticklabels([display_variables[var]], fontdict={'size': 25})\n",
    "        axes[j].tick_params(axis='x', length=10, color='white')  # Adjust x-axis tick label size\n",
    "        \n",
    "        # Add horizontal line at y=0\n",
    "        axes[j].axhline(y=0, color='gray', linestyle='-', linewidth=1)  \n",
    "\n",
    "        # Coloring every second subplot's background\n",
    "        if j % 2 == 0:  # This checks if the index is odd, applying the color to every second subplot\n",
    "            axes[j].set_facecolor('#f0f0f0')  # Light gray background\n",
    "\n",
    "        if j == 0:\n",
    "            # This is the first subplot, so add a y-axis label here\n",
    "            axes[j].set_ylabel(\"End-of-century response\", fontsize=25)\n",
    "    \n",
    "        # Improved tick label formatting to remove unnecessary trailing zeros\n",
    "        if j > 0:  # Check if not the first axis\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' and tick != 0 else '' for tick in ticks])\n",
    "            ticks = axes[j].yaxis.get_major_ticks() \n",
    "            # Modify properties of the first tick\n",
    "            tick_to_modify = 2  # Index of the tick to modify\n",
    "            ticks[tick_to_modify].tick1line.set_markersize(50)\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgecolor('gray')\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgewidth(1)\n",
    "\n",
    "        else:\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' else f'{tick:.2f}' for tick in ticks])\n",
    "\n",
    "    # Set up fixed normalization range from -50 to 50\n",
    "    norm = Normalize(vmin=-50, vmax=50)\n",
    "    \n",
    "    # Iterate over models and variables to plot\n",
    "    for i, model_name in enumerate(models, start=1):\n",
    "        ds = ddict_change_regions_mean[model_name]  # Get the dataset for the current model\n",
    "        prev_xy = None\n",
    "\n",
    "        for j, variable in enumerate(variables):\n",
    "            if variable in ds.data_vars:\n",
    "                value = ds[variable].sel(region=selected_region).values.item()\n",
    "                bgws_value = ds['bgws'].sel(region=selected_region).values.item()\n",
    "                \n",
    "                # Normalize bgws value for color mapping\n",
    "                color = bgws_cm(norm(bgws_value))\n",
    "\n",
    "                current_xy = (j, value)\n",
    "                \n",
    "                if np.isnan(value):\n",
    "                    prev_xy = None\n",
    "                    continue\n",
    "\n",
    "                if model_name.lower() == \"ensemble mean\":\n",
    "                    axes[j].plot(j, value, 'D', mec='red', mfc='none', markersize=22, mew=2, zorder=5)\n",
    "                elif model_name.lower() == \"ensemble median\":\n",
    "                    axes[j].plot(j, value, 'o', mec='orange', mfc='none', markersize=28, mew=2, zorder=4)\n",
    "                else:\n",
    "                    if j % 2 == 0:\n",
    "                        dot_color = '#f0f0f0'\n",
    "                    else: \n",
    "                        dot_color = 'white'\n",
    "                    axes[j].plot(j, value, 'o', color=dot_color, markersize=38, zorder=1)\n",
    "                    axes[j].annotate(str(i), xy=current_xy, xytext=(0, 0), textcoords='offset points',\n",
    "                                     fontsize=38, weight='bold', color=color,\n",
    "                                     ha='center', va='center', zorder=2)\n",
    "\n",
    "                if prev_xy is not None:\n",
    "                    linestyle = '--' if bgws_value < 0 else '-'\n",
    "                    con = ConnectionPatch(xyA=prev_xy, xyB=current_xy, coordsA=\"data\", coordsB=\"data\",\n",
    "                                          axesA=axes[j-1], axesB=axes[j],\n",
    "                                          linestyle=linestyle, shrinkA=17, shrinkB=17, color=color, linewidth=2)  \n",
    "                    fig.add_artist(con)\n",
    "\n",
    "                prev_xy = current_xy\n",
    "            else:\n",
    "                prev_xy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ba7f7-6c3e-4694-aefb-68cbc2ca4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].pr.isel(region=18).values.item()\n",
    "print(f'Precipitation change: {dpr}')\n",
    "dmrro = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].mrro.isel(region=18).values.item()\n",
    "print(f'Runoff change: {dmrro}')\n",
    "dtran = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].tran.isel(region=18).values.item()\n",
    "print(f'Transpiration change: {dtran}')\n",
    "dbgws = ds_dict_change_regions_mean['ssp370-historical']['Ensemble mean'].bgws.isel(region=18).values.item()\n",
    "print(f'delta BGWS: {dbgws}')\n",
    "#Compute BGWS change based on variables\n",
    "bgws_d = ((dmrro - dtran)/dpr) * 100\n",
    "print(f'BGWS_delta: {dbgws}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe38c05-9465-4807-b06a-74a8f96b42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_change(ds_dict_change_regions_mean['ssp370-historical'], \n",
    "                   selected_indices=[18] , # 'ALL' \n",
    "                   selected_vars=selected_variables, \n",
    "                   common_scale_for_mm_day=True,\n",
    "                   legend=False,\n",
    "                   save_fig=False,\n",
    "                   subdiv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55faa03-4294-41a8-9eb4-3c47be6b1f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region_subd(fig, axes, models, selected_region, ds_dict_change, variables, display_variables, change_type, bgws_cm, subdiv_idx, use_common_scale_for_mm_day=True):\n",
    "    # Fetch region and subdivision names for the title\n",
    "    region_name = ds_dict_change[list(ds_dict_change.keys())[0]].coords['names'].sel(region=selected_region).item()\n",
    "    subdivision_name = str(ds_dict_change[list(ds_dict_change.keys())[0]].coords['subdivision'][subdiv_idx].item())\n",
    "\n",
    "    # Set the overall title for the plot\n",
    "    plot_title = f\"{region_name} - Subdivision {subdivision_name}\"\n",
    "    fig.suptitle(plot_title, fontsize=32)\n",
    "\n",
    "    # Identify \"mm/day\" variables\n",
    "    mm_day_variables = ['pr', 'mrro', 'evspsbl', 'tran', 'evapo'] \n",
    "\n",
    "    # Calculate global max and min values for each variable across all subdivisions\n",
    "    global_max_min_values = {}\n",
    "    for var in variables:\n",
    "        global_max = -np.inf\n",
    "        global_min = np.inf\n",
    "        for model_name, ds in ds_dict_change.items():\n",
    "            for subdiv in ds.coords['subdivision']:\n",
    "                if var in ds.data_vars:\n",
    "                    value = ds[var].sel(region=selected_region, subdivision=subdiv).values.item()\n",
    "                    if not np.isnan(value):\n",
    "                        if use_common_scale_for_mm_day and var in mm_day_variables:\n",
    "                            global_max = max(global_max, np.abs(value))\n",
    "                            global_min = min(global_min, -np.abs(value))\n",
    "                        else:\n",
    "                            global_max = max(global_max, value)\n",
    "                            global_min = min(global_min, value)\n",
    "        if use_common_scale_for_mm_day and var in mm_day_variables:\n",
    "            global_max_min_values[var] = (global_min, global_max)\n",
    "        else:\n",
    "            global_max_min_values[var] = (global_min, global_max)\n",
    "\n",
    "    # Adjust axes properties and add variable names\n",
    "    for j, var in enumerate(variables):\n",
    "        # Calculate the maximum absolute value for the variable\n",
    "        if var in global_max_min_values:\n",
    "            max_abs_value = max(abs(global_max_min_values[var][0]), abs(global_max_min_values[var][1])) * 1.05\n",
    "        else:\n",
    "            max_abs_value = 0\n",
    "        \n",
    "        # Calculate ticks\n",
    "        ticks = adjust_array(np.linspace(-max_abs_value, max_abs_value, num=5))\n",
    "        \n",
    "        # Set the y-axis limits to ensure 0 is always in the middle\n",
    "        axes[j].set_ylim(ticks[0], ticks[-1])\n",
    "        axes[j].set_yticks(ticks)\n",
    "        axes[j].spines['left'].set_bounds(ticks[0], ticks[-1]) # Set bounds for left spine\n",
    "        axes[j].tick_params(axis='y', labelsize=18)  # Adjust y-axis tick label size\n",
    "\n",
    "        # Set x-axis ticks and labels with improved formatting\n",
    "        axes[j].set_xlim(j - 1, j + 1)\n",
    "        axes[j].set_xticks([j])\n",
    "        axes[j].spines['top'].set_visible(False)\n",
    "        axes[j].spines['bottom'].set_visible(False)\n",
    "        axes[j].spines['right'].set_visible(False)\n",
    "        axes[j].set_xticklabels([display_variables[var]], fontdict={'size': 25})\n",
    "        axes[j].tick_params(axis='x', length=10, color='white')  # Adjust x-axis tick label size\n",
    "        \n",
    "        # Add horizontal line at y=0\n",
    "        axes[j].axhline(y=0, color='gray', linestyle='-', linewidth=1)  \n",
    "\n",
    "        # Coloring every second subplot's background\n",
    "        if j % 2 == 0:  # This checks if the index is odd, applying the color to every second subplot\n",
    "            axes[j].set_facecolor('#f0f0f0')  # Light gray background\n",
    "\n",
    "        if j == 0:\n",
    "            # This is the first subplot, so add a y-axis label here\n",
    "            axes[j].set_ylabel(\"End-of-century response\", fontsize=25)\n",
    "    \n",
    "        # Improved tick label formatting to remove unnecessary trailing zeros\n",
    "        if j > 0:  # Check if not the first axis\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' and tick != 0 else '' for tick in ticks])\n",
    "            ticks = axes[j].yaxis.get_major_ticks() \n",
    "            # Modify properties of the first tick\n",
    "            tick_to_modify = 2  # Index of the tick to modify\n",
    "            ticks[tick_to_modify].tick1line.set_markersize(50)\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgecolor('gray')\n",
    "            ticks[tick_to_modify].tick1line.set_markeredgewidth(1)\n",
    "\n",
    "        else:\n",
    "            axes[j].set_yticklabels([f'{tick:.2f}'.rstrip('0').rstrip('.') if '.' in f'{tick:.2f}' else f'{tick:.2f}' for tick in ticks])\n",
    "    \n",
    "    # Iterate over models and variables to plot\n",
    "    for i, model_name in enumerate(models, start=1):\n",
    "        ds = ds_dict_change[model_name]  # Get the dataset for the current model\n",
    "        prev_xy = None\n",
    "\n",
    "        for j, variable in enumerate(variables):\n",
    "            if variable in ds.data_vars:\n",
    "                value = ds[variable].sel(region=selected_region, subdivision=subdiv_idx).values.item()\n",
    "                bgws_value = ds['bgws'].sel(region=selected_region, subdivision=subdiv_idx).values.item()\n",
    "                \n",
    "                # Normalize bgws value for color mapping\n",
    "                color = bgws_cm((bgws_value - -0.1) / (0.1 - -0.1))\n",
    "\n",
    "                current_xy = (j, value)\n",
    "                \n",
    "                if np.isnan(value):\n",
    "                    prev_xy = None\n",
    "                    continue\n",
    "\n",
    "                if model_name.lower() == \"ensemble mean\":\n",
    "                    axes[j].plot(j, value, 'D', mec='red', mfc='none', markersize=22, mew=2, zorder=5)\n",
    "                elif model_name.lower() == \"ensemble median\":\n",
    "                    axes[j].plot(j, value, 'o', mec='orange', mfc='none', markersize=28, mew=2, zorder=4)\n",
    "                else:\n",
    "                    if j % 2 == 0:\n",
    "                        dot_color = '#f0f0f0'\n",
    "                    else: \n",
    "                        dot_color = 'white'\n",
    "                    axes[j].plot(j, value, 'o', color=dot_color, markersize=38, zorder=1)\n",
    "                    axes[j].annotate(str(i), xy=current_xy, xytext=(0, 0), textcoords='offset points',\n",
    "                                     fontsize=38, weight='bold', color=color,\n",
    "                                     ha='center', va='center', zorder=2)\n",
    "\n",
    "                if prev_xy is not None:\n",
    "                    linestyle = '--' if bgws_value < 0 else '-'\n",
    "                    con = ConnectionPatch(xyA=prev_xy, xyB=current_xy, coordsA=\"data\", coordsB=\"data\",\n",
    "                                          axesA=axes[j-1], axesB=axes[j],\n",
    "                                          linestyle=linestyle, shrinkA=17, shrinkB=17, color=color, linewidth=2)  \n",
    "                    fig.add_artist(con)\n",
    "\n",
    "                prev_xy = current_xy\n",
    "            else:\n",
    "                prev_xy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222fb72-a624-4353-a369-03f176ef19a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_region_change(ds_dict_regional_mean_change_subdiv, \n",
    "                   selected_indices='ALL', \n",
    "                   selected_vars=selected_variables, \n",
    "                   common_scale_for_mm_day=False,\n",
    "                   legend=False,\n",
    "                   save_fig=True,\n",
    "                   subdiv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185b456-4d55-4c13-b912-cf5b504af7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_change(ds_dict_regions_change[list(ds_dict_regions_change.keys())[0]], \n",
    "                   selected_indices='ALL', \n",
    "                   selected_vars=selected_variables, \n",
    "                   common_scale_for_mm_day=False,\n",
    "                   legend=False,\n",
    "                   save_fig=False,\n",
    "                   subdiv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961ddef-9abc-4057-8e59-728a112bf921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes:\n",
    "# Legend smaller, units and x-axis in generak bigger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
