{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7716ffb9-a564-44c7-87d4-2d4caeecdb1c",
   "metadata": {},
   "source": [
    "# CMIP6 Statistics and Plots\n",
    "\n",
    "**Following steps are included in this script:**\n",
    "\n",
    "1. Load netCDF files\n",
    "2. Compute statistics\n",
    "3. Plot statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5a4f3-40bb-459a-88f0-f180c8b3ee8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854af429-43a1-489d-8513-dca8c1466663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import dask\n",
    "import matplotlib.cm\n",
    "from matplotlib import rcParams\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from cftime import DatetimeNoLeap\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams[\"mathtext.default\"] = 'regular'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5daa16-4811-4773-b98d-6b69626ff6cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb57b43-bbbe-414b-8075-8cda5d1ea4ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9326b-048c-48c2-84e0-5af87d06a120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========= Helper function to open the dataset ========\n",
    "def open_dataset(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ca849-c1f4-431c-ae0f-e6a3fb6ba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to open and merge datasets\n",
    "def open_and_merge_datasets(folder, model, experiment_id, variables):\n",
    "    filepaths = []\n",
    "    for var in variables:\n",
    "        path = f'../../data/CMIP6/{experiment_id}/{folder}/{var}'\n",
    "        fp = glob.glob(os.path.join(path, f'CMIP.{model}.{experiment_id}.{var}_regridded.nc'))\n",
    "        if fp:\n",
    "            filepaths.append(fp[0])\n",
    "        else:\n",
    "            #print(f\"No file found for variable '{var}' in model '{model}'.\")\n",
    "            print(fp)\n",
    "\n",
    "    datasets = [xr.open_dataset(fp) for fp in filepaths]\n",
    "    ds = xr.merge(datasets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9148cef-f033-40ac-aeef-dec5ccdb277d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79176a9d-1bde-438d-a226-9c749fc98042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_period(ds_dict, start_year=None, end_year=None):\n",
    "    '''\n",
    "    Helper function to select periods.\n",
    "    \n",
    "    Parameters:\n",
    "    ds_dict (dict): Dictionary with xarray datasets.\n",
    "    start_year (int): The start year of the period.\n",
    "    end_year (int): The end year of the period.\n",
    "    \"\"\"\n",
    "    '''\n",
    "    start_year = DatetimeNoLeap(start_year, 1, 16, 12, 0, 0, 0,has_year_zero=True) # 16th of January of start year\n",
    "    end_year = DatetimeNoLeap(end_year, 12, 16, 12, 0, 0, 0, has_year_zero=True) # 16th of December of end year\n",
    "    ds_dict = {k: v.sel(time=slice(start_year, end_year)) for k, v in ds_dict.items()}\n",
    "    \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a690d-ac2f-4875-96dc-66e8424a4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Standardize ========\n",
    "def standardize(ds_dict):\n",
    "    '''\n",
    "    Helper function to standardize datasets of a dictionary\n",
    "    '''\n",
    "    ds_dict_stand = {}\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        attrs = ds.attrs\n",
    "        ds_stand = (ds - ds.mean()) / ds.std()\n",
    "\n",
    "        # Preserve variable attributes from the original dataset\n",
    "        for var in ds.variables:\n",
    "            if var in ds_stand.variables:\n",
    "                ds_stand[var].attrs = ds[var].attrs\n",
    "\n",
    "        ds_stand.attrs = attrs\n",
    "        ds_dict_stand[name] = ds_stand\n",
    "        \n",
    "    return ds_dict_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090c127-204b-4d69-9e33-5769b28e4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args_and_get_info(ds_dict, variable):\n",
    "    # Check the validity of input arguments\n",
    "    if not isinstance(ds_dict, dict):\n",
    "        raise TypeError(\"ds_dict must be a dictionary of xarray datasets.\")\n",
    "    if not all(isinstance(ds, xr.Dataset) for ds in ds_dict.values()):\n",
    "        raise TypeError(\"All values in ds_dict must be xarray datasets.\")\n",
    "    if not isinstance(variable, str):\n",
    "        raise TypeError('variable must be a string.')\n",
    "        \n",
    "    # Dictionary to store plot titles for each statistic\n",
    "    titles = {\"mean\": \"Mean\", \"std\": \"Standard deviation of yearly means\", \"min\": \"Minimum\", \"max\": \"Maximum\", \"median\": \"Median\", \"time\": \"Time\", \"space\": \"Space\"}\n",
    "    freq = {\"mon\": \"Monthly\"}\n",
    "    \n",
    "    long_name = {\n",
    "        'Precipitation': 'Precipitation',\n",
    "        'Total Runoff': 'Total Runoff',\n",
    "        'Vapor Pressure Deficit': 'Vapor Pressure Deficit',\n",
    "        'Evaporation Including Sublimation and Transpiration': 'Evapotranspiration',\n",
    "        'Transpiration': 'Transpiration',\n",
    "        'Leaf Area Index': 'Leaf Area Index',\n",
    "        'Carbon Mass Flux out of Atmosphere Due to Gross Primary Production on Land [kgC m-2 s-1]': 'Gross Primary Production',\n",
    "        'Total Liquid Soil Moisture Content of 1 m Column': '1 m Soil Moisture',\n",
    "        'Total Liquid Soil Moisture Content of 2 m Column': '2 m Soil Moisture',\n",
    "        'Runoff - Precipitation': 'Runoff - Precipitation',\n",
    "        'Transpiration - Precipitation': 'Transpiration - Precipitation',\n",
    "        '(Runoff + Transpiration) - Precipitation':  '(Runoff + Transpiration) - Precipitation',\n",
    "        'ET - Precipitation':  'ET - Precipitation', \n",
    "        'Negative Runoff': 'Negative Runoff',\n",
    "    }\n",
    "   \n",
    "    # Data information\n",
    "    var_long_name = ds_dict[list(ds_dict.keys())[0]][variable].long_name\n",
    "    period = f\"{ds_dict[list(ds_dict.keys())[0]].attrs['period'][0]}-{ds_dict[list(ds_dict.keys())[0]].attrs['period'][1]}\"\n",
    "    experiment_id =  ds_dict[list(ds_dict.keys())[0]].experiment_id\n",
    "    unit = ds_dict[list(ds_dict.keys())[0]][variable].units\n",
    "    statistic_dim = ds_dict[list(ds_dict.keys())[0]].statistic_dimension\n",
    "    statistic = ds_dict[list(ds_dict.keys())[0]].attrs['statistic']\n",
    "    frequency = freq[ds_dict[list(ds_dict.keys())[0]].frequency]\n",
    "\n",
    "    return var_long_name, period, unit, statistic_dim, statistic, experiment_id, titles, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54437cf1-8268-4619-b224-e6be3684894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ensemble(ds_dict):\n",
    "    # Combine all datasets into one larger dataset\n",
    "    combined = xr.concat(ds_dict.values(), dim='ensemble')\n",
    "    # Compute the ensemble metric\n",
    "    ds_dict['Ensemble mean'] = getattr(combined, 'mean')(dim='ensemble')#, skipna=True) # use getattr to call method by string name\n",
    "    \n",
    "    # Preserve variable attributes from the original dataset\n",
    "    for var in ds_dict['Ensemble mean'].variables:\n",
    "        ds_dict['Ensemble mean'][var].attrs = ds_dict[list(ds_dict.keys())[0]][var].attrs\n",
    "    \n",
    "    ds_dict['Ensemble mean'].attrs = {\"period\" : ds_dict[list(ds_dict.keys())[0]].attrs['period'],\n",
    "                           \"statistic\" : \"mean\", # use variable metric here\n",
    "                           \"statistic_dimension\" : \"time\",\n",
    "                           \"experiment_id\": \"ssp370-historical\", \n",
    "                           \"source_id\" : f\"Ensemble mean\",\n",
    "                           \"frequency\":  ds_dict[list(ds_dict.keys())[0]].attrs['frequency']} \n",
    "    \n",
    "    ds_dict['Ensemble median'] = getattr(combined, 'median')(dim='ensemble')#, skipna=True) # use getattr to call method by string name\n",
    "    \n",
    "    ds_dict['Ensemble median'].attrs = {\"period\" : ds_dict[list(ds_dict.keys())[0]].attrs['period'],\n",
    "                           \"statistic\" : \"median\", # use variable metric here\n",
    "                           \"statistic_dimension\" : \"time\",\n",
    "                           \"experiment_id\": \"ssp370-historical\", \n",
    "                           \"source_id\": f\"Ensemble median\",\n",
    "                           \"frequency\":  ds_dict[list(ds_dict.keys())[0]].attrs['frequency']} \n",
    "    \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a2736-eb0f-466e-b547-4d293e8a5af5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766cd9d-393f-4db9-b0a3-744388ad88c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_statistic_single(ds, statistic, dimension, yearly_mean=True):\n",
    "    if dimension == \"time\":\n",
    "        stat_ds = getattr(ds, statistic)(\"time\", keep_attrs=True, skipna=True)\n",
    "        stat_ds.attrs['period'] = [str(ds.time.dt.year[0].values), str(ds.time.dt.year[-1].values)]\n",
    "        \n",
    "    if dimension == \"space\":\n",
    "        # Assign the period attribute before grouping by year\n",
    "        ds.attrs['period'] = [str(ds.time.dt.year[0].values), str(ds.time.dt.year[-1].values)]\n",
    "        \n",
    "        if yearly_mean:\n",
    "            ds = ds.groupby('time.year').mean('time', keep_attrs=True, skipna=True)\n",
    "            ds.attrs['mean'] = 'yearly mean'\n",
    "            \n",
    "        \n",
    "        #get the weights, apply on data, and compute statistic\n",
    "        weights = np.cos(np.deg2rad(ds.lat))\n",
    "        weights.name = \"weights\"\n",
    "        ds_weighted = ds.weighted(weights)\n",
    "        stat_ds = getattr(ds_weighted, statistic)((\"lon\", \"lat\"), keep_attrs=True, skipna=True)\n",
    "    \n",
    "    stat_ds.attrs['statistic'] = statistic\n",
    "    stat_ds.attrs['statistic_dimension'] = dimension\n",
    "\n",
    "    return stat_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadad33e-375e-4f6f-94b1-918dce7e2f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_statistic(ds_dict, statistic, dimension, start_year=None, end_year=None, yearly_mean=True):\n",
    "    \"\"\"\n",
    "    Computes the specified statistic for each dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        statistic (str): The statistic to compute, which can be one of 'mean', 'std', 'min', 'var', or 'median'.\n",
    "        dimension (str): The dimension to compute over, which can be 'time' or 'space'.\n",
    "        start_year (str, optional): The start year of the period to compute the statistic over.\n",
    "        end_year (str, optional): The end year of the period to compute the statistic over.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with computed statistic for each dataset.\n",
    "    \"\"\"\n",
    "    # Check the validity of input arguments\n",
    "    if not isinstance(ds_dict, dict):\n",
    "        raise TypeError(\"ds_dict must be a dictionary of xarray datasets.\")\n",
    "    if not all(isinstance(ds, xr.Dataset) for ds in ds_dict.values()):\n",
    "        raise TypeError(\"All values in ds_dict must be xarray datasets.\")\n",
    "    if statistic not in [\"mean\", \"std\", \"min\", \"max\", \"var\", \"median\"]:\n",
    "        raise ValueError(f\"Invalid statistic '{statistic}' specified.\")\n",
    "    if dimension not in [\"time\", \"space\"]:\n",
    "        raise ValueError(f\"Invalid dimension '{dimension}' specified.\")\n",
    "\n",
    "    # Select period\n",
    "    if start_year is not None and end_year is not None:\n",
    "        select_period(ds_dict, start_year=start_year, end_year=end_year)\n",
    "        \n",
    "        \n",
    "    # Use multiprocessing to compute the statistic for each dataset in parallel\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.starmap(compute_statistic_single, [(ds, statistic, dimension, yearly_mean) for ds in ds_dict.values()])\n",
    "\n",
    "    return dict(zip(ds_dict.keys(), results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55955a2d-2e0a-41ba-bdd8-d0d8b8211506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from itertools import combinations\n",
    "\n",
    "# Define a function to compute the metrics\n",
    "def compute_metrics_for_pair(args):\n",
    "    df, var1, var2, metrics = args\n",
    "    valid_values = np.logical_and(np.isfinite(df[var1]), np.isfinite(df[var2]))\n",
    "\n",
    "    # Compute metrics\n",
    "    X = df[var1][valid_values].values.reshape(-1, 1)\n",
    "    y = df[var2][valid_values].values\n",
    "    metric_dict = {}\n",
    "\n",
    "    if 'rmse_rf' in metrics:\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(X, y)\n",
    "        y_pred_rf = rf.predict(X)\n",
    "        rmse_rf = np.sqrt(mean_squared_error(y, y_pred_rf))\n",
    "        metric_dict['rmse_rf'] = rmse_rf\n",
    "    \n",
    "    if 'rmse_lr' or 'r2_lr' in metrics:\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X, y)\n",
    "        y_pred_lr = lr.predict(X)\n",
    "        if 'rmse_lr' in metrics:\n",
    "            rmse_lr = np.sqrt(mean_squared_error(y, y_pred_lr))\n",
    "            metric_dict['rmse_lr'] = rmse_lr\n",
    "        if 'r2_lr' in metrics:\n",
    "            r2_lr = r2_score(y, y_pred_lr) # compute the R^2 (coefficient of determination)\n",
    "            metric_dict['r2_lr'] = r2_lr\n",
    "\n",
    "    if 'pearson' in metrics:\n",
    "        r_pearson = pearsonr(X.flatten(), y)[0]\n",
    "        metric_dict['pearson'] = r_pearson\n",
    "\n",
    "    if 'spearman' in metrics:\n",
    "        r_spearman = spearmanr(X.flatten(), y)[0]\n",
    "        metric_dict['spearman'] = r_spearman\n",
    "        \n",
    "    if 'kendalltau' in metrics:\n",
    "        tau_kendall = kendalltau(X.flatten(), y)[0]\n",
    "        metric_dict['kendalltau'] = tau_kendall\n",
    "\n",
    "    return (var1, var2, metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d176a36-95a5-4a18-b46f-a311e49243f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def precompute_metrics(ds_dict, variables, metrics=['pearson']):\n",
    "    # Initialize the results dictionary\n",
    "    results_dict = {metric: {} for metric in metrics}\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        # Create a DataFrame with all the variables\n",
    "        df = pd.DataFrame({var: ds[var].values.flatten() for var in variables})\n",
    "        \n",
    "        # Define all pairs of variables\n",
    "        pairs = list(permutations(variables, 2))  # <-- Change here\n",
    "        args = [(df, var1, var2, metrics) for var1, var2 in pairs]\n",
    "\n",
    "        # Use a multiprocessing pool to compute the metrics for all pairs\n",
    "        with Pool() as p:\n",
    "            results = p.map(compute_metrics_for_pair, args)\n",
    "        \n",
    "        # Store the results in the results_dict\n",
    "        for var1, var2, metric_dict in results:\n",
    "            for metric, value in metric_dict.items():\n",
    "                # Ensure the keys exist in the dictionary\n",
    "                results_dict[metric].setdefault(name, {}).setdefault(f'{var1}_{var2}', value)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de1242-8b90-44db-903d-6ae01d25b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yearly_correlations(ds_dict, variable_pairs, start_year=None, end_year=None, corr_type='pearson'):\n",
    "    \"\"\"\n",
    "    Calculates yearly Pearson correlation for the given pairs of variables from the same model.\n",
    "\n",
    "    Parameters:\n",
    "    ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "    variable_pairs (list of tuples): The pairs of variables to calculate the correlation for.\n",
    "    start_year (int): The start year of the period to compute the correlation over.\n",
    "    end_year (int): The end year of the period to compute the correlation over.\n",
    "    corr_type (str): The type of correlation coefficient to compute. Can be either 'pearson', 'spearman', or 'kendall'.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with a DataFrame for each dataset, where each DataFrame contains the yearly Pearson\n",
    "        correlation for each pair of variables.\n",
    "    \"\"\"\n",
    "    # Map for complete metric names and symbols\n",
    "    metric_map = {\n",
    "        'r2_lr': ('Coefficient of Determination', 'R²'),\n",
    "        'pearson': ('Pearson Correlation Coefficient', 'r'),\n",
    "        'spearman': ('Spearman Rank Correlation Coefficient', 'ρ'),\n",
    "        'kendalltau': ('Kendall Rank Correlation Coefficient', 'τ')\n",
    "    }\n",
    "    \n",
    "    # Select period\n",
    "    if start_year is not None and end_year is not None:\n",
    "        select_period(ds_dict, start_year=start_year, end_year=end_year)\n",
    "\n",
    "    yearly_correlations = {}\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        yearly_corr_dict = {}\n",
    "\n",
    "        # Resample to yearly data\n",
    "        ds_yearly = ds.resample(time='1Y').mean()\n",
    "        \n",
    "        for var1, var2 in variable_pairs:\n",
    "            # Prepare empty list for yearly correlations\n",
    "            yearly_correlations_values = []\n",
    "            yearly_correlations_years = []\n",
    "\n",
    "            # Get the unique years\n",
    "            years = ds_yearly['time'].dt.year\n",
    "            for year in np.unique(years):\n",
    "                # Select the data for this year\n",
    "                ds_year = ds_yearly.sel(time=f'{year}')\n",
    "                \n",
    "                # Calculate the correlation for this year and append to the list\n",
    "                if corr_type == 'pearson':\n",
    "                    corr_value = xr.corr(ds_year[var1], ds_year[var2], dim=['lon', 'lat'])\n",
    "                    \n",
    "                elif corr_type == 'spearman':\n",
    "                    ds_year_stacked = ds_year.stack(z=('lon', 'lat'))\n",
    "                    df = ds_year_stacked.to_dataframe()\n",
    "                    #df = np.isfinite(df[var1])\n",
    "                    corr_value, _ = spearmanr(df[var1], df[var2])\n",
    "                    corr_value = xr.DataArray(corr_value)\n",
    "                    \n",
    "                elif corr_type == 'kendall':\n",
    "                    ds_year_stacked = ds_year.stack(z=('lon', 'lat'))\n",
    "                    df = ds_year_stacked.to_dataframe()\n",
    "                    corr_value, _ = kendalltau(df[var1], df[var2])\n",
    "                    corr_value = xr.DataArray(corr_value)\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid correlation type. Expected 'pearson', 'spearman', or 'kendall'.\")\n",
    "\n",
    "                # Calculate the correlation for this year and append to the list\n",
    "                #corr_value = xr.corr(ds_year[var1], ds_year[var2], dim=['lon', 'lat'])\n",
    "\n",
    "                yearly_correlations_values.append(float(corr_value.values)) # Extract the scalar value\n",
    "                yearly_correlations_years.append(year)\n",
    "\n",
    "            # Store in the yearly_corr_dict\n",
    "            yearly_corr_dict[f'{var1}-{var2}'] = xr.DataArray(yearly_correlations_values, dims='time', coords={'time': yearly_correlations_years})\n",
    "\n",
    "        # Create a Dataset from the yearly_corr_dict and store in the yearly_correlations dict\n",
    "        yearly_correlations[name] = xr.Dataset(yearly_corr_dict)\n",
    "        yearly_correlations[name].attrs = {'Metric': metric_map[corr_type][0],\n",
    "                                           'Metric_sign': metric_map[corr_type][1]\n",
    "                                          }\n",
    "\n",
    "    return yearly_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9381cb-6944-4552-b6c7-aac1b6a3c6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_stats(ds_dict):\n",
    "    \"\"\"\n",
    "    Compute yearly mean of each variable in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ds_dict (dict): The input dictionary of xarray.Dataset.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are the dataset names and the values are another dictionary.\n",
    "          This inner dictionary has keys as variable names and values as DataArray of yearly means.\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    for model, ds in ds_dict.items():\n",
    "        # Compute the yearly mean\n",
    "        yearly_ds = ds.resample(time='1Y').mean()\n",
    "\n",
    "        stats[model] = {}\n",
    "        for var in yearly_ds.data_vars:\n",
    "            # Compute the spatial mean\n",
    "            spatial_mean = yearly_ds[var].mean(dim=['lat', 'lon'])\n",
    "            \n",
    "            # Store the yearly mean values\n",
    "            stats[model][var] = spatial_mean\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbbc45-b47c-461b-99db-d20d9fa0625d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_yearly_means(ds_dict_region):\n",
    "    yearly_means_dict = {}\n",
    "\n",
    "    # For each dataset, compute the yearly mean over the 'time', 'lat', and 'lon' dimensions\n",
    "    for region, ds_dict in ds_dict_region.items():\n",
    "        yearly_means_dict[region] = {}\n",
    "        for ds_name, ds in ds_dict.items():\n",
    "            # Create weights\n",
    "            weights = np.cos(np.deg2rad(ds.lat))\n",
    "\n",
    "            # Compute the yearly mean\n",
    "            ds_yearly = ds.groupby('time.year').mean('time')\n",
    "\n",
    "            # Apply the weights and calculate the spatial mean\n",
    "            ds_weighted = ds_yearly.weighted(weights)\n",
    "            yearly_means_dict[region][ds_name] = ds_weighted.mean(('lat', 'lon'))\n",
    "\n",
    "    return yearly_means_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea5cb4-d7fa-4edc-afee-645ddfd6f9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_correlation_coefficients(ds_dict, variables, time_dim='time', yearly_corr=False, target_var=None):\n",
    "    \"\"\"\n",
    "    Compute the correlation coefficients for different variable combinations and\n",
    "    store them in a new dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        variables (list): A list of variables for which to compute the correlation coefficients.\n",
    "        time_dim (str): The name of the time dimension in the datasets. Default is 'time'.\n",
    "        yearly_corr (bool): If True, compute correlation of yearly mean data. Default is False.\n",
    "        target_var (str, optional): If provided, only compute correlations with this variable. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary where keys are the same as in the input dictionary, and each value is an xarray Dataset\n",
    "              containing correlation coefficients for different variable combinations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new dictionary to store the correlation data\n",
    "    ds_dict_corr = {}\n",
    "\n",
    "    # Determine the combinations of variables to compute correlations for\n",
    "    if target_var is not None:\n",
    "        if target_var not in variables:\n",
    "            raise ValueError(f\"Target variable '{target_var}' not found in the list of variables.\")\n",
    "        var_combinations = [(target_var, var) for var in variables if var != target_var]\n",
    "    else:\n",
    "        var_combinations = combinations(variables, 2)\n",
    "\n",
    "    # Iterate over all combinations of two variables\n",
    "    for var1, var2 in var_combinations:\n",
    "        # Iterate over all datasets in the dictionary\n",
    "        for ds_name, ds in ds_dict.items():\n",
    "            # Check if both variables exist in the current dataset\n",
    "            if var1 in ds and var2 in ds:\n",
    "                if yearly_corr:\n",
    "                    # Resample the dataset to yearly data\n",
    "                    ds_corr = ds.resample({time_dim: 'Y'}).mean()\n",
    "                else:\n",
    "                    ds_corr = ds\n",
    "                \n",
    "                # If the dataset is not yet in the new dictionary, create a new xarray Dataset for it\n",
    "                if ds_name not in ds_dict_corr:\n",
    "                    ds_dict_corr[ds_name] = xr.Dataset()\n",
    "\n",
    "                # Compute the correlation coefficients and add them as a new DataArray to the Dataset\n",
    "                ds_dict_corr[ds_name][f'{var1} x {var2}'] = xr.corr(ds_corr[var1], ds_corr[var2], dim=time_dim)\n",
    "                ds_dict_corr[ds_name].attrs = ds_dict[ds_name].attrs\n",
    "                ds_dict_corr[ds_name].attrs['Metric'] = 'Pearson Correlation Coefficient'\n",
    "                ds_dict_corr[ds_name].attrs['Metric_sign'] = 'r'\n",
    "                \n",
    "                if yearly_corr:\n",
    "                    ds_dict_corr[ds_name].attrs['means'] = 'yearly means'\n",
    "                else:\n",
    "                    ds_dict_corr[ds_name].attrs['means'] = 'monthly means'\n",
    "                \n",
    "                \n",
    "    return ds_dict_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53592816-7215-44ef-8f2d-55e90f54e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation_coefficients(ds_dict, variables, time_dim='time', yearly_corr=False):\n",
    "    \"\"\"\n",
    "    Compute the correlation coefficients for different variable combinations and\n",
    "    store them in a new dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        variables (list): A list of variables for which to compute the correlation coefficients.\n",
    "        time_dim (str): The name of the time dimension in the datasets. Default is 'time'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary where keys are the same as in the input dictionary, and each value is an xarray Dataset\n",
    "              containing correlation coefficients for different variable combinations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a new dictionary to store the correlation data\n",
    "    ds_dict_corr = {}\n",
    "\n",
    "    # Iterate over all combinations of two variables\n",
    "    for var1, var2 in combinations(variables, 2):\n",
    "        # Iterate over all datasets in the dictionary\n",
    "        for ds_name, ds in ds_dict.items():\n",
    "            # Check if both variables exist in the current dataset\n",
    "            if var1 in ds and var2 in ds:\n",
    "                if yearly_corr:\n",
    "                    # Resample the dataset to yearly data\n",
    "                    ds_corr = ds.resample({time_dim: 'Y'}).mean()\n",
    "                else:\n",
    "                    ds_corr = ds\n",
    "                \n",
    "                # If the dataset is not yet in the new dictionary, create a new xarray Dataset for it\n",
    "                if ds_name not in ds_dict_corr:\n",
    "                    ds_dict_corr[ds_name] = xr.Dataset()\n",
    "\n",
    "                # Compute the correlation coefficients and add them as a new DataArray to the Dataset\n",
    "                ds_dict_corr[ds_name][f'{var1} x {var2}'] = xr.corr(ds_corr[var1], ds_corr[var2], dim=time_dim)\n",
    "                ds_dict_corr[ds_name].attrs = ds_dict[ds_name].attrs\n",
    "                ds_dict_corr[ds_name].attrs['Metric'] = 'Pearson Correlation Coefficient'\n",
    "                ds_dict_corr[ds_name].attrs['Metric_sign'] = 'r'\n",
    "                \n",
    "                if yearly_corr:\n",
    "                    ds_dict_corr[ds_name].attrs['means'] = 'yearly means'\n",
    "                else:\n",
    "                    ds_dict_corr[ds_name].attrs['means'] = 'monthly means'\n",
    "                \n",
    "                \n",
    "    return ds_dict_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e6ced-227e-41b6-972f-79bb4e110c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_change_corr(ds_dict_hist_corr, ds_dict_ssp370_corr):\n",
    "    ds_dict_corr_change = {}\n",
    "\n",
    "    for name, ds in ds_dict_hist_corr.items():\n",
    "        ds_dict_corr_change[name] = ds_dict_ssp370_corr[name] - ds\n",
    "        ds_dict_corr_change[name].attrs = {'period': 'Change Correlation SSP370 - Historical',\n",
    "                                      'statistic': 'mean',\n",
    "                                      'statistic_dimension':  'time',\n",
    "                                      'experiment_id': 'ssp370-historical',\n",
    "                                      'source_id': name,\n",
    "                                      'Metric': 'Pearson Correlation Coefficient',\n",
    "                                      'Metric_sign': 'r'\n",
    "                                    }\n",
    "        if ds_dict_hist_corr[name].attrs['means'] == 'yearly means' and ds_dict_ssp370_corr[name].attrs['means'] == 'yearly means':\n",
    "            ds_dict_corr_change[name].attrs['means'] = 'yearly means'\n",
    "        elif ds_dict_hist_corr[name].attrs['means'] == 'monthly means' and ds_dict_ssp370_corr[name].attrs['means'] == 'monthly means':\n",
    "            ds_dict_corr_change[name].attrs['means'] = 'monthly means'\n",
    "        else:\n",
    "            raise ValueError(f\"Computing change between seasonal and monthly mean data.\")\n",
    "            \n",
    "        return ds_dict_corr_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3356085-14f7-460a-afdd-c52cb2dcb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_change(ds_dict_hist_mean, ds_dict_ssp370_mean, relative_change=False, iqr=False):\n",
    "    ds_dict_change = {}\n",
    "\n",
    "    for name, ds in ds_dict_hist_mean.items():\n",
    "        # Compute either absolute or relative change\n",
    "        if relative_change:\n",
    "            \n",
    "            # Convert temperature back to Kelvin to not have negative and positive values\n",
    "            attrs = ds_dict_hist_mean[name]['tas'].attrs\n",
    "            ds_dict_hist_mean[name]['tas'] = ds_dict_hist_mean[name]['tas'] + 273.15\n",
    "            ds_dict_hist_mean[name]['tas'].attrs = attrs\n",
    "            ds_dict_hist_mean[name]['tas'].attrs['units'] = 'K'\n",
    "            \n",
    "            attrs = ds_dict_ssp370_mean[name]['tas'].attrs\n",
    "            ds_dict_ssp370_mean[name]['tas'] = ds_dict_ssp370_mean[name]['tas'] + 273.15\n",
    "            ds_dict_ssp370_mean[name]['tas'].attrs = attrs\n",
    "            ds_dict_ssp370_mean[name]['tas'].attrs['units'] = 'K'\n",
    "            \n",
    "            ds_f = ds_dict_ssp370_period_metric_rel[name]\n",
    "\n",
    "            # Compute relative change only where ds is not 0\n",
    "            rel_change = ds.where(ds != 0)\n",
    "            rel_change = ((ds_f - rel_change) / abs(rel_change)) * 100\n",
    "\n",
    "            # Where ds was 0, set the corresponding relative change to np.nan\n",
    "            rel_change = rel_change.where(ds != 0)\n",
    "\n",
    "            if iqr:\n",
    "                # Compute the IQR and use it for filtering\n",
    "                q1 = rel_change.quantile(0.25)\n",
    "                q3 = rel_change.quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                lower_bound = q1 - 4 * iqr\n",
    "                upper_bound = q3 + 4 * iqr\n",
    "\n",
    "                # Apply the condition\n",
    "                condition = (rel_change >= lower_bound) & (rel_change <= upper_bound)\n",
    "                rel_change = rel_change.where(condition)\n",
    "\n",
    "            ds_dict_change[name] = rel_change\n",
    "            \n",
    "        else:\n",
    "            ds_dict_change[name] = ds_dict_ssp370_mean[name] - ds\n",
    "            \n",
    "        ds_dict_change[name].attrs = {'period': 'Change SSP370 - Historical',\n",
    "                                      'statistic': ds_dict_ssp370_mean[name].statistic,\n",
    "                                      'statistic_dimension':  ds_dict_ssp370_mean[name].statistic_dimension,\n",
    "                                      'experiment_id': 'ssp370-historical',\n",
    "                                      'source_id': ds_dict_ssp370_mean[name].source_id,\n",
    "                                      'frequency': ds_dict_ssp370_mean[name].frequency\n",
    "                                    }\n",
    "        for variables in ds:\n",
    "            ds_dict_change[name][variables].attrs = ds_dict_ssp370_mean[name][variables].attrs\n",
    "            if relative_change:\n",
    "                ds_dict_change[name][variables].attrs['units_rel'] = '%'\n",
    "                ds_dict_change[name].attrs['change'] = 'Relative Change'\n",
    "            else:\n",
    "                ds_dict_change[name].attrs['change'] = 'Absolute Change'\n",
    "             \n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00be5-44a2-4324-8372-b58068c448b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_nbwfp(ds_dict):\n",
    "\n",
    "    for model, ds in ds_dict.items():\n",
    "        nbwfp = (ds['mrro']-ds['tran'])/ds['pr']\n",
    "\n",
    "        # Replace infinite values with NaN\n",
    "        nbwfp = xr.where(np.isinf(nbwfp), float('nan'), nbwfp)\n",
    "\n",
    "        # Set all values above 2 and below -2 to NaN\n",
    "        nbwfp = xr.where(nbwfp > 2, float('nan'), nbwfp)\n",
    "        nbwfp = xr.where(nbwfp < -2, float('nan'), nbwfp)\n",
    "\n",
    "        ds_dict[model]['nbwfp'] = nbwfp\n",
    "        ds_dict[model]['nbwfp'].attrs = {'long_name': 'Net Blue Water Flux / Precipitation',\n",
    "                             'units': ''}\n",
    "        \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974fda1a-fbb2-409f-9a9c-4a66e040acb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bcbe1-d55f-47bf-9d7a-35b919446ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_mean_values(stats_hist, stats_ssp370, scaling_both=False, scaling_hist=False, full_variable_names=None):\n",
    "    \"\"\"\n",
    "    Plots the boxplots for each variable in each model.\n",
    "\n",
    "    Parameters:\n",
    "    stats_hist (dict): The statistics for the historical period.\n",
    "    stats_ssp370 (dict): The statistics for the SSP370 scenario.\n",
    "    scaling (bool): whether to scale y-axis data.\n",
    "    full_variable_names (dict): dictionary of full variable names.\n",
    "    \"\"\"\n",
    "    # Get the list of variables\n",
    "    variables = list(stats_hist[next(iter(stats_hist))].keys())\n",
    "\n",
    "    # Calculate the number of plots and dimensions of the grid of subplots\n",
    "    n_plots = len(variables)\n",
    "    n_cols = min(n_plots, 3)  # Maximum 3 plots in a row\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "\n",
    "    # Create the figure\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows), squeeze=False)\n",
    "    axs = axs.flatten()  # Flatten the axes array\n",
    "\n",
    "    for i, var in enumerate(variables):\n",
    "        # Prepare lists to store yearly mean values\n",
    "        yearly_means_hist, yearly_means_ssp370 = [], []\n",
    "\n",
    "        for name in stats_hist.keys():\n",
    "            # Extract the yearly mean values for the historical period\n",
    "            yearly_means_hist.append(stats_hist[name][var].values)\n",
    "            \n",
    "            # Extract the yearly mean values for the SSP370 scenario\n",
    "            yearly_means_ssp370.append(stats_ssp370[name][var].values)\n",
    "\n",
    "        # Standardize the data if requested\n",
    "        if scaling_hist:\n",
    "            scaler = StandardScaler()\n",
    "            yearly_means_hist = [scaler.fit_transform(np.array(x).reshape(-1, 1)).flatten() for x in yearly_means_hist]\n",
    "            yearly_means_ssp370 = [scaler.transform(np.array(x).reshape(-1, 1)).flatten() for x in yearly_means_ssp370]\n",
    "            \n",
    "            fig.suptitle(f'Yearly Means of Variables for Historical (1985-2014) and SSP370 (2071-2100) Period Normalized by Historical Mean and Standard Deviation of Historical Data', fontsize=12, y=1.0)\n",
    "            suffix = \"_scaled_historical\"\n",
    "        elif scaling_both:\n",
    "            scaler_hist = StandardScaler()\n",
    "            yearly_means_hist = [scaler_hist.fit_transform(np.array(x).reshape(-1, 1)).flatten() for x in yearly_means_hist]\n",
    "\n",
    "            scaler_ssp370 = StandardScaler()\n",
    "            yearly_means_ssp370 = [scaler_ssp370.fit_transform(np.array(x).reshape(-1, 1)).flatten() for x in yearly_means_ssp370]\n",
    "            \n",
    "            fig.suptitle(f'Yearly Means of Variables for Historical (1985-2014) and SSP370 (2071-2100) Period Normalized by Respective Mean and Standard Deviation', fontsize=12, y=1.0)\n",
    "            suffix = \"_scaled_both\"\n",
    "        else:\n",
    "            fig.suptitle(f'Yearly Means of Variables for Historical (1985-2014) and SSP370 (2071-2100)', fontsize=12, y=1.0)\n",
    "            suffix = \"\"\n",
    "\n",
    "            \n",
    "        # Compute the box plot positions\n",
    "        positions = np.arange(len(stats_hist.keys()))\n",
    "\n",
    "        # Select the current axes\n",
    "        ax = axs[i]\n",
    "\n",
    "        # Define an offset for x-values to place box plots for different periods side by side\n",
    "        offset = 0.15\n",
    "\n",
    "        # Plot the box plots for the historical period\n",
    "        ax.boxplot(yearly_means_hist, positions=positions-offset, widths=0.3, patch_artist=True, \n",
    "                   boxprops=dict(facecolor='cornflowerblue'), medianprops=dict(color='black'), \n",
    "                   showfliers=True)\n",
    "        \n",
    "        # Plot the box plots for the SSP370 scenario\n",
    "        ax.boxplot(yearly_means_ssp370, positions=positions+offset, widths=0.3, patch_artist=True, \n",
    "                   boxprops=dict(facecolor='sandybrown'), medianprops=dict(color='black'), \n",
    "                   showfliers=True)\n",
    "\n",
    "        # Set the x-ticks labels and the title\n",
    "        ax.set_xticks(positions)\n",
    "        ax.set_xticklabels(stats_hist.keys(), rotation=90)\n",
    "        ax.set_ylabel(f'[{full_variable_names[var][1]}]', fontsize=9)\n",
    "        \n",
    "        # Set title with full variable name if provided\n",
    "        if full_variable_names and var in full_variable_names:\n",
    "            ax.set_title(full_variable_names[var][0], fontsize=9)\n",
    "        else:\n",
    "            ax.set_title(var)\n",
    "\n",
    "    # Set a legend\n",
    "    axs[0].legend([Patch(facecolor='cornflowerblue'), Patch(facecolor='sandybrown')], ['Historical', 'SSP370'])\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    filename = f\"Variable_changes{suffix}.png\"\n",
    "    \n",
    "    savepath = f'../../results/CMIP6/yearly_mean_comparison'\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "    filepath = os.path.join(savepath, filename)\n",
    "\n",
    "    fig.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641a772-cd43-4bee-85ab-631cb58eca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_change_map(ds_dict, variable, vmin, vmax, cmap='viridis', metric='mean', save_fig=False, file_format='png'):\n",
    "    \"\"\"\n",
    "    Plots a map of the specified statistic of the given variable for each dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        variable (str): The name of the variable to plot.\n",
    "        cmap (str): The name of the colormap to use for the plot. Default is 'viridis'.\n",
    "        save_fig (bool): If True, save the figure to a file. Default is False.\n",
    "        file_format (str): The format of the saved figure. Default is 'png'.\n",
    "\n",
    "    Returns:\n",
    "        str: The file path where the figure was saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check arguments and get info\n",
    "    if ds_dict[list(ds_dict.keys())[0]].attrs['change'] == 'Relative Change':\n",
    "        var_long_name, period, unit, statistic_dim, statistic, experiment_id, titles, frequency = check_args_and_get_info(ds_dict, variable)\n",
    "        unit = '%'\n",
    "    else:\n",
    "        var_long_name, period, unit, statistic_dim, statistic, experiment_id, titles, frequency = check_args_and_get_info(ds_dict, variable)\n",
    "    \n",
    "    # Create a figure\n",
    "    n_datasets_with_var = sum([1 for ds in ds_dict.values() if variable in ds])\n",
    "    n_cols = 4  # Set number of columns to 4\n",
    "    n_rows = math.ceil(n_datasets_with_var / n_cols)  # Calculate rows\n",
    "    \n",
    "    fig = plt.figure(figsize=[12 * n_cols, 6.5 * n_rows])  # Start with a blank figure, without subplots\n",
    "\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # Loop over datasets and plot the requested statistic\n",
    "    subplot_counter = 0\n",
    "    for i, (name, ds) in enumerate(ds_dict.items()):\n",
    "        if variable not in ds:\n",
    "            print(f\"Variable '{variable}' not found in dataset '{name}', skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Add a new subplot with a cartopy projection\n",
    "        ax = fig.add_subplot(n_rows, n_cols, subplot_counter+1, projection=ccrs.Robinson())\n",
    "        \n",
    "        data_to_plot = ds[variable]\n",
    "        im = data_to_plot.plot(ax=ax, cmap=cmap, vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree(), add_colorbar=False)  # Added a cartopy transform to the plot and cmap parameter\n",
    "        ax.set_title(name, fontsize=18)\n",
    "        ax.coastlines()  # Adds lines around the continents\n",
    "\n",
    "        subplot_counter += 1\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    # Add a common colorbar at the bottom of the plots\n",
    "    cbar = fig.colorbar(im, ax=fig.axes, extend='both', orientation='horizontal', fraction=0.02, pad=0.04, aspect=75, shrink=0.4)\n",
    "\n",
    "    # Set tick size\n",
    "    cbar.ax.tick_params(labelsize=20)  # Adjust size as needed\n",
    "    \n",
    "    # Set colorbar label\n",
    "    cbar.set_label(f\"{var_long_name} Change [{unit}]\", size=26)  # Adjust size as needed\n",
    "    \n",
    "    # Set figure title with first and last year of dataset \n",
    "    if ds_dict[list(ds_dict.keys())[0]].attrs['change'] == 'Relative Change':\n",
    "        fig.suptitle(f\"Relative Change of {var_long_name} {titles[statistic]} ({period})\", fontsize=26, y=0.9)\n",
    "    else:\n",
    "        fig.suptitle(f\"Absolute Change of {var_long_name} {titles[statistic]} ({period})\", fontsize=26, y=0.9)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', 'ssp370-historical', 'time', metric, 'change_maps')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        if ds_dict[list(ds_dict.keys())[0]].attrs['change'] == 'Relative Change':\n",
    "            filename = f'relative_change.{statistic}.{variable}.{ds.experiment_id}.{file_format}'\n",
    "        else:\n",
    "            filename = f'absolute_change.{statistic}.{variable}.{ds.experiment_id}.{file_format}'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=300)\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c6728-aa37-48ed-88ee-2bca84fa1521",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10db210-8757-4858-ae1e-4f89e7949440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_mean_correlations(correlations_hist, correlations_ssp370, variable_pairs, target_variable, scale_axis=False, variable_captions=None):\n",
    "    \"\"\"\n",
    "    Plots the mean correlations for each variable pair that includes the target variable.\n",
    "\n",
    "    Parameters:\n",
    "    correlations_hist (dict): The output from calculate_correlations for the historical period.\n",
    "    correlations_ssp370 (dict): The output from calculate_correlations for the SSP370 scenario.\n",
    "    variable_pairs (list of tuples): The pairs of variables that the correlations were calculated for.\n",
    "    target_variable (str): The variable that must be included in a pair for it to be plotted.\n",
    "    scale_axis (bool): Whether to scale the y-axis according to metric value ranges. Default is False.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get info\n",
    "    metric = correlations_hist[list(correlations_hist.keys())[0]].Metric\n",
    "    metric_sign = correlations_hist[list(correlations_hist.keys())[0]].Metric_sign\n",
    "    \n",
    "    # Filter variable pairs\n",
    "    variable_pairs = [(var1, var2) for var1, var2 in variable_pairs if var1 == target_variable or var2 == target_variable]\n",
    "\n",
    "    # Calculate the number of plots and dimensions of the grid of subplots\n",
    "    n_plots = len(variable_pairs)\n",
    "    n_cols = min(n_plots, 3)  # Maximum 3 plots in a row\n",
    "    n_rows = int(np.ceil(n_plots / n_cols))\n",
    "\n",
    "    # Create the figure\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows), squeeze=False)\n",
    "    axs = axs.flatten()  # Flatten the axes array\n",
    "    \n",
    "    for i, (var1, var2) in enumerate(variable_pairs):\n",
    "        # Prepare lists to store yearly correlation values\n",
    "        yearly_corr_hist, yearly_corr_ssp370 = [], []\n",
    "\n",
    "        for name in correlations_hist.keys():\n",
    "            # Extract the yearly mean values for the historical period\n",
    "            yearly_corr_hist.append(correlations_hist[name][f'{var1}-{var2}'].values)\n",
    "\n",
    "            # Extract the yearly mean values for the SSP370 scenario\n",
    "            yearly_corr_ssp370.append(correlations_ssp370[name][f'{var1}-{var2}'].values)\n",
    "\n",
    "        # Compute the box plot positions\n",
    "        positions = np.arange(len(correlations_hist.keys()))\n",
    "\n",
    "        # Select the current axes\n",
    "        ax = axs[i]\n",
    "\n",
    "        # Define an offset for x-values to place box plots for different periods side by side\n",
    "        offset = 0.15\n",
    "\n",
    "        # Plot the box plots for the historical period\n",
    "        ax.boxplot(yearly_corr_hist, positions=positions-offset, widths=0.3, patch_artist=True, \n",
    "                   boxprops=dict(facecolor='cornflowerblue'), medianprops=dict(color='black'), \n",
    "                   showfliers=True)\n",
    "\n",
    "        # Plot the box plots for the SSP370 scenario\n",
    "        ax.boxplot(yearly_corr_ssp370, positions=positions+offset, widths=0.3, patch_artist=True, \n",
    "                   boxprops=dict(facecolor='sandybrown'), medianprops=dict(color='black'), \n",
    "                   showfliers=True)\n",
    "\n",
    "        # Set the x-ticks labels and the title\n",
    "        ax.set_ylabel(f'{metric_sign}')\n",
    "        ax.set_title(f'{variable_captions.get(var1, var1)} x {variable_captions.get(var2, var2)}', fontsize=9)\n",
    "        ax.set_xticks(positions)\n",
    "        ax.set_xticklabels(list(correlations_hist.keys()), rotation=90)\n",
    "        \n",
    "    fig.suptitle(f'Yearly {metric} for Historical (1985-2014) and SSP370 (2071-2100) Period', fontsize=12, y=1.0)\n",
    "    \n",
    "    # Set a legend\n",
    "    axs[0].legend([Patch(facecolor='cornflowerblue'), Patch(facecolor='sandybrown')], ['Historical', 'SSP370'])\n",
    "\n",
    "    # Handle empty subplots in case n_plots is less than n_rows * n_cols\n",
    "    for i in range(n_plots, n_rows*n_cols):\n",
    "        fig.delaxes(axs[i])\n",
    "    \n",
    "    # Handle y-axis scaling\n",
    "    if scale_axis:\n",
    "        for ax in axs:\n",
    "            ax.set_ylim([-1, 1] if metric != 'r2_lr' else [0, 1])\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    suffix = \"_scaled_axis\" if scale_axis else \"\"\n",
    "    filename = f\"{metric}_changes_{target_variable}{suffix}.png\"\n",
    "    \n",
    "    savepath = f'../../results/CMIP6/yearly_metrics_comparison'\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "    filepath = os.path.join(savepath, filename)\n",
    "\n",
    "    fig.savefig(filepath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555de63-1237-4ed3-b496-48f9f835eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_corr_change_plot(ds_dict, target_variable, full_var_names_and_unit, cmap='viridis', save_fig=False, file_format='png'):\n",
    "    \"\"\"\n",
    "    Plots a map of the specified statistic of the given variable for the Ensemble_mean dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        target_variable (str): The target variable to plot correlations with.\n",
    "        cmap (str): The name of the colormap to use for the plot. Default is 'viridis'.\n",
    "        save_fig (bool): If True, save the figure to a file. Default is False.\n",
    "        file_format (str): The format of the saved figure. Default is 'png'.\n",
    "    \"\"\"\n",
    "    # Info\n",
    "    experiment_id = ds_dict[list(ds_dict.keys())[0]].experiment_id\n",
    "    metric = ds_dict[list(ds_dict.keys())[0]].Metric\n",
    "    metric_sign = ds_dict[list(ds_dict.keys())[0]].Metric_sign\n",
    "    means = ds_dict[list(ds_dict.keys())[0]].attrs['means']\n",
    "    target_var_long_name = full_var_names_and_unit[target_variable][0]\n",
    "    \n",
    "    # Create a figure\n",
    "    n_cols = 3  # Set number of columns to 3\n",
    "    n_rows = 3  # Set number of rows to 3\n",
    "    \n",
    "    fig = plt.figure(figsize=[12 * n_cols, 6.5 * n_rows])  # Start with a blank figure, without subplots\n",
    "\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # Loop over datasets and plot the requested statistic\n",
    "    subplot_counter = 0\n",
    "\n",
    "    # Get the Ensemble_mean dataset\n",
    "    ensemble_ds = ds_dict.get(\"Ensemble_mean\", None)\n",
    "\n",
    "    if ensemble_ds is None:\n",
    "        print(\"Ensemble_mean dataset not found.\")\n",
    "        return None\n",
    "\n",
    "    for variable in ensemble_ds.variables:\n",
    "        if not (f'{target_variable} x ' in variable or f' x {target_variable}' in variable):\n",
    "            continue\n",
    "\n",
    "        # Add a new subplot with a cartopy projection\n",
    "        ax = fig.add_subplot(n_rows, n_cols, subplot_counter+1, projection=ccrs.Robinson())\n",
    "\n",
    "        data_to_plot = ensemble_ds[variable]\n",
    "        im = data_to_plot.plot(ax=ax, cmap=cmap, vmin = -1, vmax = 1, transform=ccrs.PlateCarree(), add_colorbar=False)  # Added a cartopy transform to the plot and cmap parameter\n",
    "        \n",
    "        if f'{target_variable} x ' in variable:\n",
    "            corr_var = variable.replace(f'{target_variable} x ', '')\n",
    "        elif f' x {target_variable}' in variable:\n",
    "            corr_var = variable.replace(f' x {target_variable}', '')\n",
    "        else:\n",
    "            continue\n",
    "        corr_var_long_name = full_var_names_and_unit[corr_var][0]\n",
    "        ax.set_title(f'{target_var_long_name} x {corr_var_long_name}', fontsize=18)  # Use the long names in the title\n",
    "        ax.coastlines()  # Adds lines around the continents\n",
    "\n",
    "        subplot_counter += 1\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    # Add a common colorbar at the bottom of the plots\n",
    "    cbar = fig.colorbar(im, ax=fig.axes, orientation='horizontal', fraction=0.02, pad=0.04, aspect=75, shrink=0.4)\n",
    "    \n",
    "\n",
    "    # Set colorbar ticks\n",
    "    cbar.set_ticks([-0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75])\n",
    "    \n",
    "    \n",
    "    # Set tick size\n",
    "    cbar.ax.tick_params(labelsize=20)  # Adjust size as needed\n",
    "    \n",
    "    # Set colorbar label\n",
    "    cbar.set_label(f'{metric_sign} change', size=26)  # Adjust size as needed\n",
    "    \n",
    "    # Set figure title with first and last year of dataset \n",
    "    if experiment_id == 'historical' or experiment_id == 'ssp370':\n",
    "        fig.suptitle(f\"{metric} ({experiment_id}) of Ensemble Mean for Variable Combinations with {target_var_long_name} ({means})\", fontsize=20, y=0.9)\n",
    "    elif experiment_id == 'ssp370-historical':\n",
    "        fig.suptitle(f\"{metric} Change ({experiment_id}) of Ensemble Mean for Variable Combinations with {target_var_long_name} ({means})\", fontsize=20, y=0.9)\n",
    "    \n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    if save_fig:\n",
    "        if experiment_id == 'historical' or experiment_id == 'ssp370':\n",
    "            savepath = os.path.join('../..', 'results', 'CMIP6', experiment_id, 'time', 'mean', 'corr_maps', means)\n",
    "            os.makedirs(savepath, exist_ok=True)\n",
    "            filename = f'ensmean_{target_variable}_correlations.{file_format}'\n",
    "            filepath = os.path.join(savepath, filename)\n",
    "            fig.savefig(filepath, dpi=300)\n",
    "        elif experiment_id == 'ssp370-historical':\n",
    "            savepath = os.path.join('../..', 'results', 'CMIP6', experiment_id, 'time', 'mean', 'corr_maps', means)\n",
    "            os.makedirs(savepath, exist_ok=True)\n",
    "            filename =f'ensmean_{target_variable}_correlations_change.{file_format}'\n",
    "            filepath = os.path.join(savepath, filename)\n",
    "            fig.savefig(filepath, dpi=300)\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c30d8-7d61-497f-9fd6-689ad3634fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_maps(ds_dict, target_variable_combination, cmap='viridis', save_fig=False, file_format='png'):\n",
    "    \"\"\"\n",
    "    Plots a map of the specified variable combination for each dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        target_variable_combination (str): The target variable combination to plot.\n",
    "        cmap (str): The name of the colormap to use for the plot. Default is 'viridis'.\n",
    "        save_fig (bool): If True, save the figure to a file. Default is False.\n",
    "        file_format (str): The format of the saved figure. Default is 'png'.\n",
    "    \"\"\"\n",
    "    # Info\n",
    "    experiment_id = ds_dict[list(ds_dict.keys())[0]].experiment_id\n",
    "    metric = ds_dict[list(ds_dict.keys())[0]].Metric\n",
    "    metric_sign = ds_dict[list(ds_dict.keys())[0]].Metric_sign\n",
    "    means = ds_dict[list(ds_dict.keys())[0]].attrs['means']\n",
    "    \n",
    "    # Create a figure\n",
    "    n_datasets_with_var = sum([1 for ds in ds_dict.values() if target_variable_combination in ds.variables])\n",
    "    n_cols = 3  # Set number of columns to 3\n",
    "    n_rows = math.ceil(n_datasets_with_var / n_cols)  # Calculate rows\n",
    "    \n",
    "    fig = plt.figure(figsize=[12 * n_cols, 6.5 * n_rows])  # Start with a blank figure, without subplots\n",
    "\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # Loop over datasets and plot the requested variable combination\n",
    "    subplot_counter = 0\n",
    "    for i, (name, ds) in enumerate(ds_dict.items()):\n",
    "        if target_variable_combination not in ds.variables:\n",
    "            continue\n",
    "\n",
    "        # Add a new subplot with a cartopy projection\n",
    "        ax = fig.add_subplot(n_rows, n_cols, subplot_counter+1, projection=ccrs.Robinson())\n",
    "        \n",
    "        data_to_plot = ds[target_variable_combination]\n",
    "        im = data_to_plot.plot(ax=ax, cmap=cmap, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "        ax.set_title(name, fontsize=18)\n",
    "        ax.coastlines()  # Adds lines around the continents\n",
    "\n",
    "        subplot_counter += 1\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "    # Add a common colorbar at the bottom of the plots\n",
    "    cbar = fig.colorbar(im, ax=fig.axes, orientation='horizontal', fraction=0.02, pad=0.04, aspect=75, shrink=0.4)\n",
    "    \n",
    "    # Set tick size\n",
    "    cbar.ax.tick_params(labelsize=14)  # Adjust size as needed\n",
    "    \n",
    "    # Set colorbar label\n",
    "    cbar.set_label(metric_sign, size=18)  # Adjust size as needed\n",
    "    \n",
    "    # Set figure title with first and last year of dataset \n",
    "    if experiment_id == 'historical' or 'ssp370':\n",
    "        fig.suptitle(f\"{metric} ({experiment_id}) for Variable Combination {target_variable_combination} ({means})\", fontsize=20, y=0.9)\n",
    "    elif experiment_id == 'ssp370-historical':\n",
    "        fig.suptitle(f\"{metric} Change ({experiment_id}) for Variable Combination {target_variable_combination} ({means})\", fontsize=20, y=0.9)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    if save_fig:\n",
    "        if experiment_id == 'historical' or 'ssp370':\n",
    "            savepath = os.path.join('../..', 'results', 'CMIP6', experiment_id, 'time', 'mean', 'corr_maps', means)\n",
    "            os.makedirs(savepath, exist_ok=True)\n",
    "            filename = f'{target_variable_combination}_correlation.{file_format}'\n",
    "            filepath = os.path.join(savepath, filename)\n",
    "            fig.savefig(filepath, dpi=300)\n",
    "        elif experiment_id == 'ssp370-historical':\n",
    "            savepath = os.path.join('../..', 'results', 'CMIP6', 'comparison', 'corr_maps', means)\n",
    "            os.makedirs(savepath, exist_ok=True)\n",
    "            filename =f'{target_variable_combination}_correlation_change.{file_format}'\n",
    "            filepath = os.path.join(savepath, filename)\n",
    "            fig.savefig(filepath, dpi=300)\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173177e7-1327-46be-9952-4ba5d9d45155",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load netCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343c372-5fab-4276-9c97-171ecae7340b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========= Define period, models and path ==============\n",
    "variables=['tas', 'pr', 'vpd', 'evspsbl', 'mrro', 'lmrso_1m', 'lmrso_2m', 'tran', 'lai', 'gpp', 'EI', 'wue']\n",
    "experiment_id = 'historical'\n",
    "source_id = ['TaiESM1', 'BCC-CSM2-MR',  'CanESM5', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'IPSL-CM6A-LR', 'UKESM1-0-LL', 'MPI-ESM1-2-LR', 'CESM2-WACCM', 'NorESM2-MM', 'Ensemble mean', 'Ensemble median'] #\n",
    "folder='preprocessed'\n",
    "\n",
    "# ========= Use Dask to parallelize computations ==========\n",
    "dask.config.set(scheduler='processes')\n",
    "\n",
    "# Create dictionary using a dictionary comprehension and Dask\n",
    "ds_dict_hist = dask.compute({model: open_and_merge_datasets(folder, model, experiment_id, variables) for model in source_id})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f749cba-efb8-4532-9e4b-a7b880530fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============= Have a look into the data ==============\n",
    "print(ds_dict_hist.keys())\n",
    "ds_dict_hist[list(ds_dict_hist.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f417b3-2b33-4081-b1d8-6d3a1c21d269",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29262fe-a12e-44ff-894e-6d851abac37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_hist_period = select_period(ds_dict_hist, start_year=1985, end_year=2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a12260-1df3-4232-bf91-196fb8144269",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_ssp370_period = select_period(ds_dict_ssp370, start_year=2071, end_year=2100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de9ead-0d36-4f06-9430-9efeae7cc9bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b6390-f4b2-41d0-951d-c6bae78ce192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Compute statistic for plot ===============\n",
    "ds_dict_hist_period_metric = compute_statistic(ds_dict_hist_period, 'mean', 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a9c21-8094-4700-b972-36e3f720d629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========= Compute statistic for plot ===============\n",
    "ds_dict_ssp370_period_metric = compute_statistic(ds_dict_ssp370_period, 'mean', 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e28e2e6-2da4-42d5-9885-216adad65d94",
   "metadata": {},
   "source": [
    "### Compute Ensemble metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f58f45-f4e5-4828-b7e6-df094c8c3d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_hist_period_metric = compute_ensemble(ds_dict_hist_period_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b40574-e5a5-4bc3-a198-22124b5f1b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_ssp370_period_metric = compute_ensemble(ds_dict_ssp370_period_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f0308-c03e-4b46-908c-19a63091a4c5",
   "metadata": {},
   "source": [
    "### Compute NBWFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf097f7-eb68-498a-9323-0fb531637403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_hist_period = compute_nbwfp(ds_dict_hist_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c51cd9-8921-47da-ba6f-a9b6b6b43889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_ssp370_period = compute_nbwfp(ds_dict_ssp370_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63029d7a-983e-4767-bc01-aad2e2685474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compute change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db50627-0096-43a6-a25c-dbe050ac9316",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Absolute change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd479b1-5862-4f8e-b0af-c24bf8645182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_abs_change = {}\n",
    "ds_dict_abs_change = compute_change(ds_dict_hist_period_metric, ds_dict_ssp370_period_metric, relative_change=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c7068-3fa8-4c07-85e6-ca9f7692574d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Relative change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd8367-54bf-4cfd-a572-dd79f82beeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_rel_change = {}\n",
    "ds_dict_rel_change = compute_change(ds_dict_hist_period_metric, ds_dict_ssp370_period_metric, relative_change=True, iqr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7d0b48-e951-4e38-a856-61a378c2d2dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot Variable Change Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f7d7e-f03b-40fc-be3f-7afd90af387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Plot Change ==========\n",
    "plot_mean_change_map(ds_dict_rel_change, 'tas', 0, 5, cmap='YlOrRd', metric='mean', save_fig=True, file_format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260bd1f-349e-455c-b50b-4edfe085a7ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Correlation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4344d-4203-4772-b222-b6cd358fcdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Compute Correlations ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33383f93-4f04-46ca-a9a9-029289a47609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables=['tas', 'pr', 'vpd', 'evspsbl', 'mrro', 'lmrso_1m', 'lmrso_2m', 'tran', 'lai', 'gpp', 'wue', 'nbwfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe1fb6-f8c9-4cd5-81c5-c867c1feed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_hist_corr = compute_correlation_coefficients(ds_dict_hist_period, variables, yearly_corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ea77e-4541-42c4-956c-64a368ec0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_ssp370_corr = compute_correlation_coefficients(ds_dict_ssp370_period, variables, yearly_corr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76fe34b-205d-4f65-a8e2-5f221e41dcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======= Create unique variable pairs ========\n",
    "variable_pairs = [(variables[i], variables[j]) for i in range(len(variables)) for j in range(i+1, len(variables))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eecd7f-12af-4775-9da8-89fb7d8f7d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_variable = 'nbwfp'\n",
    "variable_pairs = [(target_variable, var) for var in variables if var != target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39bad1e-b1bc-47f9-9ae3-d0dc9972d66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Create Plots for all variable pairs\n",
    "for var in variable_pairs:\n",
    "    corr_maps(ds_dict_hist_corr, f'{var[0]} x {var[0+1]}', 'coolwarm', save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707dcb71-d143-4a2c-b36c-f85fb0f8e04a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Create Plots for all variable pairs\n",
    "for var in variable_pairs:\n",
    "    corr_maps(ds_dict_ssp370_corr, f'{var[0]} x {var[0+1]}', 'coolwarm', save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dff8cd-3e47-4004-8224-9a724ea0a8d6",
   "metadata": {},
   "source": [
    "### Plot Correlation Change Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b9bb4-0b22-4eb5-8df6-bd437220135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Compute Change ========\n",
    "ds_dict_corr_change = compute_change_corr(ds_dict_hist_corr, ds_dict_ssp370_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec26d9-42d3-49d5-80ba-685bbc7eaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Create unique variable pairs ========\n",
    "variable_pairs = [(variables[i], variables[j]) for i in range(len(variables)) for j in range(i+1, len(variables))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e84fdb-70c6-4aaa-8cc9-21ccd68d20e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Create Plots for all variable pairs\n",
    "for var in variable_pairs:\n",
    "    corr_maps(ds_dict_corr_change, f'{var[0]} x {var[0+1]}', 'coolwarm', save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8ce99-bf88-4358-9d82-f646b35ab32a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Correlation Change Maps for Ensemble mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd0692-cec1-4b1d-b501-eebc9b05b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_corr_change_plot(ds_dict_corr_change, 'mrro', full_var_names_and_unit, 'coolwarm', save_fig=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
