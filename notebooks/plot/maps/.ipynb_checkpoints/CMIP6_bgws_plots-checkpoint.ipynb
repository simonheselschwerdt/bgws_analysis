{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7716ffb9-a564-44c7-87d4-2d4caeecdb1c",
   "metadata": {},
   "source": [
    "# CMIP6 BGWS Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5a4f3-40bb-459a-88f0-f180c8b3ee8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854af429-43a1-489d-8513-dca8c1466663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import dask\n",
    "import matplotlib.cm\n",
    "from matplotlib import rcParams\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from cftime import DatetimeNoLeap\n",
    "import glob\n",
    "import load_and_preprocess as lap\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams[\"mathtext.default\"] = 'regular'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5daa16-4811-4773-b98d-6b69626ff6cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb57b43-bbbe-414b-8075-8cda5d1ea4ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8d01f-9ff4-45df-862d-c11a73d44685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Create a helper function to open the dataset ========\n",
    "def open_dataset(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    return ds\n",
    "\n",
    "# Define a helper function to open and merge datasets\n",
    "def open_and_merge_datasets(folder, model, experiment_id, temp_res, variables):\n",
    "    filepaths = []\n",
    "    for var in variables:\n",
    "        path = f'../../data/CMIP6/{experiment_id}/{folder}/{temp_res}/{var}'\n",
    "        fp = glob.glob(os.path.join(path, f'CMIP.{model}.{experiment_id}.{var}.regridded.nc'))\n",
    "        if fp:\n",
    "            filepaths.append(fp[0])\n",
    "        else:\n",
    "            print(f\"No file found for variable '{var}' in model '{model}'.\")\n",
    "            print(fp)\n",
    "\n",
    "    datasets = [xr.open_dataset(fp) for fp in filepaths]\n",
    "    ds = xr.merge(datasets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9148cef-f033-40ac-aeef-dec5ccdb277d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0755d44-865c-439e-b702-f2ccb30e1010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_var(ds_dict, var):\n",
    "    for name, ds in ds_dict.items():\n",
    "        ds_dict[name] = ds.drop(var)\n",
    "        \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba91dd1-a3c7-4ef4-9b93-4116470f0d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_period(ds_dict, start_year=None, end_year=None, period=None, yearly_sum=False):\n",
    "    '''\n",
    "    Helper function to select periods and optionally compute yearly sums.\n",
    "    \n",
    "    Parameters:\n",
    "    ds_dict (dict): Dictionary with xarray datasets.\n",
    "    start_year (int): The start year of the period.\n",
    "    end_year (int): The end year of the period.\n",
    "    period (int, list, str, None): Single month (int), list of months (list), multiple seasons (str) to select,\n",
    "                                   or None to not select any specific period.\n",
    "    yearly_sum (bool): If True, compute the yearly sum over the selected period.\n",
    "    '''\n",
    "    \n",
    "    # Create a deep copy of the original ds_dict to avoid modifying it directly\n",
    "    ds_dict_copy = copy.deepcopy(ds_dict)\n",
    "\n",
    "    # Define season to month mapping for northern hemisphere\n",
    "    seasons_to_months = {\n",
    "        'nh_winter': [12, 1, 2],\n",
    "        'nh_spring': [3, 4, 5],\n",
    "        'nh_summer': [6, 7, 8],\n",
    "        'nh_fall': [9, 10, 11]\n",
    "    }\n",
    "    \n",
    "    # Define month name mapping\n",
    "    month_names = {\n",
    "        1: 'J', 2: 'F', 3: 'M', 4: 'A', 5: 'M', 6: 'J',\n",
    "        7: 'J', 8: 'A', 9: 'S', 10: 'O', 11: 'N', 12: 'D'\n",
    "    }\n",
    "\n",
    "    # Define number of days per month (assuming 28 days for February)\n",
    "    days_per_month = {\n",
    "        1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30,\n",
    "        7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31\n",
    "    }\n",
    "\n",
    "    months = []\n",
    "\n",
    "    # If no specific period is selected, all data will be used.\n",
    "    if period is None:\n",
    "        period_name = 'whole_year'\n",
    "        months = list(range(1, 13))  # All months\n",
    "    elif isinstance(period, int):\n",
    "        period_name = month_names[period]\n",
    "        months = [period]\n",
    "    elif isinstance(period, str):\n",
    "        # Check if the input is a single season or multiple seasons\n",
    "        if 'and' in period:\n",
    "            seasons = period.lower().split('and')\n",
    "            period_name = ''\n",
    "            for season in seasons:\n",
    "                season = season.strip()\n",
    "                months.extend(seasons_to_months.get(season, []))\n",
    "                period_name += ''.join(month_names[m] for m in seasons_to_months.get(season, []))\n",
    "        else:\n",
    "            months = seasons_to_months.get(period.lower(), [])\n",
    "            period_name = ''.join(month_names[m] for m in months)\n",
    "    elif isinstance(period, list):\n",
    "        period_name = ''.join(month_names[m] for m in period if m in month_names)\n",
    "        months = period\n",
    "    else:\n",
    "        raise ValueError(\"Period must be None, an integer, a string representing a single season, \"\n",
    "                         \"a string with multiple seasons separated by 'and', or a list of integers.\")\n",
    "\n",
    "    for k, ds in ds_dict_copy.items():\n",
    "        if start_year and end_year:\n",
    "            start_date = f'{start_year}-01-01'\n",
    "            end_date = f'{end_year}-12-31'\n",
    "            ds = ds.sel(time=slice(start_date, end_date))\n",
    "\n",
    "        # If months are specified, select those months\n",
    "        if months:\n",
    "            month_mask = ds['time.month'].isin(months)\n",
    "            ds = ds.where(month_mask, drop=True)\n",
    "\n",
    "        # Store the original attributes of each variable\n",
    "        original_attrs = {var: ds[var].attrs for var in ds.data_vars}\n",
    "\n",
    "        # If yearly_sum is True, sum over 'time' dimension to get yearly sum\n",
    "        if yearly_sum: # does only make sense for accumulative variables e.g. pr or tran\n",
    "            attrs = ds.attrs\n",
    "            # Multiply each value by the number of days in the respective month\n",
    "            days = ds['time'].dt.days_in_month\n",
    "            ds = (ds * days).resample(time='AS').sum(dim='time')\n",
    "            sum_type = 'yearly_sum'\n",
    "            ds.attrs = attrs\n",
    "        else:\n",
    "            sum_type = 'monthly_mean'\n",
    "\n",
    "        # Reassign the original attributes back to each variable\n",
    "        for var in ds.data_vars:\n",
    "            ds[var].attrs = original_attrs[var]\n",
    "\n",
    "        ds_dict_copy[k] = ds\n",
    "        ds_dict_copy[k].attrs['months'] = period_name\n",
    "        ds_dict_copy[k].attrs['yearly_sum'] = sum_type\n",
    "\n",
    "    return ds_dict_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a690d-ac2f-4875-96dc-66e8424a4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Standardize ========\n",
    "def standardize(ds_dict):\n",
    "    '''\n",
    "    Helper function to standardize datasets of a dictionary\n",
    "    '''\n",
    "    ds_dict_stand = {}\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        attrs = ds.attrs\n",
    "        ds_stand = (ds - ds.mean()) / ds.std()\n",
    "\n",
    "        # Preserve variable attributes from the original dataset\n",
    "        for var in ds.variables:\n",
    "            if var in ds_stand.variables:\n",
    "                ds_stand[var].attrs = ds[var].attrs\n",
    "\n",
    "        ds_stand.attrs = attrs\n",
    "        ds_dict_stand[name] = ds_stand\n",
    "        \n",
    "    return ds_dict_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090c127-204b-4d69-9e33-5769b28e4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args_and_get_info(ds_dict, variable):\n",
    "    # Check the validity of input arguments\n",
    "    if not isinstance(ds_dict, dict):\n",
    "        raise TypeError(\"ds_dict must be a dictionary of xarray datasets.\")\n",
    "    if not all(isinstance(ds, xr.Dataset) for ds in ds_dict.values()):\n",
    "        raise TypeError(\"All values in ds_dict must be xarray datasets.\")\n",
    "    if not isinstance(variable, str):\n",
    "        raise TypeError('variable must be a string.')\n",
    "        \n",
    "    # Dictionary to store plot titles for each statistic\n",
    "    titles = {\"mean\": \"Mean\", \"std\": \"Standard deviation of yearly means\", \"min\": \"Minimum\", \"max\": \"Maximum\", \"median\": \"Median\", \"time\": \"Time\", \"space\": \"Space\"}\n",
    "    freq = {\"mon\": \"Monthly\"}\n",
    "    \n",
    "    long_name = {\n",
    "        'Precipitation': 'Precipitation',\n",
    "        'Total Runoff': 'Total Runoff',\n",
    "        'Vapor Pressure Deficit': 'Vapor Pressure Deficit',\n",
    "        'Evaporation Including Sublimation and Transpiration': 'Evapotranspiration',\n",
    "        'Transpiration': 'Transpiration',\n",
    "        'Leaf Area Index': 'Leaf Area Index',\n",
    "        'Carbon Mass Flux out of Atmosphere Due to Gross Primary Production on Land [kgC m-2 s-1]': 'Gross Primary Production',\n",
    "        'Total Liquid Soil Moisture Content of 1 m Column': '1 m Soil Moisture',\n",
    "        'Total Liquid Soil Moisture Content of 2 m Column': '2 m Soil Moisture',\n",
    "        'Runoff - Precipitation': 'Runoff - Precipitation',\n",
    "        'Transpiration - Precipitation': 'Transpiration - Precipitation',\n",
    "        '(Runoff + Transpiration) - Precipitation':  '(Runoff + Transpiration) - Precipitation',\n",
    "        'ET - Precipitation':  'ET - Precipitation', \n",
    "        'Negative Runoff': 'Negative Runoff',\n",
    "    }\n",
    "   \n",
    "    # Data information\n",
    "    var_long_name = ds_dict[list(ds_dict.keys())[0]][variable].long_name\n",
    "    period = f\"{ds_dict[list(ds_dict.keys())[0]].attrs['period'][0]}-{ds_dict[list(ds_dict.keys())[0]].attrs['period'][1]}\"\n",
    "    experiment_id =  ds_dict[list(ds_dict.keys())[0]].experiment_id\n",
    "    unit = ds_dict[list(ds_dict.keys())[0]][variable].units\n",
    "    statistic_dim = ds_dict[list(ds_dict.keys())[0]].statistic_dimension\n",
    "    statistic = ds_dict[list(ds_dict.keys())[0]].attrs['statistic']\n",
    "    frequency = freq[ds_dict[list(ds_dict.keys())[0]].frequency]\n",
    "\n",
    "    return var_long_name, period, unit, statistic_dim, statistic, experiment_id, titles, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a73aa-e566-4d11-8dd0-c6de7e0cc432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_ensemble(ds_dict_change):\n",
    "    for key in ['Ensemble mean', 'Ensemble median']:\n",
    "        if key in ds_dict_change:\n",
    "            ds_dict_change.pop(key)\n",
    "\n",
    "    # Drop 'member_id' coordinate if it exists in any of the datasets\n",
    "    for ds_key in ds_dict_change:\n",
    "        if 'member_id' in ds_dict_change[ds_key].coords:\n",
    "            ds_dict_change[ds_key] = ds_dict_change[ds_key].drop('member_id')\n",
    "\n",
    "    combined = xr.concat(ds_dict_change.values(), dim='ensemble')\n",
    "    ds_dict_change['Ensemble median'] = getattr(combined, 'median')(dim='ensemble')\n",
    "    \n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e4851-532d-4dd6-af51-15e12b7761f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regionmask\n",
    "\n",
    "def apply_region_mask(ds_dict):\n",
    "    \"\"\"\n",
    "    Applies the AR6 land region mask to datasets in the provided dictionary and adds a region dimension.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary where keys are the same as in the input dictionary,\n",
    "              and each value is an xarray Dataset with a region dimension added to each variable.\n",
    "    \"\"\"\n",
    "    \n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    ds_masked_dict = {}\n",
    "    \n",
    "    for ds_name, ds in ds_dict.items():\n",
    "        ds_out = xr.Dataset()  # Initiate an empty Dataset for the masked data\n",
    "        \n",
    "        # Get attributes\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        for var in ds:\n",
    "            # Get the binary mask\n",
    "            mask = land_regions.mask_3D(ds[var])\n",
    "            \n",
    "            var_attrs = ds[var].attrs\n",
    "\n",
    "            # Multiply the original data with the mask to get the masked data\n",
    "            masked_var = ds[var] * mask\n",
    "\n",
    "            # Replace 0s with NaNs, if desired\n",
    "            masked_var = masked_var.where(masked_var != 0)\n",
    "\n",
    "            # Add the masked variable to the output Dataset\n",
    "            ds_out[var] = masked_var\n",
    "            \n",
    "            ds_out[var].attrs = var_attrs\n",
    "            \n",
    "        # Add the attributes\n",
    "        ds_out.attrs = attrs\n",
    "\n",
    "        # Add the Dataset to the output dictionary\n",
    "        ds_masked_dict[ds_name] = ds_out\n",
    "\n",
    "    return ds_masked_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fedf68-0e05-43a4-a705-ba2e9b163a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_numeric(data):\n",
    "    try:\n",
    "        _ = data.astype(float)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def compute_change(ds_dict_hist, ds_dict_fut, var_rel_change=None):\n",
    "    ds_dict_change = {}\n",
    "\n",
    "    for name, ds_hist in ds_dict_hist.items():\n",
    "        if name in ds_dict_fut:\n",
    "            ds_future = ds_dict_fut[name]\n",
    "            common_vars = set(ds_hist.data_vars).intersection(ds_future.data_vars)\n",
    "\n",
    "            ds_change = ds_hist.copy(deep=True)\n",
    "            \n",
    "            if var_rel_change == 'all':\n",
    "                var_rel_change = common_vars\n",
    "                \n",
    "            for var in common_vars:\n",
    "                if is_numeric(ds_hist[var].data) and is_numeric(ds_future[var].data):\n",
    "                    if var_rel_change is not None and var in var_rel_change:\n",
    "                        # Compute relative change where ds_hist is not zero\n",
    "                        rel_change = (ds_future[var] - ds_hist[var]) / ds_hist[var].where(ds_hist[var] != 0) * 100\n",
    "                        ds_change[var].data = rel_change.data\n",
    "                        ds_change[var].attrs['units'] = '%'\n",
    "                    else:\n",
    "                        # Compute absolute change\n",
    "                        abs_change = ds_future[var] - ds_hist[var]\n",
    "                        ds_change[var].data = abs_change.data\n",
    "\n",
    "            ds_change.attrs = ds_future.attrs\n",
    "            ds_dict_change[name] = ds_change\n",
    "\n",
    "    return ds_dict_change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a2736-eb0f-466e-b547-4d293e8a5af5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2f45a-7c54-4e4b-a62d-c43186adb78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_spatial_mean(ds_dict):\n",
    "    ds_dict_mean = {}\n",
    "    for key, ds in ds_dict.items():\n",
    "        attrs = ds.attrs\n",
    "        for var in list(ds.data_vars.keys()):\n",
    "            var_attrs = ds[var].attrs\n",
    "            \n",
    "            ds_dict_mean[key][var] = ds.mean(['lon', 'lat'])\n",
    "            ds_dict_mean[key][var].attrs = var_attrs\n",
    "        \n",
    "        ds_dict_mean[key].attrs = attrs\n",
    "        \n",
    "    return ds_dict_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766cd9d-393f-4db9-b0a3-744388ad88c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_statistic_single(ds, statistic, dimension, yearly_mean=True):\n",
    "    if dimension == \"time\":\n",
    "        stat_ds = getattr(ds, statistic)(\"time\", keep_attrs=True, skipna=True)\n",
    "        stat_ds.attrs['period'] = [str(ds.time.dt.year[0].values), str(ds.time.dt.year[-1].values)]\n",
    "        \n",
    "    if dimension == \"space\":\n",
    "        # Assign the period attribute before grouping by year\n",
    "        ds.attrs['period'] = [str(ds.time.dt.year[0].values), str(ds.time.dt.year[-1].values)]\n",
    "        \n",
    "        if yearly_mean:\n",
    "            ds = ds.groupby('time.year').mean('time', keep_attrs=True, skipna=True)\n",
    "            ds.attrs['mean'] = 'yearly mean'\n",
    "            \n",
    "        \n",
    "        #get the weights, apply on data, and compute statistic\n",
    "        weights = np.cos(np.deg2rad(ds.lat))\n",
    "        weights.name = \"weights\"\n",
    "        ds_weighted = ds.weighted(weights)\n",
    "        stat_ds = getattr(ds_weighted, statistic)((\"lon\", \"lat\"), keep_attrs=True, skipna=True)\n",
    "    \n",
    "    stat_ds.attrs['statistic'] = statistic\n",
    "    stat_ds.attrs['statistic_dimension'] = dimension\n",
    "\n",
    "    return stat_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadad33e-375e-4f6f-94b1-918dce7e2f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_statistic(ds_dict, statistic, dimension, start_year=None, end_year=None, yearly_mean=True):\n",
    "    \"\"\"\n",
    "    Computes the specified statistic for each dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        statistic (str): The statistic to compute, which can be one of 'mean', 'std', 'min', 'var', or 'median'.\n",
    "        dimension (str): The dimension to compute over, which can be 'time' or 'space'.\n",
    "        start_year (str, optional): The start year of the period to compute the statistic over.\n",
    "        end_year (str, optional): The end year of the period to compute the statistic over.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with computed statistic for each dataset.\n",
    "    \"\"\"\n",
    "    # Check the validity of input arguments\n",
    "    if not isinstance(ds_dict, dict):\n",
    "        raise TypeError(\"ds_dict must be a dictionary of xarray datasets.\")\n",
    "    if not all(isinstance(ds, xr.Dataset) for ds in ds_dict.values()):\n",
    "        raise TypeError(\"All values in ds_dict must be xarray datasets.\")\n",
    "    if statistic not in [\"mean\", \"std\", \"min\", \"max\", \"var\", \"median\"]:\n",
    "        raise ValueError(f\"Invalid statistic '{statistic}' specified.\")\n",
    "    if dimension not in [\"time\", \"space\"]:\n",
    "        raise ValueError(f\"Invalid dimension '{dimension}' specified.\")\n",
    "\n",
    "    # Select period\n",
    "    if start_year is not None and end_year is not None:\n",
    "        select_period(ds_dict, start_year=start_year, end_year=end_year)\n",
    "        \n",
    "        \n",
    "    # Use multiprocessing to compute the statistic for each dataset in parallel\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.starmap(compute_statistic_single, [(ds, statistic, dimension, yearly_mean) for ds in ds_dict.values()])\n",
    "\n",
    "    return dict(zip(ds_dict.keys(), results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d176a36-95a5-4a18-b46f-a311e49243f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def precompute_metrics(ds_dict, variables, metrics=['pearson']):\n",
    "    # Initialize the results dictionary\n",
    "    results_dict = {metric: {} for metric in metrics}\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        # Create a DataFrame with all the variables\n",
    "        df = pd.DataFrame({var: ds[var].values.flatten() for var in variables})\n",
    "        \n",
    "        # Define all pairs of variables\n",
    "        pairs = list(permutations(variables, 2))  # <-- Change here\n",
    "        args = [(df, var1, var2, metrics) for var1, var2 in pairs]\n",
    "\n",
    "        # Use a multiprocessing pool to compute the metrics for all pairs\n",
    "        with Pool() as p:\n",
    "            results = p.map(compute_metrics_for_pair, args)\n",
    "        \n",
    "        # Store the results in the results_dict\n",
    "        for var1, var2, metric_dict in results:\n",
    "            for metric, value in metric_dict.items():\n",
    "                # Ensure the keys exist in the dictionary\n",
    "                results_dict[metric].setdefault(name, {}).setdefault(f'{var1}_{var2}', value)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9381cb-6944-4552-b6c7-aac1b6a3c6bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_stats(ds_dict):\n",
    "    \"\"\"\n",
    "    Compute yearly mean of each variable in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ds_dict (dict): The input dictionary of xarray.Dataset.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are the dataset names and the values are another dictionary.\n",
    "          This inner dictionary has keys as variable names and values as DataArray of yearly means.\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    for model, ds in ds_dict.items():\n",
    "        # Compute the yearly mean\n",
    "        yearly_ds = ds.resample(time='1Y').mean()\n",
    "\n",
    "        stats[model] = {}\n",
    "        for var in yearly_ds.data_vars:\n",
    "            # Compute the spatial mean\n",
    "            spatial_mean = yearly_ds[var].mean(dim=['lat', 'lon'])\n",
    "            \n",
    "            # Store the yearly mean values\n",
    "            stats[model][var] = spatial_mean\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43015f97-e54e-4f20-aa0c-3e10f0c8d748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_yearly_means(ds_dict):\n",
    "    yearly_means_dict = {}\n",
    "\n",
    "    # For each dataset, compute the yearly mean over the 'time', 'lat', and 'lon' dimensions\n",
    "    for name, ds in ds_dict.items():  \n",
    "        ds_yearly = ds.groupby('time.year').mean('time')    \n",
    "        \n",
    "        yearly_means_dict[name] = ds_yearly\n",
    "\n",
    "    return yearly_means_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbbc45-b47c-461b-99db-d20d9fa0625d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_yearly_regional_means(ds_dict_region):\n",
    "    yearly_means_dict = {}\n",
    "\n",
    "    # For each dataset, compute the yearly mean over the 'time', 'lat', and 'lon' dimensions\n",
    "    for region, ds_dict in ds_dict_region.items():\n",
    "        yearly_means_dict[region] = {}\n",
    "        for ds_name, ds in ds_dict.items():\n",
    "            # Compute the yearly mean\n",
    "            ds_yearly = ds.groupby('time.year').mean('time')\n",
    "            \n",
    "            # Create weights\n",
    "            weights = np.cos(np.deg2rad(ds.lat))\n",
    "            # Apply the weights and calculate the spatial mean\n",
    "            ds_weighted = ds_yearly.weighted(weights)\n",
    "            yearly_means_dict[region][ds_name] = ds_weighted.mean(('lat', 'lon'))\n",
    "\n",
    "    return yearly_means_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b71e4e-b89b-4169-bac4-97f010c2f2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_spatial_mean(ds_dict):\n",
    "    ds_dict_mean = {}\n",
    "    \n",
    "    for key, ds in ds_dict.items():\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        # Initialize a new Dataset for this key\n",
    "        ds_dict_mean[key] = xr.Dataset()\n",
    "        \n",
    "        for var in list(ds.data_vars.keys()):\n",
    "            var_attrs = ds[var].attrs\n",
    "            \n",
    "            ds_dict_mean[key][var] = ds[var].mean(['lon', 'lat'])\n",
    "            ds_dict_mean[key][var].attrs = var_attrs\n",
    "        \n",
    "        ds_dict_mean[key].attrs = attrs\n",
    "        \n",
    "    return ds_dict_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22691ecc-6183-484e-ac91-4c35668756da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_spatial_mean_std(ds_dict):\n",
    "    ds_stats = {}\n",
    "    \n",
    "    for key, ds in ds_dict.items():\n",
    "        attrs = ds.attrs\n",
    "        \n",
    "        # Initialize a new Dataset for spatial statistics\n",
    "        ds_stats[key] = xr.Dataset()\n",
    "        \n",
    "        for var in list(ds.data_vars.keys()):\n",
    "            var_attrs = ds[var].attrs\n",
    "            \n",
    "            # Calculate the mean and standard deviation, skipping NaN values\n",
    "            ds_stats[key][f'{var}'] = ds[var].mean(['lon', 'lat'], skipna=True)\n",
    "            ds_stats[key][f'{var}'].attrs = var_attrs\n",
    "            \n",
    "            # Use a minimum count of 2 for standard deviation to ensure degrees of freedom > 0\n",
    "            ds_stats[key][f'{var}_std'] = ds[var].std(['lon', 'lat'], skipna=True)\n",
    "            ds_stats[key][f'{var}_std'].attrs = var_attrs\n",
    "        \n",
    "        ds_stats[key].attrs = attrs\n",
    "        \n",
    "    return ds_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354754c-b13c-4650-b31b-7ae9e9e424ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_bgws(ds_dict):\n",
    "\n",
    "    for model, ds in ds_dict.items():\n",
    "        bgws = (ds['mrro']-ds['tran'])/ds['pr'] * 100\n",
    "\n",
    "        # Replace infinite values with NaN\n",
    "        bgws = xr.where(np.isinf(bgws), float('nan'), bgws)\n",
    "\n",
    "        # Set all values above 2 and below -2 to NaN\n",
    "        bgws = xr.where(bgws > 200, float('nan'), bgws)\n",
    "        bgws = xr.where(bgws < -200, float('nan'), bgws)\n",
    "\n",
    "        ds_dict[model]['bgws'] = bgws\n",
    "        ds_dict[model]['bgws'].attrs = {'long_name': 'Blue Green Water Share',\n",
    "                             'units': ''}\n",
    "        \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173177e7-1327-46be-9952-4ba5d9d45155",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ebe3c-6f99-46c8-bf2f-0c7e524af04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "season=None # None, 'spring', summer, fall, winter\n",
    "ds_dict = lap.load_and_preprocess(vars=['pr', 'tran', 'mrro', 'bgws'], scenarios=['historical', 'ssp370'], models='all', period=season, yearly_sum=False, period_statistic='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf779e16-eae5-4656-a371-75459f8e7cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict['historical'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cde197-fea2-42ce-9ca4-b424237278ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Compute ensemble and regional mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f21794-0c60-4ba7-87ed-efe8e28acbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict['historical'] = lap.compute_ensemble(ds_dict['historical'], 'mean')\n",
    "ds_dict['historical'] = lap.compute_ensemble(ds_dict['historical'], 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf149a6-c696-4793-8e8f-3bcca2974b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ds_dict['ssp370'].keys():\n",
    "    if 'member_id' in ds_dict['ssp370'][name].coords:\n",
    "        ds_dict['ssp370'][name] = ds_dict['ssp370'][name].drop('member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495a19c-04cb-496b-9a9c-a2c4f77dfb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict['ssp370'] = lap.compute_ensemble(ds_dict['ssp370'], 'mean')\n",
    "ds_dict['ssp370'] = lap.compute_ensemble(ds_dict['ssp370'], 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa4a17-eec1-470d-a5ca-c82d96b8732b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_change = lap.compute_change_dict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbd6d2-3588-4994-aaa5-c40457c4a4e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_dict_change['ssp370-historical'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa50360-f023-4d30-970c-8b4bc91d2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change['ssp370-historical'] = lap.compute_ensemble(ds_dict_change['ssp370-historical'], 'mean')\n",
    "ds_dict_change['ssp370-historical'] = lap.compute_ensemble(ds_dict_change['ssp370-historical'], 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446fee3-dbfb-42e6-a1df-2f6bc19c168e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions = lap.subdivide_region_and_compute_mean(ds_dict, with_global=True, spatial_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ebe0fc-ea6c-4e5f-92ce-04117a05cc67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Subdivide Regions, Compute Mean and Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d835e-5b27-4a05-8a19-547751b3fe60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_mean = lap.subdivide_region_and_compute_mean(ds_dict, with_global=True, spatial_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a5fab-8754-4f2f-8ac0-e18ce6b1e975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change = lap.compute_change_dict(ds_dict_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924e1a6-9025-4f34-98fa-0d02ed399075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change['historical-ssp370'], 'mean')\n",
    "ds_dict_regions_change['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change['historical-ssp370'], 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a494eaf-3077-4645-b782-1a68df807f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change['historical-ssp370']['Ensemble mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc2bb4-6328-4e9f-9d27-bd7f8cc6ebd4",
   "metadata": {},
   "source": [
    "### Test Models with prognostic vegetation against non-prgnostic vegetation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727de90d-5bf4-45e6-b624-285e4b87d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models with prognostic vegetation\n",
    "models_prog_veg = [\n",
    "    'UKESM1-0-LL', \n",
    "    'MPI-ESM1-2-LR', \n",
    "    'GFDL-ESM4'\n",
    "]\n",
    "\n",
    "# Create new dictionaries to store models with and without prognostic vegetation\n",
    "ds_dict_prog_veg = {'historical': {}, 'ssp370': {}}\n",
    "ds_dict_no_prog_veg = {'historical': {}, 'ssp370': {}}\n",
    "\n",
    "# Iterate through the original dictionary and classify models\n",
    "for scenario in ds_dict:\n",
    "    for model in ds_dict[scenario]:\n",
    "        # Exclude 'Ensemble mean' and 'Ensemble median'\n",
    "        if model in ['Ensemble mean', 'Ensemble median']:\n",
    "            continue\n",
    "        if model in models_prog_veg:\n",
    "            ds_dict_prog_veg[scenario][model] = ds_dict[scenario][model]\n",
    "        else:\n",
    "            ds_dict_no_prog_veg[scenario][model] = ds_dict[scenario][model]\n",
    "\n",
    "ds_dict_prog_veg['historical'] = lap.compute_ensemble(ds_dict_prog_veg['historical'], 'mean')\n",
    "ds_dict_prog_veg['historical'] = lap.compute_ensemble(ds_dict_prog_veg['historical'], 'median')\n",
    "ds_dict_no_prog_veg['historical'] = lap.compute_ensemble(ds_dict_no_prog_veg['historical'], 'mean')\n",
    "ds_dict_no_prog_veg['historical'] = lap.compute_ensemble(ds_dict_no_prog_veg['historical'], 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70b9c5-de76-4f3c-8879-2c45a35c76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionaries to store models with and without prognostic vegetation\n",
    "ds_dict_regions_change_prog_veg = {'historical-ssp370': {}}\n",
    "ds_dict_regions_change_no_prog_veg = {'historical-ssp370': {}}\n",
    "\n",
    "# Iterate through the original dictionary and classify models\n",
    "for scenario in ds_dict_regions_change:\n",
    "    for model in ds_dict_regions_change[scenario]:\n",
    "        # Exclude 'Ensemble mean' and 'Ensemble median'\n",
    "        if model in ['Ensemble mean', 'Ensemble median']:\n",
    "            continue\n",
    "        if model in models_prog_veg:\n",
    "            ds_dict_regions_change_prog_veg[scenario][model] = ds_dict_regions_change[scenario][model]\n",
    "        else:\n",
    "            ds_dict_regions_change_no_prog_veg[scenario][model] = ds_dict_regions_change[scenario][model]\n",
    "\n",
    "\n",
    "ds_dict_regions_change_prog_veg['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change_prog_veg['historical-ssp370'], 'mean')\n",
    "ds_dict_regions_change_prog_veg['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change_prog_veg['historical-ssp370'], 'median')\n",
    "ds_dict_regions_change_no_prog_veg['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change_no_prog_veg['historical-ssp370'], 'mean')\n",
    "ds_dict_regions_change_no_prog_veg['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change_no_prog_veg['historical-ssp370'], 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e810ac0-8d73-42ce-9c6b-299c5a2add11",
   "metadata": {},
   "source": [
    "## 4. Plot BGWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894436d-4059-4c95-94a4-6b89a1537f72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab421365-c368-4fae-8744-643cefae1fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "\n",
    "# Define start and end colors for both gradients\n",
    "deep_blue = (20/255, 110/255, 180/255)  \n",
    "light_blue = (180/255, 215/255, 255/255)\n",
    "deep_green = (14/255, 119/255, 14/255) \n",
    "light_green = (160/255, 220/255, 140/255)\n",
    "\n",
    "# Create custom colormaps\n",
    "blue_cmap = LinearSegmentedColormap.from_list(\"blue_cmap\", [light_blue, deep_blue], N=4)\n",
    "green_cmap = LinearSegmentedColormap.from_list(\"green_cmap\", [deep_green, light_green], N=4)\n",
    "\n",
    "# Sample colors from colormaps\n",
    "blue_colors = [blue_cmap(i) for i in np.linspace(0, 1, 4)]\n",
    "green_colors = [green_cmap(i) for i in np.linspace(0, 1, 4)]\n",
    "\n",
    "# Combine both gradients\n",
    "combined_grad = green_colors + blue_colors \n",
    "\n",
    "# Define boundaries\n",
    "boundaries = [-0.1, -0.75, -0.05, -0.25, 0, 0.25, 0.05, 0.75, 0.1]\n",
    "norm = BoundaryNorm(boundaries, len(combined_grad), clip=True)\n",
    "\n",
    "cmap_name = 'BGWS colormap'\n",
    "bgws_cm = LinearSegmentedColormap.from_list(cmap_name, combined_grad, N=len(combined_grad))\n",
    "\n",
    "# To test and display the colormap\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "ax.set_title(cmap_name)\n",
    "plt.imshow(np.linspace(0, 1, 256).reshape(1, -1), aspect='auto', cmap=bgws_cm)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b8274-0bcc-41e6-846d-d6bfcd43a152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors = [(34/255, 139/255, 34/255), (1, 1, 1), (60/255, 145/255, 230/255)]  # Green -> White -> Blue\n",
    "n_bins = [3]  # Discretizes the interpolation into bins\n",
    "cmap_name = 'custom_div_cmap'\n",
    "\n",
    "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "\n",
    "# To test and display the colormap\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "ax.set_title('Custom Diverging Colormap')\n",
    "plt.imshow(np.linspace(0, 1, 256).reshape(1, -1), aspect='auto', cmap=cm)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336ca2b-3903-4089-aa4f-e0d695e0d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkgoldenrod', (1, 1, 1), 'blueviolet']  \n",
    "n_bins = [3]  # Discretizes the interpolation into bins\n",
    "cmap_name = 'custom_div_cmap'\n",
    "\n",
    "cm_change = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "\n",
    "# To test and display the colormap\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "ax.set_title('Custom Diverging Colormap')\n",
    "plt.imshow(np.linspace(0, 1, 256).reshape(1, -1), aspect='auto', cmap=cm_change)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c115f4e-131f-4bb3-865f-9773c0e6f58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import regionmask\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80eb136-bef2-4b96-90bf-a47e952ad8e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot Global BGWS with statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef6910-b666-453b-ab46-7d2164a22a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_ensemble_data_on_map(ds_dict, variable, period, save_fig=False):\n",
    "    \"\"\"\n",
    "    Enhanced function to plot a map with the ensemble mean of the specified variable,\n",
    "    annotated with regions of high uncertainty based on both standard deviation and\n",
    "    interquartile range, visualizing areas where both conditions apply distinctly.\n",
    "    \"\"\"\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    \n",
    "    ensemble_ds = ds_dict['Ensemble mean'][variable]\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        if 'member_id' in ds.coords:\n",
    "            ds = ds.drop('member_id')\n",
    "   \n",
    "    # Plot the selected variable from the dataset\n",
    "    img = ensemble_ds.plot(ax=ax_main, vmin=-60, vmax=60, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "    \n",
    "    # Exclude 'Ensemble mean' and 'Ensemble median' for uncertainty calculation\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "\n",
    "    # Define high uncertainty thresholds\n",
    "    std_dev_threshold = std_dev.mean() + std_dev.std()\n",
    "        \n",
    "    # Identify grid points with high Std Dev \n",
    "    high_std_dev = std_dev > std_dev_threshold\n",
    "    \n",
    "    # Visualize: Assuming you have latitude and longitude coordinates in your DataArray\n",
    "    lon, lat = np.meshgrid(ensemble_ds.lon, ensemble_ds.lat)  # Adjust if necessary\n",
    "    \n",
    "    # For exclusive High Std Dev (not combined with high IQR)\n",
    "    ax_main.scatter(lon[high_std_dev], lat[high_std_dev], color='grey', marker='.', s=20, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Calculate global mean across models for presentation\n",
    "    global_mean_ensmean = ensemble_ds.mean().item()\n",
    "\n",
    "    # Compute std of global mean across models\n",
    "    global_mean_models = models_ds.mean(dim=['lat', 'lon'])\n",
    "    \n",
    "    global_median_ensmean = global_mean_models.median().item()\n",
    "\n",
    "    # Calculate standard deviation of global means across models\n",
    "    global_std_dev_models = global_mean_models.std(dim='model').item()\n",
    "\n",
    "    # Find the minimum and maximum global mean values and their corresponding model names\n",
    "    min_global_mean = global_mean_models.min().item()\n",
    "    min_model = global_mean_models.argmin(dim='model').item()\n",
    "    max_global_mean = global_mean_models.max().item()\n",
    "    max_model = global_mean_models.argmax(dim='model').item()\n",
    "\n",
    "    # Model names\n",
    "    min_model_name = list(ds_dict)[min_model]\n",
    "    max_model_name = list(ds_dict)[max_model]\n",
    "    \n",
    "    # Get Marker size\n",
    "    mean_color = 'blue' if global_mean_ensmean > 0 else 'green'\n",
    "    med_color = 'blue' if global_median_ensmean > 0 else 'green'\n",
    "    min_color = 'blue' if min_global_mean > 0 else 'green'\n",
    "    max_color = 'blue' if max_global_mean > 0 else 'green'\n",
    "    max_abs_mean_val = np.abs(global_mean_models.max().item())  # Assuming this intends to find the maximum value in the ensemble mean dataset\n",
    "    \n",
    "    base_scaling_factor = 2000\n",
    "    \n",
    "    # Example of exponential scaling\n",
    "    exponential_factor = 4  # Adjust based on desired emphasis\n",
    "    mean_marker_size = (abs(global_mean_ensmean) / max_abs_mean_val) * base_scaling_factor\n",
    "    std_marker_size = (abs(global_std_dev_models) / max_abs_mean_val) * base_scaling_factor\n",
    "    med_marker_size = (abs(global_median_ensmean) / max_abs_mean_val) * base_scaling_factor\n",
    "    min_marker_size = (abs(min_global_mean) / max_abs_mean_val) * base_scaling_factor\n",
    "    max_marker_size = (abs(max_global_mean) / max_abs_mean_val) * base_scaling_factor\n",
    "\n",
    "    # Global Mean\n",
    "    # left , up\n",
    "    ax_main.scatter(-172, 0, s=mean_marker_size, color=mean_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, 0, f\"Global EnsMean of BGWS: {round(global_mean_ensmean, 2)}\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "\n",
    "    # Median\n",
    "    ax_main.scatter(-172, -10, s=med_marker_size, color=med_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, -10, f\"Global EnsMed of BGWS: {round(global_median_ensmean, 2)}\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "    \n",
    "    # Min\n",
    "    ax_main.scatter(-172, -20, s=min_marker_size, color=min_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, -20, f\"Global EnsMin: {round(min_global_mean, 2)} ({min_model_name})\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "    \n",
    "    # Max\n",
    "    ax_main.scatter(-172, -30, s=max_marker_size, color=max_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, -30, f\"Global EnsMax: {round(max_global_mean, 2)} ({max_model_name})\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "    \n",
    "    # Standard Deviation of global means\n",
    "    ax_main.scatter(-172, -40, s=std_marker_size, facecolors='white', edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "    ax_main.text(-165, -40, f\"SD of Global BGWS Means: {round(global_std_dev_models, 2)}\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "\n",
    "    \n",
    "    # Add colorbar and legend\n",
    "    cbar = fig.colorbar(img, ax=ax_main, orientation='horizontal', fraction=0.046, pad=0.04, extend='both')\n",
    "    cbar.set_label(\"Blue-Green Water Share\", fontsize=24, weight='bold', labelpad=15) \n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    \n",
    "    # Create custom handles\n",
    "    # Here, 'ms' is the marker size, adjust it as needed\n",
    "    std_dev_handle = mlines.Line2D([], [], color='grey', marker='.', linestyle='None', markersize=30, label='High Model Spread')\n",
    "\n",
    "    # Pass custom handles to the legend\n",
    "    ax_main.legend(handles=[std_dev_handle], loc='lower left', fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean.{variable}.map.without_statistics.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return global_mean_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d115118-d7b4-4f65-9c55-727e1e04dc88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = 'historical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e7494-d333-4778-920a-354956876303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, ds in ds_dict[period].items():\n",
    "    if 'member_id' in ds.coords: \n",
    "        print('ture')\n",
    "        ds_dict[period][name] = ds_dict[period][name].drop('member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b35dd-c0ca-4ea7-a7ed-3b039cac9571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_mean_models = plot_ensemble_data_on_map(ds_dict[period], 'bgws', period, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425b6f2-99ec-44ef-8171-0be705512eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df415cac-bea0-4d9f-bb79-183d57453a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_data_on_map(ds_dict_prog_veg[period], 'bgws', period, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e786e-00b2-4272-b427-8f42124b2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ensemble_data_on_map(ds_dict_no_prog_veg[period], 'bgws', period, save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e20f1-e379-4126-86e3-a7ddbb5de65f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot BGWS latitude plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199db7b-43dc-4106-8251-6ee8a8872012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_ensemble_mean_lat(ds_dict, variable, period, statistic, save_fig=False):\n",
    "    \"\"\"\n",
    "    Function to plot a longitudinal line plot of the ensemble mean for the specified variable,\n",
    "    averaged over latitude. The area between the line and the zero-line will be colored.\n",
    "    \"\"\"\n",
    "    # Initialize the plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 9))\n",
    "    \n",
    "    # Extract the ensemble mean dataset\n",
    "    ensemble_mean = ds_dict['Ensemble mean'][variable]\n",
    "\n",
    "    # Average over latitude\n",
    "    mean_lat =getattr(ensemble_mean, statistic)(dim='lon')\n",
    "    \n",
    "    # Plot the line\n",
    "    lats = mean_lat.lat.values\n",
    "    values = mean_lat.values\n",
    "    #line = ax.plot(values, lats, color='black', label=f'{statistic.title()} $\\Delta$BGWS by Latitude')\n",
    "    line = ax.plot(values, lats, color='black', label=f'{statistic.title()} BGWS by Latitude')\n",
    "\n",
    "\n",
    "    # Fill between the line and zero\n",
    "    ax.fill_betweenx(lats, values, 0, where=(values > 0), facecolor=deep_blue, interpolate=True, alpha=0.5)\n",
    "    ax.fill_betweenx(lats, values, 0, where=(values <= 0), facecolor=deep_green, interpolate=True, alpha=0.5)\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(f'BGWS')\n",
    "    #ax.set_xlabel(f'$\\Delta$BGWS')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    #ax.set_title(f'Latitudinal {statistic.title()} of $\\Delta$BGWS')\n",
    "    ax.set_title(f'Latitudinal {statistic.title()} of BGWS')\n",
    "\n",
    "    # Add grid, legend, and customizations as needed\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'latitudinal_{statistic}.ensemble_mean.{variable}.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "        return filepath\n",
    "    else:\n",
    "        return 'Figure not saved. If you want to save the figure add save_fig=True to the function call'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b718e-4d5c-459d-af51-990922da5308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = 'historical-ssp370'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda843b-ca0d-4d96-865b-8d40301d2dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_ensemble_mean_lat(ds_dict_change[period], 'bgws', period, 'mean', save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74b161-9010-4228-bab9-afca418bf0a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot BGWS with Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6258ed-b2ba-465b-8543-87c5b8255f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "def split_polygon(polygon, meridian=180):\n",
    "    \"\"\"\n",
    "    Splits a Shapely polygon into two polygons at a specified meridian\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    if maxx > meridian and minx < -meridian:\n",
    "        # Polygon crosses the antimeridian\n",
    "        left_poly = []\n",
    "        right_poly = []\n",
    "        for x, y in polygon.exterior.coords:\n",
    "            if x >= meridian:\n",
    "                right_poly.append((x - 360, y))  # Wraparound for the right side\n",
    "                print(f'Wraparound for the right side')\n",
    "            else:\n",
    "                left_poly.append((x, y))\n",
    "                print(f'left_poly.append((x, y))')\n",
    "        return [Polygon(left_poly), Polygon(right_poly)]\n",
    "    else:\n",
    "        print(f'nothing')\n",
    "        return [polygon]  # Wrap the single polygon in a list for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a7d7f3-3baa-4550-993b-b80f443ad475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_regions_with_uncertainty(ds_dict, ds_dict_regions, variable, period, save_fig=False):\n",
    "    \"\"\"\n",
    "    Plot regions with the ensemble mean of the specified variable,\n",
    "    annotated with regions of high uncertainty based on standard deviation,\n",
    "    visualizing areas where uncertainty is distinct.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    \n",
    "    # Assuming 'Ensemble mean' is already calculated and included in ds_dict\n",
    "    ensemble_ds = ds_dict['Ensemble mean'][variable]\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        if 'member_id' in ds.coords:\n",
    "            ds = ds.drop('member_id')\n",
    "    \n",
    "    # Plot the selected variable from the dataset\n",
    "    img = ensemble_ds.plot(ax=ax_main, vmin=-60, vmax=60, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "    \n",
    "     # Exclude 'Ensemble mean' and 'Ensemble median' for uncertainty calculation\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "\n",
    "    # Define high uncertainty thresholds\n",
    "    std_dev_threshold = std_dev.mean() + std_dev.std()\n",
    "        \n",
    "    # Identify grid points with high Std Dev and IQR\n",
    "    high_std_dev = std_dev > std_dev_threshold\n",
    "    \n",
    "    # Visualize: Assuming you have latitude and longitude coordinates in your DataArray\n",
    "    lon, lat = np.meshgrid(ensemble_ds.lon, ensemble_ds.lat)  # Adjust if necessary\n",
    "    \n",
    "    # For exclusive High Std Dev (not combined with high IQR)\n",
    "    ax_main.scatter(lon[high_std_dev], lat[high_std_dev], color='grey', marker='.', s=20, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    # Get region bounds using regionmask\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "\n",
    "    # Exclude 'Ensemble mean' and 'Ensemble median' for uncertainty calculation\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "    \n",
    "    # Use regionmask to define regions on the map\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    \n",
    "    # Loop over the regions and overlay uncertainty based on std deviation from regional ensemble mean\n",
    "    for region_number in land_regions.numbers:\n",
    "        if region_number in ds_dict_regions['Ensemble mean'][variable].region.values:\n",
    "            region_name = ds_dict_regions['Ensemble mean'].names.sel(region=region_number).item()\n",
    "            if region_name.lower() == 'land':\n",
    "                continue  # Skip the 'land' region\n",
    "\n",
    "            region_ds = ds_dict_regions['Ensemble mean'].sel(region=region_number)\n",
    "            region_mean = region_ds[variable].mean().item()\n",
    "            region_abbr = region_ds.abbrevs.values[region_ds.region.values == region_number][0]\n",
    "            \n",
    "            # Compute std of regional mean across models\n",
    "            models_ds_region = xr.concat([ds[variable].sel(region=region_number) for name, ds in ds_dict_regions.items() if \"Ensemble\" not in name], dim='model')\n",
    "            regional_mean_models = models_ds_region.mean(dim=['lat', 'lon'])\n",
    "            regional_std_dev_models = regional_mean_models.std(dim='model').item()\n",
    "            \n",
    "            # Fetch the polygon for this region\n",
    "            region_obj = land_regions[region_number]\n",
    "            if hasattr(region_obj, 'polygons'):\n",
    "                region_polygons = region_obj.polygons\n",
    "            elif hasattr(region_obj, 'polygon'):\n",
    "                region_polygons = [region_obj.polygon]\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            for region_polygon in region_polygons:\n",
    "                feature = ShapelyFeature([region_polygon], ccrs.PlateCarree(), edgecolor='gray', facecolor='none', linewidth=2, alpha=0.7)\n",
    "                ax_main.add_feature(feature, zorder=1)\n",
    "                \n",
    "                region_obj = land_regions[region_number]\n",
    "                region_polygons = getattr(region_obj, 'polygons', [region_obj.polygon]) if hasattr(region_obj, 'polygons') or hasattr(region_obj, 'polygon') else []\n",
    "\n",
    "                centroid = region_polygon.centroid.coords[0]\n",
    "\n",
    "                # Scale marker sizes for visibility\n",
    "                base_scaling_factor = 200\n",
    "                marker_size_mean = np.sqrt(abs(region_mean)) * base_scaling_factor\n",
    "                marker_size_std = np.sqrt(abs(regional_std_dev_models)) * base_scaling_factor\n",
    "                \n",
    "                # Get marker color\n",
    "                color = 'blue' if region_mean > 0 else 'green'\n",
    "\n",
    "                # Place a single marker at the centroid of each region\n",
    "                if (region_name == 'West&Central-Europe' \n",
    "                    or region_name == 'N.Australia' \n",
    "                    or region_name == 'Greenland/Iceland'\n",
    "                    or region_name == 'C.Australia'\n",
    "                    or region_name == 'E.C.Asia'\n",
    "                    or region_name == 'Tibetan-Plateau'\n",
    "                    or region_name == 'Russian-Arctic'\n",
    "                    or region_name == 'Sahara'\n",
    "                    or region_name =='S.Asia'\n",
    "                   ):\n",
    "                    ax_main.scatter(centroid[0]-1.1, centroid[1], s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+7.1, centroid[1], s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0]-12.1, centroid[1], f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "                elif (region_name == 'N.Eastern-Africa'\n",
    "                      or region_name == 'S.Eastern-Africa'\n",
    "                     ):\n",
    "                    ax_main.scatter(centroid[0]+7.1, centroid[1], s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+15.1, centroid[1], s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0]-4.1, centroid[1], f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "                elif (region_name == 'N.Central-America'\n",
    "                      or region_name == 'S.Central-America'\n",
    "                     ):\n",
    "                    ax_main.scatter(centroid[0]-4.1, centroid[1]-4, s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+4.1, centroid[1]-4, s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0]-5.1, centroid[1]+4, f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "                else:\n",
    "                    ax_main.scatter(centroid[0]-4.1, centroid[1]-4, s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+4.1, centroid[1]-4, s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0], centroid[1]+4, f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "\n",
    "                \n",
    "    # Add colorbar and legend\n",
    "    cbar = fig.colorbar(img, ax=ax_main, orientation='horizontal', fraction=0.046, pad=0.04, extend='both')\n",
    "    cbar.set_label(\"Blue-Green Water Share\", fontsize=24, weight='bold', labelpad=15) \n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    \n",
    "    # Create custom handles\n",
    "    # Here, 'ms' is the marker size, adjust it as needed\n",
    "    std_dev_handle = mlines.Line2D([], [], color='grey', marker='.', linestyle='None', markersize=30, \n",
    "                                   label='$\\sigma$ > $\\mu_{\\sigma}$ + $\\sigma_{\\sigma}$')\n",
    "    mean_handle = mlines.Line2D([], [], color='white', marker='o', linestyle='None', markersize=30, \n",
    "                                markeredgecolor='black', markerfacecolor='green', markerfacecoloralt='blue', fillstyle = 'left', label='Regional EnsMean of BGWS')\n",
    "    std_handle = mlines.Line2D([], [], color='white', marker='o', linestyle='None', markersize=30, \n",
    "                               markeredgecolor='black', markerfacecolor='white', label='SD of Regional BGWS Means')   \n",
    "    \n",
    "    # Pass custom handles to the legend\n",
    "    ax_main.legend(handles=[mean_handle, std_handle, std_dev_handle], loc='lower left', fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean.{variable}.map.regions_winter.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3bdaca-6985-4dd7-91dc-7a842fffd955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = 'ssp370'\n",
    "plot_regions_with_uncertainty(ds_dict[period], ds_dict_regions[period], 'bgws', period, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13796172-2caa-4675-8249-71e7b6c2d6df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot BGWS with zoomed in Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e39e35-0a09-4d29-8e19-19f03cef7252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate dynamic font size\n",
    "def calculate_font_size(minx, maxx, miny, maxy, base_font_size=18):\n",
    "    \"\"\"\n",
    "    Dynamically calculate font size based on the extent of the map.\n",
    "    \n",
    "    Args:\n",
    "        minx, maxx, miny, maxy: Extent of the map.\n",
    "        base_font_size: Base size to adjust from.\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted font size.\n",
    "    \"\"\"\n",
    "    # Example calculation - this can be adjusted based on your needs\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "    scale_factor = np.sqrt(width * height) / 22  # Example scaling factor - adjust as needed\n",
    "    print(scale_factor)\n",
    "    return max(base_font_size * scale_factor, base_font_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d40b688-96aa-4d1b-bc59-426a0081202a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region_zoom_with_uncertainty(ds_dict, ds_dict_regions, variable, region_name, period, save_fig=False):\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    \n",
    "    ensemble_ds = ds_dict['Ensemble mean'][variable]\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        if 'member_id' in ds.coords:\n",
    "            ds_dict[name] = ds.drop('member_id')\n",
    "    for name, ds in ds_dict_regions.items():\n",
    "        if 'member_id' in ds_dict_regions[name].coords:\n",
    "            ds_dict_regions[name] = ds_dict_regions[name].drop('member_id')\n",
    "    \n",
    "    # Additional code to plot all polygons and adjust zoom\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    selected_region = land_regions[region_name]\n",
    "    \n",
    "    if hasattr(selected_region, 'polygons'):  # For regions with multiple polygons\n",
    "        all_polygons = selected_region.polygons\n",
    "    else:  # For regions defined by a single polygon\n",
    "        all_polygons = [selected_region.polygon]\n",
    "        \n",
    "    # Calculating the combined bounds of all polygons to adjust zoom\n",
    "    minx, miny, maxx, maxy = np.inf, np.inf, -np.inf, -np.inf\n",
    "    \n",
    "    for geom in all_polygons:\n",
    "        if isinstance(geom, Polygon):\n",
    "            # Directly calculate bounds for a Polygon\n",
    "            p_minx, p_miny, p_maxx, p_maxy = geom.bounds\n",
    "            minx, miny = min(minx, p_minx), min(miny, p_miny)\n",
    "            maxx, maxy = max(maxx, p_maxx), max(maxy, p_maxy)\n",
    "            ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "            img = ensemble_ds.plot(ax=ax_main, vmin=-60, vmax=60, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "            ax_main.add_geometries([geom], crs=ccrs.PlateCarree(), edgecolor='black', facecolor='none')\n",
    "        elif isinstance(geom, MultiPolygon):\n",
    "            # Iterate over each polygon in the MultiPolygon to calculate bounds\n",
    "            ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=180))\n",
    "            img = ensemble_ds.plot(ax=ax_main, vmin=-60, vmax=60, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "                \n",
    "            minx, maxx = -np.inf, np.inf\n",
    "            for polygon in geom:\n",
    "                p_minx, p_miny, p_maxx, p_maxy = polygon.bounds\n",
    "                minx, miny = max(minx, p_minx), min(miny, p_miny)\n",
    "                maxx, maxy = min(maxx, p_maxx), max(maxy, p_maxy)\n",
    "                ax_main.add_geometries([polygon], crs=ccrs.PlateCarree(), edgecolor='black', facecolor='none')\n",
    "\n",
    "   # Adjusting map extent with a small buffer\n",
    "    buffer = 2  # Adjust the buffer size as needed\n",
    "    \n",
    "    if maxx < minx:\n",
    "        maxx_ = 360 + maxx\n",
    "    else:\n",
    "        maxx_ = maxx\n",
    "    \n",
    "    if maxx_ == 180:\n",
    "        ax_main.set_extent([minx - buffer, min((maxx_ + buffer), 180), miny - buffer , maxy + buffer], crs=ccrs.PlateCarree())\n",
    "    else:\n",
    "        ax_main.set_extent([minx - buffer, maxx_ + buffer, miny - buffer , maxy + buffer], crs=ccrs.PlateCarree())\n",
    "    #print(minx - buffer, maxx_ + buffer, miny - buffer, maxy + buffer)\n",
    "    \n",
    "    #font_size = calculate_font_size(minx, maxx_, miny, maxy)\n",
    "  \n",
    "    # Compute the stats for uncertainty dots\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "    std_dev_threshold = std_dev.mean() + std_dev.std()\n",
    "    high_std_dev = std_dev > std_dev_threshold\n",
    "    \n",
    "    lon, lat = np.meshgrid(ensemble_ds.lon, ensemble_ds.lat)\n",
    "    \n",
    "    ax_main.scatter(lon[high_std_dev], lat[high_std_dev], color='grey', marker='.', s=200, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    # Overlay uncertainty and mean ± std text for the zoomed region\n",
    "    region_ds = ds_dict_regions['Ensemble mean'].sel(region=selected_region.number)\n",
    "    region_mean = region_ds[variable].mean().item()\n",
    "    \n",
    "    # Compute std of regional mean across models\n",
    "    models_ds_region = xr.concat([ds[variable].sel(region=selected_region.number) for name, ds in ds_dict_regions.items() if \"Ensemble\" not in name], dim='model')\n",
    "    regional_mean_models = models_ds_region.mean(dim=['lat', 'lon'])\n",
    "    regional_std_dev_models = regional_mean_models.std(dim='model').item()\n",
    "    \n",
    "    # Assuming selected_region is a polygon and we're accessing its centroid    \n",
    "    centroid = selected_region.centroid\n",
    "\n",
    "    # Now use centroid[0] and centroid[1] as the longitude and latitude\n",
    "    ax_main.text(centroid[0], centroid[1], f'Mean: {region_mean:.2f} \\n ± {regional_std_dev_models:.2f}',\n",
    "                 fontsize=38, ha='center', va='bottom', transform=ccrs.PlateCarree(),\n",
    "                 bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.5))\n",
    "    \n",
    "    # Add colorbar and legend\n",
    "    cbar = fig.colorbar(img, ax=ax_main, orientation='horizontal', fraction=0.046, pad=0.04, extend='both')\n",
    "    cbar.set_label(\"Blue-Green Water Share\", fontsize=24, weight='bold', labelpad=15) \n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    \n",
    "    std_dev_handle = mlines.Line2D([], [], color='grey', marker='.', linestyle='None', markersize=30, \n",
    "                                   label='High Model Spread')\n",
    "  \n",
    "    ax_main.legend(handles=[std_dev_handle], loc='lower left', fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        region_names = region_name.replace(\"/\", \"_\")\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'regional_maps')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_{variable}_region_zoom_{region_names}.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    else:\n",
    "        filepath = 'Figure not saved. Add save_fig=True to save the figure.'\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019bf91-6eff-4f5f-8f30-a2d6c04fe75f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = 'historical'\n",
    "for names in ds_dict_regions[period]['BCC-CSM2-MR'].names.values:\n",
    "    # Skip the iteration if the name is 'land'\n",
    "    if names == 'land':\n",
    "        continue\n",
    "    plot_region_zoom_with_uncertainty(ds_dict[period], ds_dict_regions[period], 'bgws', names, period, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560313a-6b1a-4051-a8cb-271014aa051e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Global BGWS Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb9c6bd-3d90-4901-9bed-15c31e830333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_global_BGWS_change(ds_dict, variable, period, save_fig=False):\n",
    "    \"\"\"\n",
    "    Enhanced function to plot a map with the ensemble mean of the specified variable,\n",
    "    annotated with regions of high uncertainty based on both standard deviation and\n",
    "    interquartile range, visualizing areas where both conditions apply distinctly.\n",
    "    \"\"\"\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    \n",
    "    ensemble_ds = ds_dict['Ensemble mean'][variable]\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        if 'member_id' in ds.coords:\n",
    "            ds = ds.drop('member_id')\n",
    "    \n",
    "    # Plot the selected variable from the dataset\n",
    "    img = ensemble_ds.plot(ax=ax_main, vmin=-50, vmax=50, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "    \n",
    "    # Exclude 'Ensemble mean' and 'Ensemble median' for uncertainty calculation\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "\n",
    "    # Define high uncertainty thresholds\n",
    "    std_dev_threshold = std_dev.mean() + std_dev.std()\n",
    "        \n",
    "    # Identify grid points with high Std Dev and IQR\n",
    "    high_std_dev = std_dev > std_dev_threshold\n",
    "    \n",
    "    # Visualize: Assuming you have latitude and longitude coordinates in your DataArray\n",
    "    lon, lat = np.meshgrid(ensemble_ds.lon, ensemble_ds.lat)  # Adjust if necessary\n",
    "    \n",
    "    # For exclusive High Std Dev (not combined with high IQR)\n",
    "    ax_main.scatter(lon[high_std_dev], lat[high_std_dev], color='grey', marker='.', s=20, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Calculate global mean across models for presentation\n",
    "    global_mean_ensmean = ensemble_ds.mean().item()\n",
    "\n",
    "    # Compute std of global mean across models\n",
    "    global_mean_models = models_ds.mean(dim=['lat', 'lon'])\n",
    "    \n",
    "    global_median_ensmean = global_mean_models.median().item()\n",
    "\n",
    "    # Calculate standard deviation of global means across models\n",
    "    global_std_dev_models = global_mean_models.std(dim='model').item()\n",
    "\n",
    "    # Find the minimum and maximum global mean values and their corresponding model names\n",
    "    min_global_mean = global_mean_models.min().item()\n",
    "    min_model = global_mean_models.argmin(dim='model').item()\n",
    "    max_global_mean = global_mean_models.max().item()\n",
    "    max_model = global_mean_models.argmax(dim='model').item()\n",
    "\n",
    "    # Model names\n",
    "    min_model_name = list(ds_dict)[min_model]\n",
    "    max_model_name = list(ds_dict)[max_model]\n",
    "    \n",
    "    # Get Marker size\n",
    "    mean_color = 'blue' if global_mean_ensmean > 0 else 'green'\n",
    "    med_color = 'blue' if global_median_ensmean > 0 else 'green'\n",
    "    min_color = 'blue' if min_global_mean > 0 else 'green'\n",
    "    max_color = 'blue' if max_global_mean > 0 else 'green'\n",
    "    max_abs_mean_val = np.abs(global_mean_models.max().item())  # Assuming this intends to find the maximum value in the ensemble mean dataset\n",
    "    \n",
    "    base_scaling_factor = 2000\n",
    "    \n",
    "    # Example of exponential scaling\n",
    "    exponential_factor = 4  # Adjust based on desired emphasis\n",
    "    mean_marker_size = (abs(global_mean_ensmean) / max_abs_mean_val) * base_scaling_factor\n",
    "    std_marker_size = (abs(global_std_dev_models) / max_abs_mean_val) * base_scaling_factor\n",
    "    med_marker_size = (abs(global_median_ensmean) / max_abs_mean_val) * base_scaling_factor\n",
    "    min_marker_size = (abs(min_global_mean) / max_abs_mean_val) * base_scaling_factor\n",
    "    max_marker_size = (abs(max_global_mean) / max_abs_mean_val) * base_scaling_factor\n",
    "\n",
    "    # Global Mean\n",
    "    # left , up\n",
    "    ax_main.scatter(-172, 0, s=mean_marker_size, color=mean_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, 0, f\"Global EnsMean of $\\Delta$ BGWS: {round(global_mean_ensmean, 2)}\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "\n",
    "    # Median\n",
    "    ax_main.scatter(-172, -10, s=med_marker_size, color=med_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, -10, f\"Global EnsMed of $\\Delta$ BGWS: {round(global_median_ensmean, 2)}\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "    \n",
    "    # Min\n",
    "    ax_main.scatter(-172, -20, s=min_marker_size, color=min_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, -20, f\"Global EnsMin: {round(min_global_mean, 2)} ({min_model_name})\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "    \n",
    "    # Max\n",
    "    ax_main.scatter(-172, -30, s=max_marker_size, color=max_color, alpha=1, transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "    ax_main.text(-165, -30, f\"Global EnsMax: {round(max_global_mean, 2)} ({max_model_name})\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "    \n",
    "    # Standard Deviation of global means\n",
    "    ax_main.scatter(-172, -40, s=std_marker_size, facecolors='white', edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "    ax_main.text(-165, -40, f\"SD of Global $\\Delta$ BGWS Means: {round(global_std_dev_models, 2)}\", horizontalalignment='left', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize=24, rotation=0, bbox=dict(facecolor='white', alpha=0.75, edgecolor='none'))\n",
    "\n",
    "    # Add colorbar and legend\n",
    "    cbar = fig.colorbar(img, ax=ax_main, orientation='horizontal', fraction=0.046, pad=0.04, extend='both')\n",
    "    cbar.set_label(\"$\\Delta$ Blue-Green Water Share\", fontsize=24, weight='bold', labelpad=15) \n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    \n",
    "    # Create custom handles\n",
    "    # Here, 'ms' is the marker size, adjust it as needed\n",
    "    std_dev_handle = mlines.Line2D([], [], color='grey', marker='.', linestyle='None', markersize=30, label='$\\sigma$ > $\\mu_{\\sigma}$ + $\\sigma_{\\sigma}$')\n",
    "\n",
    "    # Pass custom handles to the legend\n",
    "    ax_main.legend(handles=[std_dev_handle], loc='lower left', fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'change_map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_change.{variable}.map.with_median_winter.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return global_mean_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70087c-bbaf-4fae-9d7f-52df1ec9d287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = 'ssp370-historical'\n",
    "for name, ds in ds_dict_change[period].items():\n",
    "    if 'member_id' in ds.coords: \n",
    "        print('ture')\n",
    "        ds_dict_change[period][name] = ds_dict_change[period][name].drop('member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b32416-65f1-40e0-8e17-0c529a2606ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_global_BGWS_change(ds_dict_change[period], 'bgws', period, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb4f4c-7a2f-4917-aca8-64de4d991457",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict_change[period].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd160cd5-5ff5-47ce-a5c3-587c92f8a64c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot BGWS Change with Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67197e5-0e2f-46ae-a953-5b481d826e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_regions_change_with_uncertainty(ds_dict, ds_dict_regions, variable, period, save_fig=False):\n",
    "    \"\"\"\n",
    "    Plot regions with the ensemble mean of the specified variable,\n",
    "    annotated with regions of high uncertainty based on standard deviation,\n",
    "    visualizing areas where uncertainty is distinct.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    \n",
    "    # Assuming 'Ensemble mean' is already calculated and included in ds_dict\n",
    "    ensemble_ds = ds_dict['Ensemble mean'][variable]\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        if 'member_id' in ds.coords:\n",
    "            ds = ds.drop('member_id')\n",
    "    \n",
    "    # Plot the selected variable from the dataset\n",
    "    img = ensemble_ds.plot(ax=ax_main, vmin=-10, vmax=10, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "    \n",
    "     # Exclude 'Ensemble mean' and 'Ensemble median' for uncertainty calculation\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "\n",
    "    # Define high uncertainty thresholds\n",
    "    std_dev_threshold = std_dev.mean() + std_dev.std()\n",
    "        \n",
    "    # Identify grid points with high Std Dev and IQR\n",
    "    high_std_dev = std_dev > std_dev_threshold\n",
    "    \n",
    "    # Visualize: Assuming you have latitude and longitude coordinates in your DataArray\n",
    "    lon, lat = np.meshgrid(ensemble_ds.lon, ensemble_ds.lat)  # Adjust if necessary\n",
    "    \n",
    "    # For exclusive High Std Dev (not combined with high IQR)\n",
    "    ax_main.scatter(lon[high_std_dev], lat[high_std_dev], color='grey', marker='.', s=20, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    # Get region bounds using regionmask\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "\n",
    "    # Exclude 'Ensemble mean' and 'Ensemble median' for uncertainty calculation\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "    \n",
    "    # Use regionmask to define regions on the map\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    \n",
    "    # Loop over the regions and overlay uncertainty based on std deviation from regional ensemble mean\n",
    "    for region_number in land_regions.numbers:\n",
    "        if region_number in ds_dict_regions['Ensemble mean'][variable].region.values:\n",
    "            region_name = ds_dict_regions['Ensemble mean'].names.sel(region=region_number).item()\n",
    "            if region_name.lower() == 'land':\n",
    "                continue  # Skip the 'land' region\n",
    "\n",
    "            region_ds = ds_dict_regions['Ensemble mean'].sel(region=region_number)\n",
    "            region_mean = region_ds[variable].mean().item()\n",
    "            region_abbr = region_ds.abbrevs.values[region_ds.region.values == region_number][0]\n",
    "            \n",
    "            # Compute std of regional mean across models\n",
    "            models_ds_region = xr.concat([ds[variable].sel(region=region_number) for name, ds in ds_dict_regions.items() if \"Ensemble\" not in name], dim='model')\n",
    "            regional_mean_models = models_ds_region.mean(dim=['lat', 'lon'])\n",
    "            regional_std_dev_models = regional_mean_models.std(dim='model').item()\n",
    "            \n",
    "            # Fetch the polygon for this region\n",
    "            region_obj = land_regions[region_number]\n",
    "            if hasattr(region_obj, 'polygons'):\n",
    "                region_polygons = region_obj.polygons\n",
    "            elif hasattr(region_obj, 'polygon'):\n",
    "                region_polygons = [region_obj.polygon]\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            for region_polygon in region_polygons:\n",
    "                feature = ShapelyFeature([region_polygon], ccrs.PlateCarree(), edgecolor='gray', facecolor='none', linewidth=2, alpha=0.7)\n",
    "                ax_main.add_feature(feature, zorder=1)\n",
    "                \n",
    "                region_obj = land_regions[region_number]\n",
    "                region_polygons = getattr(region_obj, 'polygons', [region_obj.polygon]) if hasattr(region_obj, 'polygons') or hasattr(region_obj, 'polygon') else []\n",
    "\n",
    "                centroid = region_polygon.centroid.coords[0]\n",
    "\n",
    "                # Scale marker sizes for visibility\n",
    "                base_scaling_factor = 200\n",
    "                marker_size_mean = np.sqrt(abs(region_mean)) * base_scaling_factor\n",
    "                marker_size_std = np.sqrt(abs(regional_std_dev_models)) * base_scaling_factor\n",
    "                \n",
    "                # Get marker color\n",
    "                color = 'blue' if region_mean > 0 else 'green'\n",
    "\n",
    "                # Place a single marker at the centroid of each region\n",
    "                if (region_name == 'West&Central-Europe' \n",
    "                    or region_name == 'N.Australia' \n",
    "                    or region_name == 'Greenland/Iceland'\n",
    "                    or region_name == 'C.Australia'\n",
    "                    or region_name == 'E.C.Asia'\n",
    "                    or region_name == 'Tibetan-Plateau'\n",
    "                    or region_name == 'Russian-Arctic'\n",
    "                    or region_name == 'Sahara'\n",
    "                    or region_name =='S.Asia'\n",
    "                   ):\n",
    "                    ax_main.scatter(centroid[0]-1.1, centroid[1], s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+7.1, centroid[1], s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0]-12.1, centroid[1], f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "                elif (region_name == 'N.Eastern-Africa'\n",
    "                      or region_name == 'S.Eastern-Africa'\n",
    "                     ):\n",
    "                    ax_main.scatter(centroid[0]+7.1, centroid[1], s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+15.1, centroid[1], s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0]-4.1, centroid[1], f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "                elif (region_name == 'N.Central-America'\n",
    "                      or region_name == 'S.Central-America'\n",
    "                     ):\n",
    "                    ax_main.scatter(centroid[0]-4.1, centroid[1]-4, s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+4.1, centroid[1]-4, s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0]-5.1, centroid[1]+4, f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "                else:\n",
    "                    ax_main.scatter(centroid[0]-4.1, centroid[1]-4, s=marker_size_mean, color=color, alpha=1, \n",
    "                                    transform=ccrs.PlateCarree(), edgecolor='black', zorder=2)\n",
    "                    ax_main.scatter(centroid[0]+4.1, centroid[1]-4, s=marker_size_std,  facecolors='white', \n",
    "                                    edgecolors='black', transform=ccrs.PlateCarree(), zorder=2) \n",
    "                \n",
    "                    # Annotate the region with abbreviation and marker\n",
    "                    ax_main.text(centroid[0], centroid[1]+4, f\"{region_abbr}\",\n",
    "                                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                                 fontsize=24, rotation=0, \n",
    "                                 bbox=dict(facecolor='white', alpha=0.75, edgecolor='none')) \n",
    "\n",
    "                \n",
    "    # Add colorbar and legend\n",
    "    cbar = fig.colorbar(img, ax=ax_main, orientation='horizontal', fraction=0.046, pad=0.04, extend='both')\n",
    "    cbar.set_label(\"$\\Delta$ Blue-Green Water Share\", fontsize=24, weight='bold', labelpad=15) \n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    \n",
    "    # Create custom handles\n",
    "    # Here, 'ms' is the marker size, adjust it as needed\n",
    "    std_dev_handle = mlines.Line2D([], [], color='grey', marker='.', linestyle='None', markersize=30, \n",
    "                                   label='$\\sigma$ > $\\mu_{\\sigma}$ + $\\sigma_{\\sigma}$')\n",
    "    mean_handle = mlines.Line2D([], [], color='white', marker='o', linestyle='None', markersize=30, \n",
    "                                markeredgecolor='black', markerfacecolor='green', markerfacecoloralt='blue', fillstyle = 'left', label='Regional EnsMean of $\\Delta$ BGWS')\n",
    "    std_handle = mlines.Line2D([], [], color='white', marker='o', linestyle='None', markersize=30, \n",
    "                               markeredgecolor='black', markerfacecolor='white', label='SD of Regional $\\Delta$ BGWS Means')   \n",
    "    \n",
    "    # Pass custom handles to the legend\n",
    "    ax_main.legend(handles=[mean_handle, std_handle, std_dev_handle], loc='lower left', fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'change_map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_change.{variable}.map.regions_winter.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5cce9-76ba-45ae-9f09-3098ed7be120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = 'historical-ssp370'\n",
    "plot_regions_change_with_uncertainty(ds_dict_change[period], ds_dict_regions_change[period], 'bgws', period, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb7a4b-43fc-40e6-b234-aad4b13ce46a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot BGWS Change with Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ed81e-5cfa-4e08-a8ce-9e7f6844b61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13270190-9b1b-4e53-b7a5-70019c61b769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8c854-bc0b-426b-9078-75bc1f9e69f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_region_change_zoom_with_uncertainty(ds_dict, ds_dict_regions, variable, region_name, period, save_fig=False):\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    \n",
    "    ensemble_ds = ds_dict['Ensemble mean'][variable]\n",
    "    \n",
    "    for name, ds in ds_dict.items():\n",
    "        if 'member_id' in ds.coords:\n",
    "            ds_dict[name] = ds.drop('member_id')\n",
    "    for name, ds in ds_dict_regions.items():\n",
    "        if 'member_id' in ds_dict_regions[name].coords:\n",
    "            ds_dict_regions[name] = ds_dict_regions[name].drop('member_id')\n",
    "    \n",
    "    # Additional code to plot all polygons and adjust zoom\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    selected_region = land_regions[region_name]\n",
    "    \n",
    "    if hasattr(selected_region, 'polygons'):  # For regions with multiple polygons\n",
    "        all_polygons = selected_region.polygons\n",
    "    else:  # For regions defined by a single polygon\n",
    "        all_polygons = [selected_region.polygon]\n",
    "        \n",
    "    # Calculating the combined bounds of all polygons to adjust zoom\n",
    "    minx, miny, maxx, maxy = np.inf, np.inf, -np.inf, -np.inf\n",
    "    \n",
    "    for geom in all_polygons:\n",
    "        if isinstance(geom, Polygon):\n",
    "            # Directly calculate bounds for a Polygon\n",
    "            p_minx, p_miny, p_maxx, p_maxy = geom.bounds\n",
    "            minx, miny = min(minx, p_minx), min(miny, p_miny)\n",
    "            maxx, maxy = max(maxx, p_maxx), max(maxy, p_maxy)\n",
    "            ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "            img = ensemble_ds.plot(ax=ax_main, vmin=-10, vmax=10, cmap=cm_change, transform=ccrs.PlateCarree(), add_colorbar=False, add_labels=False)\n",
    "            ax_main.add_geometries([geom], crs=ccrs.PlateCarree(), edgecolor='black', facecolor='none')\n",
    "        elif isinstance(geom, MultiPolygon):\n",
    "            # Iterate over each polygon in the MultiPolygon to calculate bounds\n",
    "            ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=180))\n",
    "            img = ensemble_ds.plot(ax=ax_main, vmin=-10, vmax=10, cmap=cm_change, transform=ccrs.PlateCarree(), add_colorbar=False, add_labels=False)\n",
    "                \n",
    "            minx, maxx = -np.inf, np.inf\n",
    "            for polygon in geom:\n",
    "                p_minx, p_miny, p_maxx, p_maxy = polygon.bounds\n",
    "                minx, miny = max(minx, p_minx), min(miny, p_miny)\n",
    "                maxx, maxy = min(maxx, p_maxx), max(maxy, p_maxy)\n",
    "                ax_main.add_geometries([polygon], crs=ccrs.PlateCarree(), edgecolor='black', facecolor='none')\n",
    "\n",
    "    # Adjusting map extent with a small buffer\n",
    "    buffer = 2  # Adjust the buffer size as needed\n",
    "    \n",
    "    if maxx < minx:\n",
    "        maxx_ = 360 + maxx\n",
    "    else:\n",
    "        maxx_ = maxx\n",
    "    \n",
    "    if maxx_ == 180:\n",
    "        ax_main.set_extent([minx - buffer, min((maxx_ + buffer), 180), miny - buffer , maxy + buffer], crs=ccrs.PlateCarree())\n",
    "    else:\n",
    "        ax_main.set_extent([minx - buffer, maxx_ + buffer, miny - buffer , maxy + buffer], crs=ccrs.PlateCarree())\n",
    "    #print(minx - buffer, maxx_ + buffer, miny - buffer, maxy + buffer)\n",
    "    \n",
    "    #font_size = calculate_font_size(minx, maxx_, miny, maxy)\n",
    "  \n",
    "    # Compute the stats for uncertainty dots\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    # Determine the sign of the change for each model at each grid cell using numpy.sign\n",
    "    # Compute the stats for uncertainty dots\n",
    "    models_ds = xr.concat([ds[variable] for name, ds in ds_dict.items() if \"Ensemble\" not in name], dim='model')\n",
    "    std_dev = models_ds.std(dim='model')\n",
    "    std_dev_threshold = std_dev.mean() + std_dev.std()\n",
    "    low_agreement = std_dev > std_dev_threshold\n",
    "    \n",
    "    lon, lat = np.meshgrid(ensemble_ds.lon, ensemble_ds.lat)\n",
    "    \n",
    "    ax_main.scatter(lon[low_agreement], lat[low_agreement], color='grey', marker='.', s=200, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    # Overlay uncertainty and mean ± std text for the zoomed region\n",
    "    region_ds = ds_dict_regions['Ensemble mean'].sel(region=selected_region.number)\n",
    "    region_mean = region_ds[variable].mean().item()\n",
    "    \n",
    "    # Compute std of regional mean across models\n",
    "    models_ds_region = xr.concat([ds[variable].sel(region=selected_region.number) for name, ds in ds_dict_regions.items() if \"Ensemble\" not in name], dim='model')\n",
    "    regional_mean_models = models_ds_region.mean(dim=['lat', 'lon'])\n",
    "    regional_std_dev_models = regional_mean_models.std(dim='model').item()\n",
    "    \n",
    "    # Assuming selected_region is a polygon and we're accessing its centroid    \n",
    "    centroid = selected_region.centroid\n",
    "\n",
    "    # Now use centroid[0] and centroid[1] as the longitude and latitude\n",
    "    ax_main.text(centroid[0], centroid[1], f'Mean: {region_mean:.2f} \\n ± {regional_std_dev_models:.2f}',\n",
    "                 fontsize=38, ha='center', va='bottom', transform=ccrs.PlateCarree(),\n",
    "                 bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.5))\n",
    "    \n",
    "    # Add colorbar and legend\n",
    "    cbar = fig.colorbar(img, ax=ax_main, orientation='horizontal', fraction=0.046, pad=0.04, extend='both')\n",
    "    cbar.set_label(\"$\\Delta$ Blue-Green Water Share\", fontsize=24, weight='bold', labelpad=15) \n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    \n",
    "    std_dev_handle = mlines.Line2D([], [], color='grey', marker='.', linestyle='None', markersize=30, \n",
    "                                   label='Low Model Agreement')\n",
    "  \n",
    "    ax_main.legend(handles=[std_dev_handle], loc='lower left', fontsize=24)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        region_names = region_name.replace(\"/\", \"_\")\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', period, 'time', 'mean', 'regional_change_maps')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_{variable}_region_change_zoom_{region_names}.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    else:\n",
    "        filepath = 'Figure not saved. Add save_fig=True to save the figure.'\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5169c94-c958-42ed-9df2-f6c9666105de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change[period]['BCC-CSM2-MR'].names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a0c91-b560-46c9-9b40-6a7cd655cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    " sign_change = xr.apply_ufunc(np.sign, models_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb12e5e-cd42-4f08-b877-b76249dd45d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c9d10-7557-486e-9a8e-694039b24857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece33bc-3de8-41d9-8ddd-d7a1beffc164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433b1bc-3d44-47af-813a-55fca7e4e21b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4d2c8-8dd2-4f5e-8020-e23a6b7646bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c44a6d-0461-4649-b9d3-76ff856a7561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29522940-c74c-409e-aa47-1172cc42415c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_region_change_zoom_with_uncertainty(ds_dict_change[period], ds_dict_regions_change[period], 'bgws', 'Mediterranean', period, save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32307213-5a09-4441-b570-05f3b4f2e41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ea3c1-6869-4872-b522-c63ae9592e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period = 'historical-ssp370'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bada862-5631-4cec-ab68-bff9b86f8343",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for names in ds_dict_regions_change[period]['BCC-CSM2-MR'].names.values:\n",
    "    # Skip the iteration if the name is 'land'\n",
    "    if names == 'land':\n",
    "        continue\n",
    "    plot_region_change_zoom_with_uncertainty(ds_dict_change[period], ds_dict_regions_change[period], 'bgws', names, period, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd9b6e-0a64-4bb9-8fc3-07225daa8273",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot Global BGWS Change with Subdivisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1997ac-f426-4fa4-8bdb-827b2e66b1c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "def plot_subdivisions_global(ds_current, ds_change, region, variable, save_fig=False):\n",
    "    \"\"\"\n",
    "    Function to plot subdivisions based on current and change datasets for a specific variable and region.\n",
    "    Each subdivision is represented by a different color on the map.\n",
    "    \"\"\"\n",
    "    # Select the region and variable\n",
    "    ds_current_region = ds_current.isel(region=region)[variable]\n",
    "    ds_change_region = ds_change.isel(region=region)[variable]\n",
    "    \n",
    "    # Create masks for the current bgws values\n",
    "    mask_bgws_positive = ds_current_region > 0\n",
    "    mask_bgws_negative = ds_current_region < 0\n",
    "\n",
    "    # Create masks for the change in bgws values\n",
    "    mask_change_positive = ds_change_region > 0\n",
    "    mask_change_close_0 = (ds_change_region >= -1) & (ds_change_region <= 1)\n",
    "    mask_change_negative = ds_change_region < 0\n",
    "\n",
    "    # Define subdivisions\n",
    "    subdivisions = {\n",
    "        '$-$ BGWS & $-$ $\\Delta$BGWS': (ds_current_region.where(mask_bgws_negative & mask_change_negative), ds_change_region.where(mask_bgws_negative & mask_change_negative)),\n",
    "        '+ BGWS & $-$ $\\Delta$BGWS': (ds_current_region.where(mask_bgws_positive & mask_change_negative), ds_change_region.where(mask_bgws_positive & mask_change_negative)),\n",
    "        '$\\Delta$BGWS close to 0': ds_current_region.where(mask_change_close_0),\n",
    "        '$-$ BGWS & + $\\Delta$BGWS': (ds_current_region.where(mask_bgws_negative & mask_change_positive), ds_change_region.where(mask_bgws_negative & mask_change_positive)),\n",
    "        '+ BGWS & + $\\Delta$BGWS': (ds_current_region.where(mask_bgws_positive & mask_change_positive), ds_change_region.where(mask_bgws_positive & mask_change_positive))\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Color map dictionary for each subdivision\n",
    "    deep_blue = (20/255, 110/255, 180/255)  \n",
    "    deep_green = (14/255, 119/255, 14/255) \n",
    "    colors = [deep_green, 'darkgoldenrod','white', 'blueviolet', deep_blue]  # Adjust colors as necessary\n",
    "\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    # Get total n for percentage per subdivision\n",
    "    total_cells = (np.isfinite(ds_current_region)).sum().item() \n",
    "\n",
    "    legend_labels = []\n",
    "    # Create and apply custom single-color colormaps\n",
    "    for (name, subdivision), color in zip(subdivisions.items(), colors):\n",
    "        colmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [color, color], N=256)\n",
    "        subdivision.plot(ax=ax, add_colorbar=False, cmap=colmap, transform=ccrs.PlateCarree(), alpha=0.5, add_labels=False)\n",
    "        count = np.isfinite(subdivision).sum().item()\n",
    "        percentage = (count / total_cells) * 100 if total_cells > 0 else 0\n",
    "        legend_labels.append(f\"{name} ({percentage:.2f}%)\")\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax.coastlines()\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    \n",
    "    # Add legend\n",
    "    legend_handles = [mlines.Line2D([], [], color=color, marker='s', linestyle='None', markersize=15, label=label) \n",
    "                      for color, label in zip(colors, legend_labels)]\n",
    "    ax.legend(handles=legend_handles, loc='lower left', fontsize=24)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Save the figure if required\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', 'historical-ssp370', 'time', 'mean', 'change_map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_change_global_subdivisions_map.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "        return filepath\n",
    "    else:\n",
    "        return 'Figure not saved. If you want to save the figure, add save_fig=True to the function call.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42590e00-92b6-4a9d-b0a3-22e604db1010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "def plot_subdivisions_global(ds_current, ds_change, region, variable, save_fig=False):\n",
    "    \"\"\"\n",
    "    Function to plot subdivisions based on current and change datasets for a specific variable and region.\n",
    "    Each subdivision is represented by a different color on the map.\n",
    "    \"\"\"\n",
    "    # Select the region and variable\n",
    "    ds_current_region = ds_current.isel(region=region)[variable]\n",
    "    ds_change_region = ds_change.isel(region=region)[variable]\n",
    "    \n",
    "    if 'member_id' in ds_current_region.coords:\n",
    "        ds_current_region = ds_current_region.drop('member_id')\n",
    "    if 'member_id' in ds_change_region.coords:\n",
    "        ds_change_region = ds_change_region.drop('member_id')\n",
    "    \n",
    "    # Create masks for the current bgws values\n",
    "    mask_bgws_positive = ds_current_region > 0\n",
    "    mask_bgws_negative = ds_current_region < 0\n",
    "\n",
    "    # Create masks for the change in bgws values\n",
    "    mask_change_positive = ds_change_region > 0\n",
    "    mask_change_negative = ds_change_region < 0\n",
    "\n",
    "    # Define subdivisions\n",
    "    subdivisions = {\n",
    "        '$-$ BGWS & $-$ $\\Delta$BGWS': (ds_current_region.where(mask_bgws_negative & mask_change_negative), ds_change_region.where(mask_bgws_negative & mask_change_negative)),\n",
    "        '+ BGWS & $-$ $\\Delta$BGWS': (ds_current_region.where(mask_bgws_positive & mask_change_negative), ds_change_region.where(mask_bgws_positive & mask_change_negative)),\n",
    "        '$-$ BGWS & + $\\Delta$BGWS': (ds_current_region.where(mask_bgws_negative & mask_change_positive), ds_change_region.where(mask_bgws_negative & mask_change_positive)),\n",
    "        '+ BGWS & + $\\Delta$BGWS': (ds_current_region.where(mask_bgws_positive & mask_change_positive), ds_change_region.where(mask_bgws_positive & mask_change_positive))\n",
    "    }\n",
    "\n",
    "    # Color map dictionary for each subdivision\n",
    "    deep_blue = (20/255, 110/255, 180/255)  \n",
    "    deep_green = (14/255, 119/255, 14/255) \n",
    "    colors = [deep_green, 'darkgoldenrod','blueviolet', deep_blue]  # Adjust colors as necessary\n",
    "\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    # Get total n for percentage per subdivision\n",
    "    total_cells = (np.isfinite(ds_current_region)).sum().item()\n",
    "    \n",
    "    # Create a rectangle box behind text and colorbar\n",
    "    rect = patches.Rectangle(\n",
    "        (0.127, 0.18), # x , y\n",
    "        0.19, # box_width\n",
    "        0.25 , # box_height\n",
    "        linewidth=1,\n",
    "        edgecolor='gray',\n",
    "        facecolor='white',\n",
    "        transform=fig.transFigure,\n",
    "        zorder=0  # Ensure the box is behind the text and colorbar\n",
    "    )\n",
    "    fig.patches.append(rect)\n",
    "\n",
    "    # Create and apply custom single-color colormaps\n",
    "    for i, ((name, (subdivision, change)), color) in enumerate(zip(subdivisions.items(), colors)):\n",
    "        # Define normalization ranges based on change direction\n",
    "        if \" + \" in name:\n",
    "            norm = plt.Normalize(vmin=0, vmax=10)\n",
    "            # Create a custom colormap with varying alpha\n",
    "            colmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", ['white', color], N=256)\n",
    "        else:\n",
    "            norm = plt.Normalize(vmin=-10, vmax=0)\n",
    "            colmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [color, 'white'], N=256)\n",
    "\n",
    "        # Apply colormap based on the change values\n",
    "        pcm = change.plot(ax=ax, add_colorbar=False, cmap=colmap, norm=norm, transform=ccrs.PlateCarree(), alpha=0.8, add_labels=False)\n",
    "        \n",
    "        # Add colorbar for each subdivision, stacked horizontally\n",
    "        cbar_ax = fig.add_axes([0.26, 0.22 + i * 0.06, 0.05, 0.02], zorder=2)  # [left, bottom, width, height]\n",
    "        \n",
    "        if \" + \" in name:\n",
    "            cbar = fig.colorbar(pcm, cax=cbar_ax, orientation='horizontal', extend='max')\n",
    "            cbar.set_ticks([0])\n",
    "            cbar.ax.set_xticks([0, 10])\n",
    "            cbar.ax.set_xticklabels(['0', '10'])\n",
    "        else:\n",
    "            cbar = fig.colorbar(pcm, cax=cbar_ax, orientation='horizontal', extend='min')\n",
    "            cbar.set_ticks([0])\n",
    "            cbar.ax.set_xticks([-10, 0])\n",
    "            cbar.ax.set_xticklabels(['-10', '0'])\n",
    "        \n",
    "        # Add the label to the left of the colorbar\n",
    "        fig.text(0.13, 0.226 + i * 0.06, name, va='center', ha='left', fontsize=24, zorder=2)\n",
    "        cbar.set_label('$\\Delta$BGWS', fontsize=16)\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "        \n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax.coastlines()\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Save the figure if required\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', 'historical-ssp370', 'time', 'mean', 'change_map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_change_global_subdivisions_map.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "        return filepath\n",
    "    else:\n",
    "        return 'Figure not saved. If you want to save the figure, add save_fig=True to the function call.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7876f-97d9-41d7-ae61-85bf97b2d28c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_subdivisions_global(ds_current, ds_change, region, variable, save_fig=False):\n",
    "    \"\"\"\n",
    "    Function to plot subdivisions based on current and change datasets for a specific variable and region.\n",
    "    Each subdivision is represented by a different color on the map.\n",
    "    \"\"\"\n",
    "    # Select the region and variable\n",
    "    ds_current_region = ds_current.isel(region=region)[variable]\n",
    "    ds_change_region = ds_change.isel(region=region)[variable]\n",
    "    \n",
    "    if 'member_id' in ds_current_region.coords:\n",
    "        ds_current_region = ds_current_region.drop('member_id')\n",
    "    if 'member_id' in ds_change_region.coords:\n",
    "        ds_change_region = ds_change_region.drop('member_id')\n",
    "    \n",
    "    # Create masks for the current bgws values\n",
    "    mask_bgws_positive = ds_current_region > 0\n",
    "    mask_bgws_negative = ds_current_region < 0\n",
    "\n",
    "    # Define subdivisions\n",
    "    subdivisions = {\n",
    "        '+ BGWS': (ds_current_region.where(mask_bgws_positive), ds_change_region.where(mask_bgws_positive)),\n",
    "        '$-$ BGWS': (ds_current_region.where(mask_bgws_negative), ds_change_region.where(mask_bgws_negative))\n",
    "    }\n",
    "\n",
    "    # Color map dictionary\n",
    "    deep_blue = (20/255, 110/255, 180/255)  \n",
    "    deep_green = (14/255, 119/255, 14/255) \n",
    "    darkgoldenrod = 'darkgoldenrod'\n",
    "    blueviolet = 'blueviolet'\n",
    "\n",
    "    colors = {\n",
    "        '+ BGWS': [darkgoldenrod, 'white', deep_blue],\n",
    "        '$-$ BGWS': [deep_green, 'white', blueviolet]\n",
    "    }\n",
    "\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    # Create a rectangle box behind text and colorbar\n",
    "    rect = patches.Rectangle(\n",
    "        (0.127, 0.18),  # x, y\n",
    "        0.18,  # box_width\n",
    "        0.15,  # box_height\n",
    "        linewidth=1,\n",
    "        edgecolor='gray',\n",
    "        facecolor='white',\n",
    "        transform=fig.transFigure,\n",
    "        zorder=0  # Ensure the box is behind the text and colorbar\n",
    "    )\n",
    "    fig.patches.append(rect)\n",
    "\n",
    "    # Create and apply custom single-color colormaps\n",
    "    for i, (name, (subdivision, change)) in enumerate(subdivisions.items()):\n",
    "        norm = plt.Normalize(vmin=-10, vmax=10)\n",
    "        colmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", colors[name], N=256)\n",
    "\n",
    "        # Apply colormap based on the change values\n",
    "        pcm = change.plot(ax=ax, add_colorbar=False, cmap=colmap, norm=norm, transform=ccrs.PlateCarree(), alpha=0.8, add_labels=False)\n",
    "        \n",
    "        # Add colorbar for each subdivision, stacked horizontally\n",
    "        cbar_ax = fig.add_axes([0.2, 0.22 + i * 0.08, 0.1, 0.02], zorder=2)  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(pcm, cax=cbar_ax, orientation='horizontal', extend='both')\n",
    "        cbar.set_ticks([-10, 0, 10])\n",
    "        cbar.ax.set_xticklabels(['-10', '0', '10'])\n",
    "        \n",
    "        # Add the label to the left of the colorbar\n",
    "        fig.text(0.13, 0.226 + i * 0.08, name, va='center', ha='left', fontsize=24, zorder=2)\n",
    "        cbar.set_label('$\\Delta$BGWS', fontsize=16)\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax.coastlines()\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Save the figure if required\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', 'historical-ssp370', 'time', 'mean', 'change_map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_change_global_subdivisions_map.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "        return filepath\n",
    "    else:\n",
    "        return 'Figure not saved. If you want to save the figure, add save_fig=True to the function call.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ecc3d-b250-4c84-90b1-d7307914b83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "ds_current = ds_dict_regions['historical']['Ensemble mean']\n",
    "ds_change = ds_dict_regions_change['historical-ssp370']['Ensemble mean']\n",
    "#region = 'Mediterranean'  # Mediterranean region index\n",
    "#region = -1\n",
    "region = ds_current.isel(region=19).names.values.item()\n",
    "variable = 'bgws'  # The variable to be plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd37b06-1c18-4a12-ab94-3b3e34555ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subdivisions_global(ds_current, ds_change, -1, variable, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725b84a-190f-453d-9281-a70b15fbb51a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Global BGWS Change with Regional Subdivisions and Regional Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f348e6a-0ef0-44f7-a0fc-d71ccaa42432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regionmask\n",
    "\n",
    "def apply_region_mask(ds_dict, with_global=False, lat_expansion=0, lon_expansion=0):\n",
    "    \"\"\"\n",
    "    Applies the AR6 land region mask to datasets in the provided dictionary, adds a region dimension,\n",
    "    and optionally includes a 'Global' aggregation. Allows for the expansion of region boundaries.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets.\n",
    "        with_global (bool): If True, includes a 'Global' region with aggregated data.\n",
    "        lat_expansion (float): Degrees to expand in the latitude direction.\n",
    "        lon_expansion (float): Degrees to expand in the longitude direction.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new dictionary where keys are the same as in the input dictionary,\n",
    "              and each value is an xarray Dataset with a region dimension added to each variable,\n",
    "              and optionally includes a 'Global' region.\n",
    "    \"\"\"\n",
    "\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    \n",
    "    # Expand the regions if expansion values are provided\n",
    "    if lat_expansion != 0 or lon_expansion != 0:\n",
    "        expanded_regions = [\n",
    "            expand_region_boundaries(region, lat_expansion, lon_expansion) for region in land_regions\n",
    "        ]\n",
    "        land_regions = regionmask.Regions(expanded_regions)\n",
    "    \n",
    "    if with_global:\n",
    "        global_mask = regionmask.defined_regions.natural_earth_v5_0_0.land_110\n",
    "    \n",
    "    ds_masked_dict = {}\n",
    "\n",
    "    for ds_name, ds in ds_dict.items():\n",
    "        ds_masked = xr.Dataset()  # Initiate an empty Dataset for the masked data\n",
    "        \n",
    "        for var in ds:\n",
    "            # Get the binary mask\n",
    "            mask = land_regions.mask_3D(ds[var])\n",
    "            \n",
    "            var_attrs = ds[var].attrs\n",
    "\n",
    "            # Multiply the original data with the mask to get the masked data\n",
    "            masked_var = ds[var] * mask\n",
    "\n",
    "            # Replace 0s with NaNs, if desired\n",
    "            masked_var = masked_var.where(masked_var != 0)\n",
    "\n",
    "            if with_global:\n",
    "                # Convert the global mask to 3D to match the regional mask dimensions\n",
    "                glob_mask = global_mask.mask_3D(ds[var])\n",
    "                \n",
    "                global_masked_var = ds[var] * glob_mask\n",
    "                \n",
    "                # Replace 0s with NaNs, if desired\n",
    "                global_masked_var = global_masked_var.where(global_masked_var != 0)\n",
    "\n",
    "                # Combine masked data\n",
    "                masked_var = xr.concat([masked_var, global_masked_var], dim='region')\n",
    "                \n",
    "            # Add the masked variable to the output Dataset\n",
    "            ds_masked[var] = masked_var\n",
    "\n",
    "            ds_masked[var].attrs = var_attrs\n",
    "\n",
    "        # Copy dataset attributes\n",
    "        ds_masked.attrs.update(ds.attrs)\n",
    "        \n",
    "        correct_region_numbers = np.arange(0, ds_masked.dims['region'])\n",
    "\n",
    "        ds_masked = ds_masked.assign_coords(region=correct_region_numbers)\n",
    "\n",
    "        # Add the modified dataset to the dictionary\n",
    "        ds_masked_dict[ds_name] = ds_masked\n",
    "\n",
    "    return ds_masked_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817b20a-7f4d-4928-80c4-97263e1b0924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subdivide_region_and_compute_mean(ds_dict, with_global=True, spatial_mean=True, lat_expansion=0, lon_expansion=0):\n",
    "    \n",
    "    ds_dict_regions = {}\n",
    "    \n",
    "    for scenario_name, scenario_dict in ds_dict.items():\n",
    "        ds_dict_regions[scenario_name] = apply_region_mask(scenario_dict, with_global=True, lat_expansion=0, lon_expansion=0)\n",
    "        if spatial_mean:\n",
    "            ds_dict_regions[scenario_name] = calculate_spatial_mean( ds_dict_regions[scenario_name])\n",
    "   \n",
    "    return ds_dict_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d1dd9-d9f1-40fc-8cb4-d46441452887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions = subdivide_region_and_compute_mean(ds_dict, with_global=False, spatial_mean=False, lat_expansion=10, lon_expansion=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24833865-079c-4281-afbd-f338c1e08d15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change = lap.compute_change_dict(ds_dict_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8c186-16f7-46ae-a960-380d311ea911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change['historical-ssp370'], 'mean')\n",
    "ds_dict_regions_change['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change['historical-ssp370'], 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a60d81-7e6b-466d-8a05-6ed85833c8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict['historical'] = lap.compute_ensemble(ds_dict['historical'], 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7b677-c0e7-48c0-b1e5-52bcc5af8b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_change['historical-ssp370'] = lap.compute_ensemble(ds_dict_change['historical-ssp370'], 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ead52-a7c0-4873-b49e-fa271f5391bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_change['historical-ssp370']['Ensemble mean'].bgws.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbf594-64f0-42ab-bd39-d8729d671244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shapely.geometry\n",
    "\n",
    "def expand_region_boundaries(region, lat_expansion, lon_expansion):\n",
    "    \"\"\"\n",
    "    Expands the boundaries of a given region by specified degrees in all directions.\n",
    "\n",
    "    Args:\n",
    "        region (regionmask.Region): The region to expand.\n",
    "        lat_expansion (float): Degrees to expand in the latitude direction.\n",
    "        lon_expansion (float): Degrees to expand in the longitude direction.\n",
    "\n",
    "    Returns:\n",
    "        shapely.geometry.Polygon: A new polygon with expanded boundaries.\n",
    "    \"\"\"\n",
    "    if hasattr(region, 'polygons'):\n",
    "        polygons = region.polygons\n",
    "    elif hasattr(region, 'polygon'):\n",
    "        polygons = [region.polygon]\n",
    "    else:\n",
    "        raise ValueError(\"Region does not have a 'polygons' or 'polygon' attribute.\")\n",
    "\n",
    "    expanded_polygons = []\n",
    "    for polygon in polygons:\n",
    "        minx, miny, maxx, maxy = polygon.bounds\n",
    "        minx -= lon_expansion\n",
    "        maxx += lon_expansion\n",
    "        miny -= lat_expansion\n",
    "        maxy += lat_expansion\n",
    "        expanded_polygon = shapely.geometry.box(minx, miny, maxx, maxy)\n",
    "        expanded_polygons.append(expanded_polygon)\n",
    "\n",
    "    return expanded_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27bf45-98b5-43e2-935b-2de0a1d61ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import regionmask\n",
    "\n",
    "def plot_subdivisions_global_with_regions(ds_current_full, ds_change_full, variable, save_fig=False, lat_expansion=0, lon_expansion=0):\n",
    "    \"\"\"\n",
    "    Function to plot subdivisions based on current and change datasets for a specific variable globally.\n",
    "    Each subdivision is represented by a different color on the map.\n",
    "    \"\"\"\n",
    "    # Select the variable from the datasets\n",
    "    ds_current_var = ds_current_full[variable]\n",
    "    ds_change_var = ds_change_full[variable]\n",
    "\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    # Define color map dictionary for subdivisions\n",
    "    colors = ['purple', 'blue', 'green', 'yellow']  # Adjust colors as necessary\n",
    "    subdivisions = {\n",
    "        '+ BGWS & $-$ $\\Delta$BGWS': (ds_current_var > 0) & (ds_change_var < 0),\n",
    "        '+ BGWS & + $\\Delta$BGWS': (ds_current_var > 0) & (ds_change_var > 0),\n",
    "        '$-$ BGWS & $-$ $\\Delta$BGWS': (ds_current_var < 0) & (ds_change_var < 0),\n",
    "        '$-$ BGWS & + $\\Delta$BGWS': (ds_current_var < 0) & (ds_change_var > 0)\n",
    "    }\n",
    "\n",
    "    # Plot each subdivision\n",
    "    for (name, mask), color in zip(subdivisions.items(), colors):\n",
    "        colmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [color, color], N=256)\n",
    "        ds_current_var.where(mask).plot.pcolormesh(ax=ax, add_colorbar=False, cmap=colmap, transform=ccrs.PlateCarree(), alpha=0.5, add_labels=False)\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax.coastlines()\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "\n",
    "    # Get region bounds using regionmask with expansion\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "\n",
    "    if lat_expansion != 0 or lon_expansion != 0:\n",
    "        expanded_polygons = []\n",
    "        for region in land_regions:\n",
    "            expanded_polygons.extend(expand_region_boundaries(region, lat_expansion, lon_expansion))\n",
    "    else:\n",
    "        expanded_polygons = [region.polygon for region in land_regions]\n",
    "\n",
    "    # Overlay the polygons\n",
    "    for polygon in expanded_polygons:\n",
    "        feature = ShapelyFeature([polygon], ccrs.PlateCarree(), edgecolor='gray', facecolor='none', linewidth=2, alpha=0.7)\n",
    "        ax.add_feature(feature, zorder=1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Save the figure if required\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', 'historical-ssp370', 'time', 'mean', 'change_map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_change_global_subdivisions_map.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "        return filepath\n",
    "    else:\n",
    "        return 'Figure not saved. If you want to save the figure, add save_fig=True to the function call.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b9480-8521-406e-9062-1eb5a401ae9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "ds_current_full = ds_dict['historical']['Ensemble mean']\n",
    "ds_change_full = ds_dict_change['historical-ssp370']['Ensemble mean']\n",
    "\n",
    "plot_subdivisions_global_with_regions(ds_current_full, ds_change_full, 'bgws', save_fig=False, lat_expansion=10, lon_expansion=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e272a4-3ec8-43ed-b028-b50c6b66885c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot BGWS Change per Regions with Subdivisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e259aa0-d087-405a-ba42-9cbe47b7477d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_subdivisions(ds_current, ds_change, region_name, variable, save_fig=False):\n",
    "    \"\"\"\n",
    "    Function to plot subdivisions based on current and change datasets for a specific variable and region,\n",
    "    with a zoomed-in view and display of uncertainty for the selected region.\n",
    "    \"\"\"\n",
    "    # Load region definitions and select the specific region\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    selected_region = land_regions[region_name]\n",
    "\n",
    "    # Select the region and variable\n",
    "    ds_current_region = ds_current.sel(region=selected_region.number)[variable]\n",
    "    ds_change_region = ds_change.sel(region=selected_region.number)[variable]\n",
    "\n",
    "    #total_cells = ds_current_region.size \n",
    "\n",
    "    # Now, sum this mask to get the count of non-NaN entries\n",
    "    total_cells = (np.isfinite(ds_current_region)).sum().item()  # Use `.item()` to extract the number if it's a zero-dimensional array\n",
    "\n",
    "\n",
    "    # Create masks for the current bgws values\n",
    "    mask_bgws_positive = ds_current_region > 0\n",
    "    mask_bgws_negative = ds_current_region < 0\n",
    "\n",
    "    # Create masks for the change in bgws values\n",
    "    mask_change_positive = ds_change_region > 0\n",
    "    mask_change_negative = ds_change_region < 0\n",
    "\n",
    "    # Define subdivisions\n",
    "    subdivisions = {\n",
    "        '+ BGWS & $-$ $\\Delta$BGWS': ds_current_region.where(mask_bgws_positive & mask_change_negative),\n",
    "        '+ BGWS & + $\\Delta$BGWS': ds_current_region.where(mask_bgws_positive & mask_change_positive),\n",
    "        '$-$ BGWS & $-$ $\\Delta$BGWS': ds_current_region.where(mask_bgws_negative & mask_change_negative),\n",
    "        '$-$ BGWS & + $\\Delta$BGWS': ds_current_region.where(mask_bgws_negative & mask_change_positive)\n",
    "    }\n",
    "\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    \n",
    "    if hasattr(selected_region, 'polygons'):  # For regions with multiple polygons\n",
    "        all_polygons = selected_region.polygons\n",
    "    else:  # For regions defined by a single polygon\n",
    "        all_polygons = [selected_region.polygon]\n",
    "    \n",
    "    # Calculating the combined bounds of all polygons to adjust zoom\n",
    "    minx, miny, maxx, maxy = np.inf, np.inf, -np.inf, -np.inf\n",
    "    \n",
    "    for geom in all_polygons:\n",
    "        if isinstance(geom, Polygon):\n",
    "            # Directly calculate bounds for a Polygon\n",
    "            p_minx, p_miny, p_maxx, p_maxy = geom.bounds\n",
    "            minx, miny = min(minx, p_minx), min(miny, p_miny)\n",
    "            maxx, maxy = max(maxx, p_maxx), max(maxy, p_maxy)\n",
    "            ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "            #img = ensemble_ds.plot(ax=ax_main, vmin=-10, vmax=10, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "            ax_main.add_geometries([geom], crs=ccrs.PlateCarree(), edgecolor='black', facecolor='none')\n",
    "        elif isinstance(geom, MultiPolygon):\n",
    "            # Iterate over each polygon in the MultiPolygon to calculate bounds\n",
    "            ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=180))\n",
    "            #img = ensemble_ds.plot(ax=ax_main, vmin=-10, vmax=10, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "                \n",
    "            minx, maxx = -np.inf, np.inf\n",
    "            for polygon in geom:\n",
    "                p_minx, p_miny, p_maxx, p_maxy = polygon.bounds\n",
    "                minx, miny = max(minx, p_minx), min(miny, p_miny)\n",
    "                maxx, maxy = min(maxx, p_maxx), max(maxy, p_maxy)\n",
    "                ax_main.add_geometries([polygon], crs=ccrs.PlateCarree(), edgecolor='black', facecolor='none')\n",
    "\n",
    "    # Adjusting map extent with a small buffer\n",
    "    buffer = 2  # Adjust the buffer size as needed\n",
    "    \n",
    "    if maxx < minx:\n",
    "        maxx_ = 360 + maxx\n",
    "    else:\n",
    "        maxx_ = maxx\n",
    "    \n",
    "    if maxx_ == 180:\n",
    "        ax_main.set_extent([minx - buffer, min((maxx_ + buffer), 180), miny - buffer , maxy + buffer], crs=ccrs.PlateCarree())\n",
    "    else:\n",
    "        ax_main.set_extent([minx - buffer, maxx_ + buffer, miny - buffer , maxy + buffer], crs=ccrs.PlateCarree())\n",
    "         \n",
    "    legend_labels = []\n",
    "        \n",
    "    # Plot each subdivision\n",
    "    colors = ['purple', 'blue', 'green', 'yellow']\n",
    "    for (name, subdivision), color in zip(subdivisions.items(), colors):\n",
    "        colmap = mcolors.LinearSegmentedColormap.from_list(\"custom\", [color, color], N=256)\n",
    "        subdivision.plot(ax=ax_main, add_colorbar=False, cmap=colmap, transform=ccrs.PlateCarree(), alpha=0.5, add_labels=False)\n",
    "        count = np.isfinite(subdivision).sum().item()\n",
    "        percentage = (count / total_cells) * 100 if total_cells > 0 else 0\n",
    "        legend_labels.append(f\"{name} ({percentage:.2f}%) ({count}/{total_cells})\")\n",
    "\n",
    "    # Add coastlines and gridlines for context\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 24}\n",
    "    gridlines.ylabel_style = {'size': 24}\n",
    "    \n",
    "    # Add legend\n",
    "    legend_handles = [mlines.Line2D([], [], color=color, marker='s', linestyle='None', markersize=15, label=label) \n",
    "                      for color, label in zip(colors, legend_labels)]\n",
    "    ax_main.legend(handles=legend_handles, loc='lower right', fontsize=24)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Save the figure if required\n",
    "    if save_fig:\n",
    "        region_name = region_name.replace(\"/\", \"_\")\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', 'historical-ssp370', 'time', 'mean', 'subdivision_change_map')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_mean_change_subdivison_map_{region_name}.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "        return filepath\n",
    "    else:\n",
    "        return 'Figure not saved. If you want to save the figure, add save_fig=True to the function call.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ce0d7-669e-48b5-a698-4ac5996191cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for region in ds_current.names.values:\n",
    "    plot_subdivisions(ds_current, ds_change, region, variable, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa62367-98f0-4f20-975d-9463ca6f4a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_with_subdivisions(ds_current, ds_change, variable='bgws'):\n",
    "    # Masks for current dataset\n",
    "    mask_bgws_positive = ds_current[variable] > 0\n",
    "    mask_bgws_negative = ds_current[variable] < 0\n",
    "\n",
    "    # Masks for change dataset\n",
    "    mask_change_positive = ds_change[variable] > 0\n",
    "    mask_change_negative = ds_change[variable] < 0\n",
    "\n",
    "    # Create the subdivision masks\n",
    "    subdivisions_masks = xr.DataArray(\n",
    "        np.array([\n",
    "            mask_bgws_positive & mask_change_negative,\n",
    "            mask_bgws_positive & mask_change_positive,\n",
    "            mask_bgws_negative & mask_change_negative,\n",
    "            mask_bgws_negative & mask_change_positive\n",
    "        ]),\n",
    "        dims=['subdivision', 'lat', 'lon', 'region'],\n",
    "        coords={\n",
    "            'subdivision': [0, 1, 2, 3],\n",
    "            'lat': ds_current.lat,\n",
    "            'lon': ds_current.lon,\n",
    "            'region': ds_current.region\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Expand datasets by broadcasting with subdivision masks\n",
    "    def expand_dataset(ds):\n",
    "        expanded_vars = {}\n",
    "        for name, var in ds.data_vars.items():\n",
    "            # Use the .where() method to mask the data based on the subdivision mask\n",
    "            expanded_var = var.expand_dims({'subdivision': subdivisions_masks['subdivision'].sizes['subdivision']}).where(subdivisions_masks)\n",
    "            expanded_vars[name] = expanded_var\n",
    "        \n",
    "        # Create new dataset with expanded variables\n",
    "        expanded_ds = xr.Dataset(expanded_vars, coords={**ds.coords, 'subdivision': subdivisions_masks['subdivision']})\n",
    "        return expanded_ds\n",
    "\n",
    "    ds_change_expanded = expand_dataset(ds_change)\n",
    "\n",
    "    return ds_change_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc1f07-ab9e-4b7d-8bc2-bc4de4f297ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usage\n",
    "ds_change_subdivisions = expand_with_subdivisions(ds_current, ds_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ce7d7-a189-48f4-9901-9d8e2f5e6dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
