{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7716ffb9-a564-44c7-87d4-2d4caeecdb1c",
   "metadata": {},
   "source": [
    "# CMIP6 Statistics and Plots\n",
    "\n",
    "**Following steps are included in this script:**\n",
    "\n",
    "1. Load netCDF files\n",
    "2. Compute statistics\n",
    "3. Plot statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854af429-43a1-489d-8513-dca8c1466663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Packages ==========\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import dask\n",
    "from matplotlib import rcParams\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from cftime import DatetimeNoLeap\n",
    "import glob\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import colors\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rcParams[\"mathtext.default\"] = 'regular'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5daa16-4811-4773-b98d-6b69626ff6cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809879e-89b9-40e4-b7f4-325f06720777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_statistic_single(ds, statistic, dimension, yearly_mean=False):\n",
    "    if dimension == \"time\":\n",
    "        stat_ds = getattr(ds, statistic)(\"time\", keep_attrs=True, skipna=True)\n",
    "        stat_ds.attrs['period'] = [str(ds.time.dt.year[0].values), str(ds.time.dt.year[-1].values)]\n",
    "        \n",
    "    if dimension == \"space\":\n",
    "        # Assign the period attribute before grouping by year\n",
    "        ds.attrs['period'] = [str(ds.time.dt.year[0].values), str(ds.time.dt.year[-1].values)]\n",
    "        \n",
    "        if yearly_mean:\n",
    "            ds = ds.groupby('time.year').mean('time', keep_attrs=True, skipna=True)\n",
    "            ds.attrs['mean'] = 'yearly mean'\n",
    "            \n",
    "        #get the weights, apply on data, and compute statistic\n",
    "        weights = np.cos(np.deg2rad(ds.lat))\n",
    "        weights.name = \"weights\"\n",
    "        ds_weighted = ds.weighted(weights)\n",
    "        stat_ds = getattr(ds_weighted, statistic)((\"lon\", \"lat\"), keep_attrs=True, skipna=True)\n",
    "    \n",
    "    stat_ds.attrs['statistic'] = statistic\n",
    "    stat_ds.attrs['statistic_dimension'] = dimension\n",
    "\n",
    "    return stat_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909a5bf7-659f-49eb-b17b-2ea90874c347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_period(ds_dict, start_year=None, end_year=None):\n",
    "    '''\n",
    "    Helper function to select periods.\n",
    "    \n",
    "    Parameters:\n",
    "    ds_dict (dict): Dictionary with xarray datasets.\n",
    "    start_year (int): The start year of the period.\n",
    "    end_year (int): The end year of the period.\n",
    "    \"\"\"\n",
    "    '''\n",
    "    start_year = DatetimeNoLeap(start_year, 1, 16, 12, 0, 0, 0,has_year_zero=True) # 16th of January of start year\n",
    "    end_year = DatetimeNoLeap(end_year, 12, 16, 12, 0, 0, 0, has_year_zero=True) # 16th of December of end year\n",
    "    ds_dict = {k: v.sel(time=slice(start_year, end_year)) for k, v in ds_dict.items()}\n",
    "    \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadad33e-375e-4f6f-94b1-918dce7e2f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_statistic(ds_dict, statistic, dimension, start_year=None, end_year=None, yearly_mean=True):\n",
    "    \"\"\"\n",
    "    Computes the specified statistic for each dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        statistic (str): The statistic to compute, which can be one of 'mean', 'std', 'min', 'var', or 'median'.\n",
    "        dimension (str): The dimension to compute over, which can be 'time' or 'space'.\n",
    "        start_year (str, optional): The start year of the period to compute the statistic over.\n",
    "        end_year (str, optional): The end year of the period to compute the statistic over.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with computed statistic for each dataset.\n",
    "    \"\"\"\n",
    "    # Check the validity of input arguments\n",
    "    if not isinstance(ds_dict, dict):\n",
    "        raise TypeError(\"ds_dict must be a dictionary of xarray datasets.\")\n",
    "    if not all(isinstance(ds, xr.Dataset) for ds in ds_dict.values()):\n",
    "        raise TypeError(\"All values in ds_dict must be xarray datasets.\")\n",
    "    if statistic not in [\"mean\", \"std\", \"min\", \"max\", \"var\", \"median\"]:\n",
    "        raise ValueError(f\"Invalid statistic '{statistic}' specified.\")\n",
    "    if dimension not in [\"time\", \"space\"]:\n",
    "        raise ValueError(f\"Invalid dimension '{dimension}' specified.\")\n",
    "\n",
    "    # Select period\n",
    "    if start_year is not None and end_year is not None:\n",
    "        ds_dict = select_period(ds_dict, start_year=start_year, end_year=end_year)\n",
    "        \n",
    "    # Use multiprocessing to compute the statistic for each dataset in parallel\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.starmap(compute_statistic_single, [(ds, statistic, dimension, yearly_mean) for ds in ds_dict.values()])\n",
    "\n",
    "    return dict(zip(ds_dict.keys(), results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75916263-7d49-4376-862d-d869bd7bf030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_args_and_get_info(ds_dict, variable):\n",
    "    # Check the validity of input arguments\n",
    "    if not isinstance(ds_dict, dict):\n",
    "        raise TypeError(\"ds_dict must be a dictionary of xarray datasets.\")\n",
    "    if not all(isinstance(ds, xr.Dataset) for ds in ds_dict.values()):\n",
    "        raise TypeError(\"All values in ds_dict must be xarray datasets.\")\n",
    "    if not isinstance(variable, str):\n",
    "        raise TypeError('variable must be a string.')\n",
    "        \n",
    "    # Dictionary to store plot titles for each statistic\n",
    "    titles = {\"mean\": \"Mean\", \"std\": \"Standard deviation of yearly means\", \"min\": \"Minimum\", \"max\": \"Maximum\", \"median\": \"Median\", \"time\": \"Time\", \"space\": \"Space\"}\n",
    "    freq = {\"mon\": \"Monthly\"}\n",
    "   \n",
    "    # Data information\n",
    "    var_long_name = ds_dict[list(ds_dict.keys())[0]][variable].long_name\n",
    "    period = f\"{ds_dict[list(ds_dict.keys())[0]].attrs['period'][0]}-{ds_dict[list(ds_dict.keys())[0]].attrs['period'][1]}\"\n",
    "    experiment_id =  ds_dict[list(ds_dict.keys())[0]].experiment_id\n",
    "    unit = ds_dict[list(ds_dict.keys())[0]][variable].units\n",
    "    statistic_dim = ds_dict[list(ds_dict.keys())[0]].statistic_dimension\n",
    "    statistic = ds_dict[list(ds_dict.keys())[0]].attrs['statistic']\n",
    "    frequency = freq[ds_dict[list(ds_dict.keys())[0]].frequency]\n",
    "\n",
    "    return var_long_name, period, unit, statistic_dim, statistic, experiment_id, titles, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d38b3-0908-41f4-ba7f-3ba50c05504a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_line_statistic(ds_dict, variable, log_scale=False, add_regression=True, save_fig=False, file_format='png', smooth_window=1):\n",
    "    \"\"\"\n",
    "    Plots a line plot of the specified statistic of the given variable for each dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        variable (str): The name of the variable to plot.\n",
    "        log_scale (bool): If True, plot the data on a log scale. Default is False.\n",
    "        add_regression (bool): If Ture, compute regression and plot it. Default is True.\n",
    "        save_fig (bool): If True, save the figure to a file. Default is False.\n",
    "        file_format (str): The format of the saved figure. Default is 'png'.\n",
    "        smooth_window (int): Window size for rolling mean smoothing. Default is 1 (no smoothing).\n",
    "\n",
    "    Returns:\n",
    "        str: The file path where the figure was saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check arguments and get info\n",
    "    var_long_name, period, unit, statistic_dim, statistic, experiment_id, titles = check_args_and_get_info(ds_dict, variable)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(30, 15))\n",
    "        \n",
    "    # Initialize a list to store the DataArrays from each dataset\n",
    "    data_list = []\n",
    "\n",
    "    # Loop over datasets and plot the requested statistic in a single figure\n",
    "    for i, (name, ds) in enumerate(ds_dict.items()):\n",
    "        if variable not in ds:\n",
    "            print(f\"Variable '{variable}' not found in dataset '{name}', skipping.\")\n",
    "            continue\n",
    "\n",
    "        data_to_plot = ds[variable].squeeze()\n",
    "\n",
    "        # Apply log-scale\n",
    "        if log_scale:\n",
    "            data_to_plot = np.log10(data_to_plot)\n",
    "\n",
    "        # Apply smoothing\n",
    "        if smooth_window > 1:\n",
    "            data_to_plot = data_to_plot.rolling(time=smooth_window, center=True).mean()\n",
    "\n",
    "        data_list.append(data_to_plot)  # Append the transformed data to the list\n",
    "\n",
    "        # Plot the data and get the color of the line\n",
    "        #sns.lineplot(x='time', y=data_to_plot, ax=ax, label=None)\n",
    "        data_lines = data_to_plot.plot.line(x='year', ax=ax, label=None)\n",
    "        #data_lines = data_to_plot.plot.line(x='time', ax=ax, label=None)\n",
    "        data_color = data_lines[0].get_color()\n",
    "\n",
    "        if add_regression:\n",
    "\n",
    "            # Create regression model\n",
    "            #trend = data_to_plot.polyfit(dim='time', deg=1)\n",
    "            trend = data_to_plot.polyfit(dim='year', deg=1)\n",
    "\n",
    "            # Fit regression model to data and add it to plot \n",
    "            regression_line = xr.polyval(ds['year'], trend).squeeze()\n",
    "            #regression_line = xr.polyval(ds['time'], trend).squeeze()\n",
    "            #regression_line['polyfit_coefficients'].plot(x='time', ax=ax, color=data_color)\n",
    "            #regression_line['polyfit_coefficients'].plot(x='year', ax=ax, linestyle='--', color=data_color)\n",
    "            #sns.lineplot(x='time', y=regression_line['polyfit_coefficients'], ax=ax, color=data_color)\n",
    "\n",
    "            # Calculate percentage of change\n",
    "            first_value = regression_line['polyfit_coefficients'].isel(year=0).item()\n",
    "            #first_value = regression_line['polyfit_coefficients'].isel(time=0).item()\n",
    "            last_value = regression_line['polyfit_coefficients'].isel(year=-1).item()\n",
    "            #last_value = regression_line['polyfit_coefficients'].isel(time=-1).item()\n",
    "            percentage_change = ((last_value - first_value) / first_value) * 100\n",
    "\n",
    "            # Add the percentage change to the legend label\n",
    "            ax.plot([], [], color=data_color, label=f\"{name} ({percentage_change:.2f}%)\")\n",
    "\n",
    "\n",
    "    # Set the x and y axis labels\n",
    "    ax.set_xlabel('Year')\n",
    "    if log_scale:\n",
    "        ax.set_ylabel(f\"{var_long_name} [{unit}] - log-scale\")\n",
    "    else:\n",
    "        ax.set_ylabel(f\"{var_long_name} [{unit}]\")\n",
    "\n",
    "    # Calculate the ensemble mean\n",
    "    ensemble_mean = xr.concat(data_list, dim='dataset').mean(dim='dataset')\n",
    "\n",
    "    if add_regression:\n",
    "\n",
    "        # Create regression model\n",
    "        #trend = ensemble_mean.polyfit(dim='time', deg=1)\n",
    "        trend = ensemble_mean.polyfit(dim='year', deg=1)\n",
    "\n",
    "        # Fit regression model to data and add it to plot \n",
    "        regression_line = xr.polyval(ds['year'], trend).squeeze()\n",
    "        #regression_line = xr.polyval(ds['time'], trend).squeeze()\n",
    "        #regression_line['polyfit_coefficients'].plot(x='year', ax=ax, linestyle='--', color=data_color)\n",
    "        #regression_line['polyfit_coefficients'].plot(x='time', ax=ax, color=data_color)\n",
    "        #sns.lineplot(x='time', y=regression_line['polyfit_coefficients'], ax=ax, color=black)\n",
    "\n",
    "        # Calculate percentage of change\n",
    "        #first_value = regression_line['polyfit_coefficients'].isel(time=0).item()\n",
    "        #last_value = regression_line['polyfit_coefficients'].isel(time=-1).item()\n",
    "        first_value = regression_line['polyfit_coefficients'].isel(year=0).item()\n",
    "        last_value = regression_line['polyfit_coefficients'].isel(year=-1).item()\n",
    "        ens_percentage_change = ((last_value - first_value) / first_value) * 100\n",
    "\n",
    "    # Plot the ensemble mean with a different line style and/or color\n",
    "    #ensemble_mean.plot.line(x='time', ax=ax, linestyle='--', color='black', label=f\"Ensemble mean ({ens_percentage_change:.2f}%)\") \n",
    "    ensemble_mean.plot.line(x='year', ax=ax, linestyle='--', color='black', label=f\"Ensemble mean ({ens_percentage_change:.2f}%)\") \n",
    "    #sns.lineplot(x='time', y=ensemble_mean, ax=ax, linestyle='--', color='black', label=f\"Ensemble mean ({ens_percentage_change:.2f}%)\") \n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Set figure title with first and last year of dataset\n",
    "    if smooth_window>1:\n",
    "        fig.suptitle(f\"{titles[statistic_dim]} {titles[statistic]} of {var_long_name} ({period}) ({smooth_window}-year running mean)\", fontsize=26, y=1.0)\n",
    "    else:\n",
    "        fig.suptitle(f\"{titles[statistic_dim]} {titles[statistic]} of {var_long_name} ({period})\", fontsize=26, y=1.0)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', experiment_id, statistic_dim, statistic, 'line_plots')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "        if smooth_window>1:\n",
    "            if log_scale:\n",
    "                filename = f'{statistic_dim}.{statistic}.{period}.{variable}.{ds.experiment_id}.{smooth_window}-year_running_mean.log_scale.{file_format}'\n",
    "            else:\n",
    "                filename = f'{statistic_dim}.{statistic}.{period}.{variable}.{ds.experiment_id}.{smooth_window}-year_running_mean.{file_format}'\n",
    "        else:\n",
    "            if log_scale:\n",
    "                filename = f'{statistic_dim}.{statistic}.{period}.{variable}.{ds.experiment_id}.log_scale.{file_format}'\n",
    "            else:\n",
    "                filename = f'{statistic_dim}.{statistic}.{period}.{variable}.{ds.experiment_id}.{file_format}'\n",
    "\n",
    "\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=300)\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6de0c-2830-40ca-8cec-86042d8f6641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sm_profile(ds_depth, save_path='../results/CMIP6/historical/', save_name='soil_moisture_profile.png', save_fig=False, xlim_bound=3, ylim_bound=1000):\n",
    "    \"\"\"\n",
    "    Plots soil moisture profile.\n",
    "\n",
    "    Args:\n",
    "        ds_depth (dict): A dictionary of xarray datasets with depth and mean mean soil water content per layer (mrsol).\n",
    "        save_path (string): Path saved figure. \n",
    "        save_name (string): Name of saved figure.\n",
    "        save_fig (bool): If True, save the figure to a file. Default is False.\n",
    "        xlim_bound (float): A value to set the max for the x-axis. Default is 3.\n",
    "        ylim_bound (float): A value to set the max for the y-axis. Default is 1000.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(30, 15))\n",
    "\n",
    "    plt.xlim(0, xlim_bound)\n",
    "    plt.ylim(0, ylim_bound)\n",
    "\n",
    "    # Define the marker size for the plot\n",
    "    marker_size = 150\n",
    "\n",
    "    for i, (name, ds) in enumerate(ds_depth.items()):\n",
    "\n",
    "        data_to_plot = ds.squeeze()\n",
    "        data_lines = ax.plot(data_to_plot['depth'], data_to_plot.variable, linestyle='--', label=f\"{name}\")\n",
    "        data_color = data_lines[0].get_color()\n",
    "        data_markers = data_to_plot.plot.scatter(x='depth', y='variable', s=marker_size, c=data_color, ax=ax, label=None)\n",
    "\n",
    "    plt.legend(fontsize=20)\n",
    "\n",
    "    if save_fig:\n",
    "        fig.savefig(f'{save_path}{save_name}', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd554aa5-93a8-45ad-bc49-3dd72e1138f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soil_moisture_profile(ds_dict, var='mrsol', save_path='../results/CMIP6/historical/', save_name='soil_moisture_profile.png', plot_fig=True, save_fig=False, xlim_bound=3, ylim_bound=1000):\n",
    "    \"\"\"\n",
    "    Plots soil moisture profile.\n",
    "\n",
    "    Args:\n",
    "        ds_depth (dict): A dictionary of xarray datasets for computing the and mean soil water content per layer (mrsol).\n",
    "        save_path (string): Path saved figure. Default is '../results/CMIP6/historical/'.\n",
    "        save_name (string): Name of saved figure.\n",
    "        plot_fig (bool): If True, plot the figure. Default is True.\n",
    "        save_fig (bool): If True, save the figure to a file. Default is False. plot_fig has to be True as well to save figure.\n",
    "        xlim_bound (float): A value to set the max for the x-axis. Default is 3.\n",
    "        ylim_bound (float): A value to set the max for the y-axis. Default is 1000.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with computed statistic for each dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    ds_depth = {}\n",
    "    \n",
    "    for i, (name, ds) in enumerate(ds_dict.items()):\n",
    "        \n",
    "        mean_time = getattr(ds[var], 'mean')(\"time\", keep_attrs=True, skipna=True)\n",
    "        mean_time_space = getattr(mean_time, 'mean')((\"lon\", \"lat\"), keep_attrs=True, skipna=True)\n",
    "        ds_depth[ds.source_id] = mean_time_space\n",
    "    \n",
    "    if plot_fig:\n",
    "        plot_sm_profile(ds_depth, save_path=save_path, save_name=save_name, save_fig=save_fig, xlim_bound=xlim_bound, ylim_bound=ylim_bound)\n",
    "\n",
    "    return ds_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aec3c2-0142-4982-aeae-e60970affae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========= Helper function to open the dataset ========\n",
    "def open_dataset(filename):\n",
    "    ds = xr.open_dataset(filename)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc33208-daa8-4c9f-b214-c9be3cfc01f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a helper function to open and merge datasets\n",
    "def open_and_merge_datasets(folder, model, experiment_id, variables):\n",
    "    filepaths = []\n",
    "    for var in variables:\n",
    "        path = f'../../data/CMIP6/{experiment_id}/{folder}/{var}'\n",
    "        fp = glob.glob(os.path.join(path, f'CMIP.{model}.{experiment_id}.{var}_regridded.nc'))\n",
    "        if fp:\n",
    "            filepaths.append(fp[0])\n",
    "        else:\n",
    "            #print(f\"No file found for variable '{var}' in model '{model}'.\")\n",
    "            print(fp)\n",
    "\n",
    "    datasets = [xr.open_dataset(fp) for fp in filepaths]\n",
    "    ds = xr.merge(datasets)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75f826-aa9b-4d99-af87-26096b09933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ensemble(ds_dict):\n",
    "    # Combine all datasets into one larger dataset\n",
    "    combined = xr.concat(ds_dict.values(), dim='ensemble')\n",
    "    # Compute the ensemble metric\n",
    "    ds_dict['Ensemble mean'] = getattr(combined, 'mean')(dim='ensemble')#, skipna=True) # use getattr to call method by string name\n",
    "    \n",
    "    # Preserve variable attributes from the original dataset\n",
    "    for var in ds_dict['Ensemble mean'].variables:\n",
    "        ds_dict['Ensemble mean'][var].attrs = ds_dict[list(ds_dict.keys())[0]][var].attrs\n",
    "    \n",
    "    ds_dict['Ensemble mean'].attrs = {\"period\" : ds_dict[list(ds_dict.keys())[0]].attrs['period'],\n",
    "                           \"statistic\" : \"mean\", # use variable metric here\n",
    "                           \"statistic_dimension\" : \"time\",\n",
    "                           \"experiment_id\": ds_dict[list(ds_dict.keys())[0]].attrs['experiment'], \n",
    "                           \"source_id\" : f\"Ensemble mean\"} \n",
    "    \n",
    "    ds_dict['Ensemble median'] = getattr(combined, 'median')(dim='ensemble')#, skipna=True) # use getattr to call method by string name\n",
    "    \n",
    "    ds_dict['Ensemble median'].attrs = {\"period\" : ds_dict[list(ds_dict.keys())[0]].attrs['period'],\n",
    "                           \"statistic\" : \"median\", # use variable metric here\n",
    "                           \"statistic_dimension\" : \"time\",\n",
    "                           \"experiment_id\": ds_dict[list(ds_dict.keys())[0]].attrs['experiment'], \n",
    "                           \"source_id\" : f\"Ensemble median\"} \n",
    "    \n",
    "    return ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73bcdc-71f8-43b2-8b3b-ff0528755725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_map_statistic(ds_dict, variable, n_cols=4, cbar_min=0, cbar_max=0.75, cmap='viridis', save_fig=False, log_scale=False, file_format='png'):\n",
    "    \"\"\"\n",
    "    Plots a map of the specified statistic of the given variable for each dataset in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        ds_dict (dict): A dictionary of xarray datasets, where each key is the name of the dataset\n",
    "            and each value is the dataset itself.\n",
    "        variable (str): The name of the variable to plot.\n",
    "        n_cols (int): The number of columns for the subplots. Default is 4.\n",
    "        cbar_min (float): A value to set vmin by multiplying with the variables minimum value across the dataset. Default is 0.\n",
    "        cbar_max (float): A value to set vmax by multiplying with the variables maximum value across the dataset. Default is 0.75.\n",
    "        cmap (str): The name of the colormap to use for the plot. Default is 'viridis'.\n",
    "        save_fig (bool): If True, save the figure to a file. Default is False.\n",
    "        file_format (str): The format of the saved figure. Default is 'png'.\n",
    "\n",
    "    Returns:\n",
    "        str: The file path where the figure was saved.\n",
    "    \"\"\"\n",
    "    # Check arguments and get info\n",
    "    var_long_name, period, unit, statistic_dim, statistic, experiment_id, titles, frequency = check_args_and_get_info(ds_dict, variable) \n",
    "\n",
    "    # Calculate vmin and vmax\n",
    "    temp_dim_ds = xr.concat([ds[variable] for ds in ds_dict.values() if variable in ds], dim='temp_dim', coords='minimal')\n",
    "    print(f\"Min: {round(float(temp_dim_ds.min()))}\")\n",
    "    print(f\"Max: {round(float(temp_dim_ds.max()))}\")\n",
    "\n",
    "    vmin = round(float(temp_dim_ds.min())) * cbar_min\n",
    "    vmax = round(float(temp_dim_ds.max()), -int(math.floor(math.log10(abs(float(temp_dim_ds.max())))))) * cbar_max\n",
    "\n",
    "    # Number of datasets that contain the variable\n",
    "    n_datasets_with_var = sum([1 for ds in ds_dict.values() if variable in ds])\n",
    "\n",
    "    # Compute the required number of rows for the subplots\n",
    "    n_rows = np.ceil(n_datasets_with_var / n_cols).astype(int)\n",
    "\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(12 * n_cols, 6.5 * n_rows))\n",
    "\n",
    "    # Create a GridSpec with specified width and height space\n",
    "    gs = plt.GridSpec(n_rows, n_cols, figure=fig, wspace=0.1, hspace=0.1)\n",
    "\n",
    "    axes = []\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            ax = fig.add_subplot(gs[i, j], projection=ccrs.Robinson())\n",
    "            axes.append(ax)\n",
    "\n",
    "    subplot_counter = 0\n",
    "    # Loop over datasets and plot the requested statistic\n",
    "    for name, ds in ds_dict.items():\n",
    "        if variable not in ds:\n",
    "            print(f\"Variable '{variable}' not found in dataset '{name}', skipping.\")\n",
    "            continue\n",
    "\n",
    "        # plot the variable in subplot\n",
    "        ax = axes[subplot_counter]\n",
    "        data_to_plot = ds[variable]\n",
    "        \n",
    "        # Add condition for log_scale colorbar\n",
    "        if log_scale:\n",
    "            norm = colors.LogNorm(vmin=vmin, vmax=vmax)\n",
    "        else:\n",
    "            norm = None\n",
    "            \n",
    "        im = data_to_plot.plot(ax=ax, vmin=-1, vmax=1, cmap=cmap, extend='max', transform=ccrs.PlateCarree(), add_colorbar=False, norm=norm)\n",
    "        ax.set_title(name, fontsize=18)\n",
    "        ax.coastlines()\n",
    "\n",
    "        subplot_counter += 1\n",
    "\n",
    "    # Add a common colorbar at the bottom of the plots\n",
    "    cbar = fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.1, pad=0.03, aspect=20, shrink=0.5)\n",
    "    # Set tick size\n",
    "    cbar.ax.tick_params(labelsize=20)  # Adjust size as needed\n",
    "    # Set colorbar label\n",
    "    cbar.set_label(f\"{var_long_name} [{unit}]\", size=26)  # Adjust size as needed\n",
    "    \n",
    "    # Set figure title \n",
    "    fig.suptitle(f\"{titles[statistic_dim]} {titles[statistic]} of {frequency} {var_long_name} ({period})\", fontsize=30, y=0.95)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Save figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', experiment_id, statistic_dim, statistic, 'maps')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'{statistic_dim}.{statistic}.{period}.{variable}.{experiment_id}.{file_format}'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=300)\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173177e7-1327-46be-9952-4ba5d9d45155",
   "metadata": {},
   "source": [
    "### 1. Load netCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000af7f-db51-4fd2-a219-e72cbb403fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Define period, models and path ==============\n",
    "variable=['pr', 'tran', 'mrro']#['tas', 'pr', 'vpd', 'evspsbl', 'mrro', 'lmrso_1m', 'lmrso_2m', 'mrso_1m', 'mrso_2m', 'tran', 'lai', 'gpp', 'wue', 'EI']\n",
    "experiment_id = 'historical'\n",
    "source_id = ['TaiESM1', 'BCC-CSM2-MR',  'CanESM5', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'IPSL-CM6A-LR', 'UKESM1-0-LL', 'MPI-ESM1-2-LR', 'CESM2-WACCM', 'NorESM2-MM']#, 'Ensemble mean', 'Ensemble median'] #\n",
    "folder='preprocessed'\n",
    "\n",
    "# ========= Use Dask to parallelize computations ==========\n",
    "dask.config.set(scheduler='processes')\n",
    "\n",
    "# Create dictionary using a dictionary comprehension and Dask\n",
    "ds_dict = dask.compute({model: open_and_merge_datasets(folder, model, experiment_id, variable) for model in source_id})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f749cba-efb8-4532-9e4b-a7b880530fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============= Have a look into the data ==============\n",
    "print(ds_dict.keys())\n",
    "ds_stat[list(ds_dict.keys())[3]].nbwfp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de9ead-0d36-4f06-9430-9efeae7cc9bb",
   "metadata": {},
   "source": [
    "### 2. Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a9c21-8094-4700-b972-36e3f720d629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========= Compute statistic for plot ===============\n",
    "ds_stat = compute_statistic(ds_dict, 'mean', 'time', start_year=1985, end_year=2014, yearly_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fcb8a4-4a04-4b9f-a66a-eb4278873eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Compute Ensemble mean/median ==============\n",
    "ds_stat = compute_ensemble(ds_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806270cb-2fd2-43a6-b9fc-73a66e401441",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, ds in ds_stat.items():\n",
    "    nbwfp = (ds['mrro'] - ds['tran']) / ds['pr']\n",
    "    \n",
    "    # Replace infinite values with NaN\n",
    "    nbwfp = xr.where(np.isinf(nbwfp), float('nan'), nbwfp)\n",
    "\n",
    "    ds['nbwfp'] = nbwfp\n",
    "    ds['nbwfp'].attrs = {'long_name': 'Net Blue Water Flux / Precipitation',\n",
    "                         'units': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94406cff-1ab9-48ad-a6ce-bc5700ef40b2",
   "metadata": {},
   "source": [
    "### Plot Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5af40-688f-41de-97d1-073e99add075",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=['tas', 'pr', 'vpd', 'evspsbl', 'mrro', 'lmrso_1m', 'lmrso_2m', 'mrso_1m', 'mrso_2m', 'tran', 'lai', 'gpp', 'wue', 'EI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadde27-364e-42f6-bc1d-8128cf102dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========= Plot the computed data ===================\n",
    "#tas - 'coolwarm' (1 - 1) // pr - 'Blues' (1 - 0.05) // vpd - 'YlOrBr' (1 - 1)// evspsbl - 'BuPu' (1 - 0.65)// mrro - 'RdPu' (0 - 0.1)\n",
    "#lmrso_1m / lmrso_2m - 'YlGnBu' (0 - 0.5) // tran - 'YlGn'  (0 - 0.65) // lai - 'YlGn'  (0 - 0.65) // gpp - 'YlGn' (0 - 0.65)\n",
    "#wue - YlGn (0 - 0.1) // EI - YlGn (1 - 0.8) // nbwfp - PiYG \n",
    "\n",
    "plot_map_statistic(ds_stat, 'nbwfp', n_cols=4, cbar_min=1, cbar_max=1, cmap='PiYG_r', save_fig=True, log_scale=False, file_format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97e26d-85a5-4abc-8c0d-1636e09870c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plot line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f77971-a789-4cc2-a7b3-081af2087cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_statistic(ds_stat, variable, log_scale=False, add_regression=True, save_fig=False, file_format='png', smooth_window=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
