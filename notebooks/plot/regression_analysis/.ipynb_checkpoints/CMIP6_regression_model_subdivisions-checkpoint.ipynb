{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7716ffb9-a564-44c7-87d4-2d4caeecdb1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CMIP6 Regression and Driver Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5a4f3-40bb-459a-88f0-f180c8b3ee8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2abf7d-6400-4813-af39-ae142ef75fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess\n",
    "import load_and_preprocess as lap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "# Statistics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr, pearsonr, kendalltau, variation, gaussian_kde, skew, kurtosis, shapiro\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "# Regression models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, ParameterGrid, RandomizedSearchCV, learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.cm\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# For color map\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f107c2-1bcc-4998-8987-1fbc53700576",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5b414a-eaa9-45cd-80ac-c7b2c46f4bf2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3. Statitical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41f31d-0d76-45ac-8b56-3f26cec06d04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### General Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1f1e6-6316-4501-9bad-36bd3fd06dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_standardized_data(X_standardized, y, predictor_vars):\n",
    "    # Summarize predictors\n",
    "    X_summary = pd.DataFrame(X_standardized, columns=predictor_vars).describe().transpose()\n",
    "    # Summarize response variable\n",
    "    y_summary = pd.DataFrame(y, columns=['bgws']).describe().transpose()\n",
    "    # Combine summaries\n",
    "    summary = pd.concat([X_summary, y_summary])\n",
    "    return summary[['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34b75f-fc88-465b-868e-cc3299cf3168",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66912a-dc41-468a-98a7-6226485aeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spearman_correlation(ds, predictor_vars, predictant):\n",
    "    # Number of regions\n",
    "    n_regions = len(ds.region)\n",
    "    # Calculate the number of rows and columns for subplots\n",
    "    n_cols = 3\n",
    "    n_rows = np.ceil(n_regions / n_cols).astype(int)\n",
    "\n",
    "    # Initialize the subplot figure\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the array for easy iteration\n",
    "\n",
    "    for index, region in enumerate(ds.region.values):\n",
    "        # Select the current region data\n",
    "        df = ds.sel(region=region).to_dataframe().dropna()\n",
    "\n",
    "        # Concatenate predictor variables and predictant for correlation\n",
    "        data = df[predictor_vars + [predictant]]\n",
    "\n",
    "        # Compute the Spearman correlation matrix\n",
    "        corr_matrix = data.corr(method='spearman')\n",
    "\n",
    "        # Plot the heatmap\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1, cbar=index == 0, ax=axes[index])\n",
    "\n",
    "        # Set the title with the region name\n",
    "        region_name = ds.names.sel(region=region).values\n",
    "        axes[index].set_title(f\"Region: {region_name}\")\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for i in range(n_regions, n_rows * n_cols):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dbe739-618c-4f31-b62a-f84dedc47d72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot all distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9589d-1545-4bd1-a9aa-c0798a8bed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_distributions(ds, predictor_vars):\n",
    "    num_regions = len(ds.region)\n",
    "    # Set up the matplotlib figure with a certain number of columns\n",
    "    cols = 3\n",
    "    rows = (num_regions // cols) + (num_regions % cols > 0)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, rows * 5), constrained_layout=True)\n",
    "    axes = axes.flatten()  # Flatten to 1D array for easy iteration\n",
    "    \n",
    "    for idx, region in enumerate(ds.region.values):\n",
    "        # Select data for the region\n",
    "        df = ds.sel(region=region).to_dataframe().reset_index()\n",
    "        df = df.dropna(subset=predictor_vars + ['bgws'])  # Drop NaN values for relevant columns only\n",
    "        \n",
    "        # Extract predictor variables and the target variable\n",
    "        X = df[predictor_vars]\n",
    "        y = df['bgws']\n",
    "        \n",
    "        # Standardize the predictors\n",
    "        scaler = StandardScaler()\n",
    "        X_standardized = scaler.fit_transform(X)\n",
    "        \n",
    "        # Create DataFrame from the standardized predictors\n",
    "        df_standardized = pd.DataFrame(X_standardized, columns=predictor_vars)\n",
    "        df_standardized['bgws'] = y.values  # Add non-standardized 'bgws'\n",
    "        \n",
    "        # Plotting on the respective subplot\n",
    "        ax = axes[idx]\n",
    "        # Create a list to store handles for the legend\n",
    "        handles = []\n",
    "        for col in df_standardized.columns:\n",
    "            # Plot each variable and get the handle\n",
    "            handle = sns.histplot(df_standardized[col], kde=True, ax=ax, label=col)\n",
    "            handles.append(handle)\n",
    "\n",
    "        region_name = ds.names.sel(region=region).values\n",
    "        ax.set_title(f'Region {region_name}')\n",
    "\n",
    "        # Only add legend to the first subplot\n",
    "        if idx == 0:\n",
    "            ax.legend(title='Variable')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for ax in axes[num_regions:]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19fdd6-b505-4936-8453-ba1ac022c7d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b00d2ee-b4eb-4801-8500-d2226b5cd21d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_scale(data):\n",
    "    # Find the absolute maximum value in the data\n",
    "    max_val = np.max(np.abs(data), axis=0)\n",
    "\n",
    "    # Scale data by dividing by the max value\n",
    "    scaled_data = data / max_val\n",
    "\n",
    "    return scaled_data, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b578b-2636-4e9e-927d-e87f04a9f1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_data(X, method):\n",
    "    scaler_data = {}\n",
    "\n",
    "    if method == 'std':\n",
    "        scaler = StandardScaler()\n",
    "        X_standardized = scaler.fit_transform(X)\n",
    "        scaler_data = {'mean': scaler.mean_, 'std': scaler.scale_}\n",
    "\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        X_standardized = scaler.fit_transform(X)\n",
    "        scaler_data = {'min': scaler.data_min_, 'max': scaler.data_max_}\n",
    "        \n",
    "    elif method == 'max':\n",
    "        X_standardized, max_val = custom_scale(X)\n",
    "        scaler_data = {'max': max_val}\n",
    "\n",
    "    elif method == 'no_scaling':\n",
    "        X_standardized = X\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Scaling method not known')\n",
    "\n",
    "    return X_standardized, scaler_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc5834-9b80-4132-8f3c-9e9e9b47fe6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_scale(data):\n",
    "    max_val = np.max(np.abs(data), axis=0)\n",
    "    scaled_data = data / max_val\n",
    "    return scaled_data, max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b7599-d58b-4789-90be-b683a06b6f18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Test scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba577f44-e776-4d0d-984b-f0213fee98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_with_dual_axis(data, scaled_data, ax, skew_unscaled, skew_scaled, kurt_unscaled, kurt_scaled):\n",
    "    # Plotting unscaled data\n",
    "    density = gaussian_kde(data)\n",
    "    xs = np.linspace(min(data), max(data), 200)\n",
    "    ax.hist(data, bins=30, alpha=0.5, color='blue', density=True)\n",
    "    ax.plot(xs, density(xs), color='darkblue')\n",
    "\n",
    "    # Creating secondary axis for scaled data\n",
    "    ax2 = ax.twinx()\n",
    "    density_scaled = gaussian_kde(scaled_data)\n",
    "    xs_scaled = np.linspace(min(scaled_data), max(scaled_data), 200)\n",
    "    ax2.hist(scaled_data, bins=30, alpha=0.5, color='orange', density=True)\n",
    "    ax2.plot(xs_scaled, density_scaled(xs_scaled), color='darkorange')\n",
    "\n",
    "    # Adding scores as text\n",
    "    textstr = f'skew_unscaled: {skew_unscaled:.2f}\\nskew_scaled: {skew_scaled:.2f}\\nkurt_unscaled: {kurt_unscaled:.2f}\\nkurt_scaled: {kurt_scaled:.2f}'\n",
    "    ax.text(0.95, 0.95, textstr, transform=ax.transAxes, fontsize=9,\n",
    "            verticalalignment='top', horizontalalignment='right', bbox=dict(facecolor='white', alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e562b4d-b9df-47b9-9b7d-55fd6e113a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_and_plot(ds):\n",
    "    regions = ds.region.values\n",
    "    variables = [var for var in ds.data_vars]\n",
    "\n",
    "    for region in [regions[0]]:\n",
    "        fig, axs = plt.subplots(1, len(variables), figsize=(5 * len(variables), 4))\n",
    "        fig.suptitle(f'Region: {ds.names.sel(region=region).values}')\n",
    "\n",
    "        for i, var in enumerate(variables):\n",
    "            data = ds[var].sel(region=region).values.flatten()\n",
    "            data_nonan = data[~np.isnan(data)]\n",
    "            \n",
    "            skew_unscaled = skew(data_nonan)\n",
    "            kurt_unscaled = kurtosis(data_nonan)\n",
    "\n",
    "            # Scale data\n",
    "            scaled_data, _ = custom_scale(data_nonan)\n",
    "\n",
    "            skew_scaled = skew(scaled_data)\n",
    "            kurt_scaled = kurtosis(scaled_data)\n",
    "\n",
    "            # Plot histograms with dual-axis\n",
    "            plot_data_with_dual_axis(data_nonan, scaled_data, axs[i], skew_unscaled, skew_scaled, kurt_unscaled, kurt_scaled)\n",
    "            axs[i].set_title(var)\n",
    "\n",
    "        # Adjust legend\n",
    "        fig.legend(['Unscaled', 'Density Unscaled', 'Scaled', 'Density Scaled'], loc='upper right')\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394584c6-255b-4a17-9489-52496ab6b9e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4. Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854afb0-8100-4ced-b9e0-c0b3ac689c26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a5410-53c8-4c14-bcf9-2455e97e7b76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c3fbe-d0fd-4640-a795-6e45f5ebfcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_models(ds_change, predictor_vars, predictant, scaling_method, regression_type='ridge', scoring='r2', cv_folds=5, scaling_back=False):\n",
    "    \"\"\"\n",
    "    Train regularized linear regression models (Ridge, Lasso, or ElasticNet) for each region using Grid Search for hyperparameter tuning,\n",
    "    perform cross-validation, compute permutation importance, and gather performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - ds_change: xarray datasets\n",
    "    - predictor_vars: List of predictor variable names\n",
    "    - predictant: Name of the predictant variable\n",
    "    - regression_type: Type of regression ('ridge', 'lasso', 'elasticnet')\n",
    "    - cv_folds: Number of folds for cross-validation\n",
    "    - scaling_method: Scaling method (std or minmax)\n",
    "    - scaling_back: Boolean flag to scale back coefficients\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing trained models, best hyperparameters, coefficients, cross-validation scores,\n",
    "      permutation importances, and performance metrics for each region.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize dictionaries\n",
    "    regression_models = {}\n",
    "    best_hyperparams = {}\n",
    "    best_scores = {}\n",
    "    regression_coeffs = {}\n",
    "    cv_scores_r2 = {}\n",
    "    cv_scores_mse = {}\n",
    "    cv_scores_r2_test = {}\n",
    "    cv_scores_mse_test = {}\n",
    "    cv_scores_r2_train = {}\n",
    "    cv_scores_mse_train = {}\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "    residuals = {}\n",
    "    performance_metrics_test = {}\n",
    "    performance_metrics_train = {}\n",
    "    permutation_importances_test = {}\n",
    "    permutation_importances_train = {}\n",
    "    scaled_data = {}\n",
    "\n",
    "    # Define parameter grid based on regression type\n",
    "    if regression_type == 'ridge':\n",
    "        model = Ridge(random_state=42)\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    elif regression_type == 'lasso':\n",
    "        model = Lasso(random_state=42)\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    elif regression_type == 'elasticnet':\n",
    "        model = ElasticNet(random_state=42)\n",
    "        param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100], 'l1_ratio': [0.2, 0.5, 0.8]}\n",
    "    else:\n",
    "        raise ValueError(\"Invalid regression type. Choose 'ridge', 'lasso', or 'elasticnet'.\")\n",
    "\n",
    "    for region in ds_change.region.values:\n",
    "        # Data preparation\n",
    "        df = ds_change.sel(region=region).to_dataframe().reset_index()\n",
    "        df.dropna(inplace=True)\n",
    "        X = df[predictor_vars]\n",
    "        y = df[predictant]\n",
    "        \n",
    "        # Get region name\n",
    "        region_name = ds_change.names.sel(region=region).values\n",
    "\n",
    "        # Scale the data\n",
    "        X_scaled, scaled_data[f'{region_name}'] = scale_data(X, method=scaling_method)\n",
    "\n",
    "        # Train/Test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv_folds, scoring=scoring, n_jobs=-1) #r2 neg_mean_squared_error\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Store best model and hyperparameters\n",
    "        best_model = grid_search.best_estimator_\n",
    "        regression_models[f'{region_name}'] = best_model\n",
    "        best_hyperparams[f'{region_name}'] = grid_search.best_params_\n",
    "        best_scores[f'{region_name}'] = grid_search.best_score_\n",
    "        regression_coeffs[f'{region_name}'] = best_model.coef_\n",
    "        \n",
    "        # Perform cross-validation and store results\n",
    "        cv_scores_r2[f'{region_name}'] = cross_val_score(best_model, X_scaled, y, cv=cv_folds, scoring='r2')\n",
    "        cv_scores_mse[f'{region_name}'] = -cross_val_score(best_model, X_scaled, y, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "        cv_scores_r2_train[f'{region_name}'] = cross_val_score(best_model, X_train, y_train, cv=cv_folds, scoring='r2')\n",
    "        cv_scores_mse_train[f'{region_name}'] = -cross_val_score(best_model, X_train, y_train, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "        cv_scores_r2_test[f'{region_name}'] = cross_val_score(best_model, X_test, y_test, cv=cv_folds, scoring='r2')\n",
    "        cv_scores_mse_test[f'{region_name}'] = -cross_val_score(best_model, X_test, y_test, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "        \n",
    "        # Compute and store performance metrics\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        performance_metrics_test[f'{region_name}'] = {'MSE': mse_test, 'R2': r2_test}\n",
    "\n",
    "        y_pred_train = best_model.predict(X_train)\n",
    "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        performance_metrics_train[f'{region_name}'] = {'MSE': mse_train, 'R2': r2_train}\n",
    "\n",
    "        # Compute permutation importance\n",
    "        perm_importance_test = permutation_importance(best_model, X_test, y_test, n_repeats=20, random_state=42)\n",
    "        permutation_importances_test[f'{region_name}'] = perm_importance_test['importances']\n",
    "\n",
    "        perm_importance_train = permutation_importance(best_model, X_train, y_train, n_repeats=20, random_state=42)\n",
    "        permutation_importances_train[f'{region_name}'] = perm_importance_train['importances']\n",
    "\n",
    "        # Store train and test data\n",
    "        train_data[f'{region}'] = (X_train, y_train)\n",
    "        test_data[f'{region}'] = (X_test, y_test)\n",
    "\n",
    "    # Convert regression coefficients to DataFrame\n",
    "    coeffs_df = pd.DataFrame.from_dict(regression_coeffs, orient='index', columns=predictor_vars)\n",
    "\n",
    "    return coeffs_df, regression_models, best_hyperparams, best_scores, train_data, test_data, cv_scores_r2, cv_scores_mse, cv_scores_r2_train, cv_scores_mse_train, cv_scores_r2_test, cv_scores_mse_test, performance_metrics_test, performance_metrics_train, permutation_importances_test, permutation_importances_train, scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98930ee-2244-45fd-b5bd-f7c659138174",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### XGBR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de029c-8d51-46f6-8f69-89e03f1b5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_models(ds, predictor_vars, predictant, scaling_method, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Train XGBoost models for each region with Grid Search, Cross-Validation, and Train/Test Split.\n",
    "\n",
    "    Parameters:\n",
    "    - ds: xarray dataset\n",
    "    - predictor_vars: List of predictor variable names\n",
    "    - predictant: Name of the predictant variable\n",
    "    - scaling_method: Method for scaling features\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing trained models, best parameters, best scores, CV scores (R2 and MSE), feature importances, and performance metrics for each region.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries\n",
    "    xgb_models = {}\n",
    "    best_params = {}\n",
    "    best_scores = {}\n",
    "    feature_importances = {}\n",
    "    permutation_importances_test = {}\n",
    "    permutation_importances_train = {}\n",
    "    performance_metrics_test = {}\n",
    "    performance_metrics_train = {}\n",
    "    cv_scores_r2 = {}\n",
    "    cv_scores_mse = {}\n",
    "    cv_scores_r2_test = {}\n",
    "    cv_scores_mse_test = {}\n",
    "    cv_scores_r2_train = {}\n",
    "    cv_scores_mse_train = {}\n",
    "    scaled_data = {}\n",
    "\n",
    "    # Parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 200, 400, 800, 1000, 1100, 1200, 1300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [5, 7, 10, 14],\n",
    "    'min_child_weight': [0.01, 0.1, 1, 10, 12],\n",
    "    'lambda': [1, 3],\n",
    "    'alpha': [0.001, 0.01],\n",
    "    #'gamma': [0.05, 0.1]\n",
    "    }\n",
    "    \n",
    "\n",
    "    for region in ds.region.values:\n",
    "        # Data preparation\n",
    "        df = ds.sel(region=region).to_dataframe().reset_index()\n",
    "        region_name = ds.names.sel(region=region).values\n",
    "        df.dropna(inplace=True)\n",
    "        X = df[predictor_vars]\n",
    "        y = df[predictant]\n",
    "        \n",
    "        X_scaled, scaled_data[f'{region_name}'] = scale_data(X, method=scaling_method)\n",
    "\n",
    "        # Train/Test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Further split the training set into training and validation sets for hyperparameter tuning\n",
    "        X_train_tuning, X_val, y_train_tuning, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Initialize XGBoost model\n",
    "        xgb = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "        # GridSearchCV for hyperparameter tuning on training data\n",
    "        grid_search = GridSearchCV(xgb, param_grid, cv=cv_folds, n_jobs=-1, scoring='r2')\n",
    "        grid_search.fit(X_train_tuning, y_train_tuning)\n",
    "\n",
    "        # Store the best model, parameters, and score for the region\n",
    "        xgb_models[f'{region_name}'] = grid_search.best_estimator_\n",
    "        best_params[f'{region_name}'] = grid_search.best_params_\n",
    "        best_scores[f'{region_name}'] = -grid_search.best_score_ \n",
    "\n",
    "        # Update feature_importances assignment\n",
    "        feature_importances[f'{region_name}'] = xgb_models[f'{region_name}'].feature_importances_\n",
    "        \n",
    "        #Compute permutation importance\n",
    "        perm_importance = permutation_importance(\n",
    "            xgb_models[f'{region_name}'], X_test, y_test, n_repeats=20, random_state=42\n",
    "        )\n",
    "        permutation_importances_test[f'{region_name}'] = perm_importance['importances']\n",
    "        \n",
    "        perm_importance_train = permutation_importance(\n",
    "            xgb_models[f'{region_name}'], X_train, y_train, n_repeats=20, random_state=42\n",
    "        )\n",
    "        permutation_importances_train[f'{region_name}'] = perm_importance_train['importances']\n",
    "\n",
    "        # Performance metrics\n",
    "        y_pred = xgb_models[f'{region_name}'].predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        performance_metrics_test[f'{region_name}'] = {'MSE': mse, 'R2': r2}\n",
    "        \n",
    "        y_pred_train = xgb_models[f'{region_name}'].predict(X_val)\n",
    "        mse_train = mean_squared_error(y_val, y_pred_train)\n",
    "        r2_train = r2_score(y_val, y_pred_train)\n",
    "        performance_metrics_train[f'{region_name}'] = {'MSE': mse_train, 'R2': r2_train}\n",
    "\n",
    "        # Perform cross-validation and store results\n",
    "        cv_scores_r2[f'{region_name}'] = cross_val_score(xgb_models[f'{region_name}'], X_scaled, y, cv=cv_folds, scoring='r2')\n",
    "        cv_scores_mse[f'{region_name}'] = -cross_val_score(xgb_models[f'{region_name}'], X_scaled, y, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "        cv_scores_r2_train[f'{region_name}'] = cross_val_score(xgb_models[f'{region_name}'], X_train, y_train, cv=cv_folds, scoring='r2')\n",
    "        cv_scores_mse_train[f'{region_name}'] = -cross_val_score(xgb_models[f'{region_name}'], X_train, y_train, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "        cv_scores_r2_test[f'{region_name}'] = cross_val_score(xgb_models[f'{region_name}'], X_test, y_test, cv=cv_folds, scoring='r2')\n",
    "        cv_scores_mse_test[f'{region_name}'] = -cross_val_score(xgb_models[f'{region_name}'], X_test, y_test, cv=cv_folds, scoring='neg_mean_squared_error')\n",
    "        \n",
    "    feature_importances_df = pd.DataFrame.from_dict(feature_importances, orient='index', columns=predictor_vars)\n",
    "\n",
    "    return feature_importances_df, permutation_importances_test, permutation_importances_train, best_params, xgb_models, best_scores, performance_metrics_test, performance_metrics_train, cv_scores_r2, cv_scores_mse, cv_scores_r2_train, cv_scores_mse_train, cv_scores_r2_test, cv_scores_mse_test, scaled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b39fc7-42e8-4ecd-90d4-32ac52acb986",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7cdce-0045-4bfd-a360-177cdbf56d5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Test Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45594aa-5d1d-40fb-b676-3e12e1b75877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves_for_all_regions(models, ds, predictor_vars, predictant, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Plots learning curves for each region's model using the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - models: Dictionary of trained models, one for each region.\n",
    "    - ds: xarray dataset used in training models.\n",
    "    - predictor_vars: List of predictor variable names.\n",
    "    - predictant: Name of the predictant variable.\n",
    "    - region_names: List of region names.\n",
    "    - cv_folds: Number of folds for cross-validation.\n",
    "    \"\"\"\n",
    "    for region in ds.region.values:\n",
    "        # Extract data for the region\n",
    "        df = ds.sel(region=region).to_dataframe().reset_index()\n",
    "        df.dropna(inplace=True)\n",
    "        X = df[predictor_vars]\n",
    "        y = df[predictant]\n",
    "        \n",
    "        region_name = ds.names.sel(region=region).values\n",
    "\n",
    "        # Learning curve computation\n",
    "        train_sizes, train_scores, validation_scores = learning_curve(\n",
    "            estimator=models[f'{region_name}'],\n",
    "            X=X, \n",
    "            y=y, \n",
    "            train_sizes=np.linspace(0.1, 1.0, 10, 550),\n",
    "            cv=cv_folds,\n",
    "            scoring='r2',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Calculate mean and standard deviation for training and validation set scores\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        validation_mean = np.mean(validation_scores, axis=1)\n",
    "        validation_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "        # Plot learning curves\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_sizes, train_mean, label='Training error', color='blue', marker='o')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.15)\n",
    "        plt.plot(train_sizes, validation_mean, label='Validation error', color='green', marker='o')\n",
    "        plt.fill_between(train_sizes, validation_mean - validation_std, validation_mean + validation_std, color='green', alpha=0.15)\n",
    "\n",
    "        plt.title(f'Learning Curves for {region_name}')\n",
    "        plt.xlabel('Training Data Size')\n",
    "        plt.ylabel('R^2')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c2c31-deb4-4783-a7ec-74bd5f68a678",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Test Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a3e35-5d5a-4ec5-8be5-e6b5730219d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_metrics(performance_metrics_train, performance_metrics_test, cv_scores_r2, cv_scores_mse, cv_scores_r2_train, cv_scores_mse_train, cv_scores_r2_test, cv_scores_mse_test):\n",
    "    regions = list(performance_metrics_train.keys())\n",
    "    mse_train = [performance_metrics_train[region]['MSE'] for region in regions]\n",
    "    mse_test = [performance_metrics_test[region]['MSE'] for region in regions]\n",
    "    r2_train = [performance_metrics_train[region]['R2'] for region in regions]\n",
    "    r2_test = [performance_metrics_test[region]['R2'] for region in regions]\n",
    "   \n",
    "    fig, ax = plt.subplots(6, 1, figsize=(15, 30))\n",
    "\n",
    "    # Plot 1: R2 Comparison\n",
    "    ax[0].plot(regions, r2_train, label='Train R2', marker='o')\n",
    "    ax[0].plot(regions, r2_test, label='Test R2', marker='o')\n",
    "    ax[0].set_title('R2 Comparison')\n",
    "    ax[0].set_xlabel('Regions')\n",
    "    ax[0].set_ylabel('R2')\n",
    "    ax[0].set_ylim([0,1])\n",
    "    ax[0].legend()\n",
    "    ax[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "    # Plot 2: MSE Comparison\n",
    "    ax[1].plot(regions, mse_train, label='Train MSE', marker='o')\n",
    "    ax[1].plot(regions, mse_test, label='Test MSE', marker='o')\n",
    "    ax[1].set_title('MSE Comparison')\n",
    "    ax[1].set_xlabel('Regions')\n",
    "    ax[1].set_ylabel('MSE')\n",
    "    ax[1].set_ylim([0,0.006])\n",
    "    ax[1].legend()\n",
    "    ax[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "    # Function to plot mean or standard deviation\n",
    "    def plot_cv_scores(ax, cv_scores_whole, cv_scores_train, cv_scores_test, title, ylabel):\n",
    "        means_whole = [np.mean(scores) for scores in cv_scores_whole]\n",
    "        means_train = [np.mean(scores) for scores in cv_scores_train]\n",
    "        means_test = [np.mean(scores) for scores in cv_scores_test]\n",
    "        if ylabel == 'Mean Scores':\n",
    "            ax.plot(regions, means_whole, label='Whole Data', marker='o')\n",
    "            ax.plot(regions, means_train, label='Train Data', marker='o')\n",
    "            ax.plot(regions, means_test, label='Test Data', marker='o')\n",
    "        else:\n",
    "            stds_whole = [np.std(scores) for scores in cv_scores_whole]\n",
    "            stds_train = [np.std(scores) for scores in cv_scores_train]\n",
    "            stds_test = [np.std(scores) for scores in cv_scores_test]\n",
    "            ax.plot(regions, stds_whole, label='Whole Data', marker='o')\n",
    "            ax.plot(regions, stds_train, label='Train Data', marker='o')\n",
    "            ax.plot(regions, stds_test, label='Test Data', marker='o')\n",
    "        \n",
    "        # Set y-axis limits for R2 plots\n",
    "        if title == 'Mean CV R2 Scores' or title == 'Std CV R2 Scores':\n",
    "            ax.set_ylim([0, 1]) \n",
    "        else:\n",
    "            ax.set_ylim([0, 0.006]) \n",
    "\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Regions')\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.legend()\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    # Plot 3: Mean CV R2 Scores\n",
    "    plot_cv_scores(ax[2], [cv_scores_r2[region] for region in regions], [cv_scores_r2_train[region] for region in regions], [cv_scores_r2_test[region] for region in regions], 'Mean CV R2 Scores', 'Mean Scores')\n",
    "\n",
    "    # Plot 4: Std CV R2 Scores\n",
    "    plot_cv_scores(ax[3], [cv_scores_r2[region] for region in regions], [cv_scores_r2_train[region] for region in regions], [cv_scores_r2_test[region] for region in regions], 'Std CV R2 Scores', 'Standard Deviation')\n",
    "\n",
    "    # Plot 5: Mean CV MSE Scores\n",
    "    plot_cv_scores(ax[4], [cv_scores_mse[region] for region in regions], [cv_scores_mse_train[region] for region in regions], [cv_scores_mse_test[region] for region in regions], 'Mean CV MSE Scores', 'Mean Scores')\n",
    "\n",
    "    # Plot 6: Std CV MSE Scores\n",
    "    plot_cv_scores(ax[5], [cv_scores_mse[region] for region in regions], [cv_scores_mse_train[region] for region in regions], [cv_scores_mse_test[region] for region in regions], 'Std CV MSE Scores', 'Standard Deviation')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d58cf-f8ca-4ca9-a9d8-d91a5b057084",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Test model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e26852-c05b-4851-b0d0-2f5e6b33471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_regression_assumptions_scikit(regression_models, test_data, predictor_vars):\n",
    "    results = []\n",
    "\n",
    "    for region_name in regression_models:\n",
    "        model = regression_models[region_name]\n",
    "        X_test, y_test = test_data[region_name]\n",
    "\n",
    "        # Predict and calculate residuals\n",
    "        predictions = model.predict(X_test)\n",
    "        residuals = y_test - predictions\n",
    "\n",
    "        # Add a constant term for the Breusch-Pagan test\n",
    "        X_test_with_constant = np.column_stack((np.ones(X_test.shape[0]), X_test))\n",
    "\n",
    "        # Test for normality of residuals\n",
    "        shapiro_stat, shapiro_p = shapiro(residuals)\n",
    "\n",
    "        # Test for homoscedasticity\n",
    "        _, _, _, bp_pvalue = het_breuschpagan(residuals, X_test_with_constant)\n",
    "\n",
    "        # VIF for multicollinearity\n",
    "        vif = [variance_inflation_factor(X_test, i) for i in range(X_test.shape[1])]\n",
    "\n",
    "        # Prepare plot data\n",
    "        plot_data = {\n",
    "            'Region': region_name,\n",
    "            'Predictions': predictions,\n",
    "            'Residuals': residuals,\n",
    "            'Shapiro-Wilk': shapiro_stat,\n",
    "            'Shapiro-Wilk p-value': shapiro_p,\n",
    "            'Breusch-Pagan p-value': bp_pvalue,\n",
    "            'VIF': vif\n",
    "        }\n",
    "        results.append(plot_data)\n",
    "    \n",
    "    # Plotting\n",
    "    num_regions = len(results)\n",
    "    fig, axs = plt.subplots(num_regions, 3, figsize=(22, 5 * num_regions)) # Changed to 3 subplots for VIF\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        sns.residplot(x=result['Predictions'], y=result['Residuals'], lowess=True, ax=axs[i, 0])\n",
    "        axs[i, 0].set_title(f'Residuals vs Predictions for {result[\"Region\"]}')\n",
    "        axs[i, 0].set_xlabel('Predicted values')\n",
    "        axs[i, 0].set_ylabel('Residuals')\n",
    "\n",
    "        # Adding text for statistical tests\n",
    "        axs[i, 0].text(0.05, 0.95, f\"Shapiro-Wilk: {result['Shapiro-Wilk']:.2f}\", transform=axs[i, 0].transAxes)\n",
    "        axs[i, 0].text(0.05, 0.90, f\"Shapiro-Wilk p-value: {result['Shapiro-Wilk p-value']:.2f}\", transform=axs[i, 0].transAxes)\n",
    "        axs[i, 0].text(0.05, 0.85, f\"Breusch-Pagan p-value: {result['Breusch-Pagan p-value']:.2f}\", transform=axs[i, 0].transAxes)\n",
    "\n",
    "        sns.histplot(result['Residuals'], kde=True, ax=axs[i, 1])\n",
    "        axs[i, 1].set_title(f'Residual Distribution for {result[\"Region\"]}')\n",
    "        axs[i, 1].set_xlabel('Residuals')\n",
    "        axs[i, 1].set_ylabel('Frequency')\n",
    "\n",
    "        # VIF bar plot\n",
    "        sns.barplot(x=predictor_vars, y=result['VIF'], ax=axs[i, 2])\n",
    "        axs[i, 2].hlines(5, xmin=-0.5, xmax=len(result['VIF'])-0.5, colors='orange', linestyles='dashed')\n",
    "        axs[i, 2].hlines(10, xmin=-0.5, xmax=len(result['VIF'])-0.5, colors='r', linestyles='dashed')\n",
    "        axs[i, 2].set_title(f'VIF for {result[\"Region\"]}')\n",
    "        axs[i, 2].set_xlabel('Predictor Variables')\n",
    "        axs[i, 2].set_ylabel('VIF Value')\n",
    "        axs[i, 2].set_ylim(0, max(result['VIF']) + 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "#Linearity: Random pattern without any discernible pattern --> non-linearity\n",
    "#\n",
    "#Independence of Errors: Durbin-Watson values between 1.5 and 2.5 are relatively normal\n",
    "#\n",
    "#Homoscedasticity (Equal Variance of Errors):  Variance of the residuals is consistent across all levels of the predicted values +\n",
    "#                                              Breusch-Pagan test: A small p-value (typically <= 0.05)  suggests heteroscedasticity, which can invalidate                                                   some of the statistical conclusions of the regression.\n",
    "#                                              \n",
    "#Normality of Errors: Shapiro-Wilk test: The closer this value is to 1, the more the residuals follow a normal distribution. \n",
    "#                     Sapiro-Wilk p-value: The p-value from the Shapiro-Wilk test. A small p-value (typically <= 0.05) indicates that                        the residuals do not follow a normal distribution.\n",
    "#                     \n",
    "#Variance Inflation Factor (VIF): Measures multicollinearity among the independent variables in the regression model. A VIF value                                        greater than 10 is typically considered an indicator of serious multicollinearity that could affect                                    the model's estimates.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aec367-2887-4987-883d-29c843f7a43b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5. Driver Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17559894-9d2f-4417-8ef0-22037f9d0fe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot Permutation Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43022b79-9708-4256-a763-9fa91f0a4918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_permutation_importances(permutation_importances, predictor_vars, performance_metrics, split='test', season='Year', save_fig=False):\n",
    "    # Set larger font sizes\n",
    "    plt.rcParams.update({'font.size': 24})\n",
    "    \n",
    "    # Get variable names and prepare them for display\n",
    "    var_names = prepare_display_variables(predictor_vars)\n",
    "\n",
    "    for region in permutation_importances:\n",
    "        # Convert arrays to DataFrame for easy plotting, applying new variable names for display\n",
    "        df = pd.DataFrame(permutation_importances[region].T, columns=predictor_vars)\n",
    "        df.rename(columns=var_names, inplace=True)\n",
    "        \n",
    "        # Create the plot for the region\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        sns.boxplot(data=df, orient='h', ax=ax)\n",
    "        ax.axvline(0, color='grey', linestyle='--')\n",
    "        \n",
    "        # Title with region\n",
    "        #ax.set_title(f'{region} - Permutation Importance ({season})')\n",
    "        \n",
    "        # Add Mean Squared Error and R-squared as text within the plot\n",
    "        mse = round(performance_metrics[region]['MSE'], 4)\n",
    "        r2 = round(performance_metrics[region]['R2'], 2)\n",
    "        ax.text(0.95, 0.01, f'Mean Squared Error: {mse}\\nR$^2$: {r2}',\n",
    "                verticalalignment='bottom', horizontalalignment='right',\n",
    "                transform=ax.transAxes,  # Position text relative to axes\n",
    "                color='black', fontsize=26)\n",
    "        \n",
    "        ax.set_xlabel('Decrease in Accuracy Score')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        if save_fig:\n",
    "            save_figure(fig, region, split, season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7024373-9725-444c-83dd-926feffbce81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_display_variables(variables):\n",
    "    var_map = {\n",
    "        'tas': ('T', '°C'),\n",
    "        'vpd': ('VPD', 'hPa'),\n",
    "        'gpp': ('GPP', r'\\frac{\\frac{gC}{m^2}}{day}'),  \n",
    "        'pr': ('P', r'\\frac{mm}{day}'),\n",
    "        'mrro': ('R', r'\\frac{mm}{day}'),\n",
    "        'evspsbl': ('ET', r'\\frac{mm}{day}'),\n",
    "        'tran': ('Tran', r'\\frac{mm}{day}'),\n",
    "        'evapo': ('E', r'\\frac{mm}{day}'),\n",
    "        'lai': ('Lai', r'\\frac{m^2}{m^2}'),\n",
    "        'mrso': ('SM', '\\%'),\n",
    "        'rgtr': ('P/T', r'\\frac{GPP}{T}'),\n",
    "        'et_partitioning': ('EP', r'\\frac{E-Tran}{ET}'),\n",
    "        'growing_season_length_period': ('GSL', 'days'),\n",
    "        'RX5day': ('RX5d', 'mm'),\n",
    "        'growing_season_length_winter': ('GSL', 'days'),\n",
    "        'growing_season_length_summer': ('GSL', 'days'),\n",
    "        'growing_season_length_fall': ('GSL', 'days'),\n",
    "        'growing_season_length_spring': ('GSL', 'days'),\n",
    "        'wue': ('WUE', r'\\frac{GPP}{Tran}'),\n",
    "        'bgws': ('BGWS', r'\\frac{R-Tran}{P}')\n",
    "    }\n",
    "    display_variables = {}\n",
    "    for var in variables:\n",
    "        if var in var_map:\n",
    "            abbreviation, units = var_map[var]\n",
    "            # Enclose units in \\left[ and \\right] for automatic sizing\n",
    "            display_variables[var] = f\"${{\\Delta\\, \\mathrm{{\\it{{{abbreviation}}}}}}}$\"\n",
    "        else:\n",
    "            print(f\"Variable '{var}' not found in var_map.\")\n",
    "            display_variables[var] = var  # Or handle this case as appropriate\n",
    "    return display_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87887ec0-5fe5-4e55-8766-2e7fc5831dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_figure(fig, region, split, season):\n",
    "    # Caption and figure saving\n",
    "    region_name = region.replace(\"/\", \"_\")\n",
    "    savepath = os.path.join('..', '..', 'results', 'CMIP6', 'historical-ssp370', 'time', 'mean', 'permutation_importance', season, split)\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    filename = f'{region_name}_permutation_importance_{split}_data_{season}.pdf'\n",
    "    filepath = os.path.join(savepath, filename)\n",
    "    fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    print(f'Figure saved under {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f28f1-e87d-4475-850f-1df51ea220d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ca7b2-8a4c-476e-b1b6-76d3d2cdff4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "season='winter' # None, 'spring', summer, fall, winter\n",
    "ds_dict = lap.load_and_preprocess(vars='all', scenarios=['historical', 'ssp370'], models='all', period=season, yearly_sum=False, period_statistic='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d1995-0cba-4005-af68-9f1f61b4293f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Subdivide Regions, Compute Mean and Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75d8b1-6909-4cac-b557-83cd569aa420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions = lap.subdivide_region_and_compute_mean(ds_dict, with_global=True, spatial_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f475a7-4705-4d0a-b99a-243381713d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change = lap.compute_change_dict(ds_dict_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d128da-a979-43f3-8124-5f5cca2439c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_dict_regions_change['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change['historical-ssp370'], 'mean')\n",
    "ds_dict_regions_change['historical-ssp370'] = lap.compute_ensemble(ds_dict_regions_change['historical-ssp370'], 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef2595-cda4-485c-9d05-300e991878ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 3. Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5afdb95-0ed0-46d8-95e1-7630b82162db",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### General Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e654b-d22f-46a7-b0b1-e65fa8adbbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_standardized_data(X, y, predictor_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95d470-71ab-45d2-92a7-80bcd748396d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c714e-050d-4f29-a809-11980f5fe0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spearman_correlation(ds, predictor_vars, predictant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c1d65-8cf0-44da-aa52-13cc935c9cdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot all distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee2dc9-33e2-4a72-92f2-5839f59f4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_distributions(ds, predictor_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023bbe98-7f78-43a5-8ee9-74bc7c7f708c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Scale Data and test effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128e89e-b0e5-49c2-be04-220289e8541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = scale_and_plot(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a571e70-091f-4b79-bab6-334fe66291fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12055d-065a-429c-b69f-a3eeef59811a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513c461-1b4f-40c2-b20c-4e038407d29d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482e3a9-5ba3-4a9c-b3f4-132cdfed39a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define data and predictor variables\n",
    "if season==None:\n",
    "    season='period'\n",
    "    \n",
    "predictor_vars = ['pr', 'vpd', 'mrso', 'lai', 'wue', 'RX5day', f'growing_season_length_{season}']  \n",
    "predictant = 'bgws'\n",
    "\n",
    "# Run model\n",
    "(\n",
    "    coeffs_df_lr, \n",
    "    linear_regression_models, \n",
    "    best_hyperparams_lr, \n",
    "    best_scores_lr, \n",
    "    train_data_lr, test_data_lr, \n",
    "    cv_scores_r2_lr, cv_scores_mse_lr, \n",
    "    cv_scores_r2_train_lr, cv_scores_mse_train_lr, \n",
    "    cv_scores_r2_test_lr, cv_scores_mse_test_lr, \n",
    "    performance_metrics_test_lr, performance_metrics_train_lr, \n",
    "    permutation_importances_test_lr, permutation_importances_train_lr, \n",
    "    scaled_data_lr \n",
    ")= lr_models(ds_dict_regions_change['historical-ssp370']['Ensemble mean'], \n",
    "                           predictor_vars, predictant, scaling_method='max', \n",
    "                           regression_type='elasticnet', scoring='neg_mean_squared_error', \n",
    "                           cv_folds=4, scaling_back=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6146e-e361-4838-b7a0-1eedd50b6301",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### XGBR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879a804-1d73-4a36-9679-793eaf1fcc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data and predictor variables\n",
    "predictor_vars = ['tas', 'pr', 'vpd','evapo', 'mrso','lai', 'gpp'] #'pr',  'gpp' 'evspsbl'  'mrro', 'tran', \n",
    "predictant = 'bgws'\n",
    "ds_reduced_regions = ds.sel(region=slice(18, 22))\n",
    "feature_importances_df_xgb, permutation_importances_test_xgb, permutation_importances_train_xgb, best_params_xgb, x_gradient_boosting_models, best_scores_xgb, performance_metrics_test_xgb, performance_metrics_train_xgb, cv_scores_r2_xgb, cv_scores_mse_xgb, cv_scores_r2_train_xgb, cv_scores_mse_train_xgb, cv_scores_r2_test_xgb, cv_scores_mse_test_xgb, scaler_data_xgb = train_xgb_models(ds_reduced_regions, predictor_vars, predictant, scaling_method='max', cv_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9e40f-2c58-4776-8803-8078ef50fc7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c072d03-b90d-471a-90b0-c5a0b5f2aa32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a28135f-90b5-4849-8984-0efd7e29d35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_learning_curves_for_all_regions(linear_regression_models, ds_dict_regions_change['historical-ssp370']['Ensemble mean'], predictor_vars, predictant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34eb75-09ff-4446-875e-e4020ac794fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491d3f7-eaeb-4ca0-a982-db665ede3de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_performance_metrics(performance_metrics_train_lr, \n",
    "                         performance_metrics_test_lr, \n",
    "                         cv_scores_r2_lr, \n",
    "                         cv_scores_mse_lr, \n",
    "                         cv_scores_r2_train_lr, \n",
    "                         cv_scores_mse_train_lr,\n",
    "                         cv_scores_r2_test_lr, \n",
    "                         cv_scores_mse_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cf469-a81a-4b33-9f56-ec1a9cb88ac7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727f7f9-b5f0-4b03-bdea-693eb7f39668",
   "metadata": {},
   "outputs": [],
   "source": [
    "assumptions_df = test_regression_assumptions_scikit(regression_models, test_data, predictor_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba4439-e3df-421a-840b-4d92d6c251b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Driver Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1920273-5c88-4b34-b685-aea4fdb3656a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plot Permutation Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f7684-69ab-4b3c-b235-110d3ccfb5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if season == 'period':\n",
    "    season='Year'\n",
    "    \n",
    "plot_permutation_importances(permutation_importances_train_lr, predictor_vars, performance_metrics_train_lr, split='train', season=season, save_fig=True)\n",
    "plot_permutation_importances(permutation_importances_test_lr, predictor_vars, performance_metrics_test_lr, split='test', season=season, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f783b-9b77-4e34-9875-f70ba433761e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Supplements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b99e4e-a726-4ce8-b26a-26023f23222f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Extreme Gradient Boosting Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c6bc9-4aad-4664-88d2-32b7d1a2b829",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Assess variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59ae94-ef1b-421d-85e6-0cc435bf410a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "permutation_importance_df_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acad1df-45fd-4e9d-870d-5cad9c61ada0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances_df * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32681dd8-0598-49bf-95d0-de6345fab979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances_df * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64ad7a-fec1-411e-b326-4ff435971e0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb58ac-0320-40f6-b533-60e3796b1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "def test_regression_assumptions_scikit(regression_models, test_data, predictor_vars):\n",
    "    results = []\n",
    "\n",
    "    for region_name in regression_models:\n",
    "        model = regression_models[region_name]\n",
    "        X_test, y_test = test_data[region_name]\n",
    "\n",
    "        # Predict and calculate residuals\n",
    "        predictions = model.predict(X_test)\n",
    "        residuals = y_test - predictions\n",
    "\n",
    "        # Add a constant term for the Breusch-Pagan test\n",
    "        X_test_with_constant = np.column_stack((np.ones(X_test.shape[0]), X_test))\n",
    "\n",
    "        # Test for normality of residuals\n",
    "        shapiro_stat, shapiro_p = shapiro(residuals)\n",
    "\n",
    "        # Test for homoscedasticity\n",
    "        _, _, _, bp_pvalue = het_breuschpagan(residuals, X_test_with_constant)\n",
    "\n",
    "        # VIF for multicollinearity\n",
    "        vif = [variance_inflation_factor(X_test, i) for i in range(X_test.shape[1])]\n",
    "\n",
    "        # Prepare plot data\n",
    "        plot_data = {\n",
    "            'Region': region_name,\n",
    "            'Predictions': predictions,\n",
    "            'Residuals': residuals,\n",
    "            'Shapiro-Wilk': shapiro_stat,\n",
    "            'Shapiro-Wilk p-value': shapiro_p,\n",
    "            'Breusch-Pagan p-value': bp_pvalue,\n",
    "            'VIF': vif\n",
    "        }\n",
    "        results.append(plot_data)\n",
    "    \n",
    "    # Plotting\n",
    "    num_regions = len(results)\n",
    "    fig, axs = plt.subplots(num_regions, 3, figsize=(22, 5 * num_regions)) # Changed to 3 subplots for VIF\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        sns.residplot(x=result['Predictions'], y=result['Residuals'], lowess=True, ax=axs[i, 0])\n",
    "        axs[i, 0].set_title(f'Residuals vs Predictions for {result[\"Region\"]}')\n",
    "        axs[i, 0].set_xlabel('Predicted values')\n",
    "        axs[i, 0].set_ylabel('Residuals')\n",
    "\n",
    "        # Adding text for statistical tests\n",
    "        axs[i, 0].text(0.05, 0.95, f\"Shapiro-Wilk: {result['Shapiro-Wilk']:.2f}\", transform=axs[i, 0].transAxes)\n",
    "        axs[i, 0].text(0.05, 0.90, f\"Shapiro-Wilk p-value: {result['Shapiro-Wilk p-value']:.2f}\", transform=axs[i, 0].transAxes)\n",
    "        axs[i, 0].text(0.05, 0.85, f\"Breusch-Pagan p-value: {result['Breusch-Pagan p-value']:.2f}\", transform=axs[i, 0].transAxes)\n",
    "\n",
    "        sns.histplot(result['Residuals'], kde=True, ax=axs[i, 1])\n",
    "        axs[i, 1].set_title(f'Residual Distribution for {result[\"Region\"]}')\n",
    "        axs[i, 1].set_xlabel('Residuals')\n",
    "        axs[i, 1].set_ylabel('Frequency')\n",
    "\n",
    "        # VIF bar plot\n",
    "        sns.barplot(x=predictor_vars, y=result['VIF'], ax=axs[i, 2])\n",
    "        axs[i, 2].hlines(5, xmin=-0.5, xmax=len(result['VIF'])-0.5, colors='orange', linestyles='dashed')\n",
    "        axs[i, 2].hlines(10, xmin=-0.5, xmax=len(result['VIF'])-0.5, colors='r', linestyles='dashed')\n",
    "        axs[i, 2].set_title(f'VIF for {result[\"Region\"]}')\n",
    "        axs[i, 2].set_xlabel('Predictor Variables')\n",
    "        axs[i, 2].set_ylabel('VIF Value')\n",
    "        axs[i, 2].set_ylim(0, max(result['VIF']) + 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f835f9b-fd63-49b1-80df-e0fcef9413dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assumptions_df = test_regression_assumptions_scikit(regression_models, test_data, predictor_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f876b-31e1-4566-b3e5-c43fee81a59f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845e157-982f-4644-ab79-107e9867e0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assess_model_performance_all_regions(ds, regression_models, best_params, best_scores, scalers, predictor_vars):\n",
    "    region_names = ds.names.values\n",
    "    region_indices = ds.region.values\n",
    "    \n",
    "    # Determine the number of rows and columns for the subplots based on the number of regions\n",
    "    num_regions = len(region_names)\n",
    "    cols = 3  # We are keeping 3 columns as per your requirement\n",
    "    rows = math.ceil(num_regions / cols)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 5 * rows), squeeze=False)\n",
    "    \n",
    "    # Initialize an empty dictionary to store performance metrics for each region\n",
    "    performance_metrics = {}\n",
    "\n",
    "    for idx, (ax, region) in enumerate(zip(axs.flatten(), region_indices)):\n",
    "        region_name = ds.names.sel(region=region).values.item()\n",
    "        # Prepare the data for the region\n",
    "        df = ds.sel(region=region).to_dataframe().dropna()\n",
    "        X = df[predictor_vars]\n",
    "        y_true = df['bgws'].values\n",
    "\n",
    "        # Retrieve the scaler for the region\n",
    "        scaler = scalers[region_name]\n",
    "        X_standardized = scaler.transform(X)  # Use transform here, not fit_transform\n",
    "        \n",
    "        # Predict using the trained model\n",
    "        model = regression_models[region_name]\n",
    "        y_pred = model.predict(X_standardized)\n",
    "        \n",
    "        # Calculate residuals\n",
    "        residuals = y_true - y_pred\n",
    "        \n",
    "        # Calculate and store performance metrics\n",
    "        mse_value = mean_squared_error(y_true, y_pred)\n",
    "        r2_value = r2_score(y_true, y_pred)\n",
    "        best_param = best_params[region_name]\n",
    "        best_cv_score = best_scores[region_name]\n",
    "        \n",
    "        performance_metrics[region_name] = {\n",
    "            'MSE': mse_value,\n",
    "            'R^2': r2_value,\n",
    "            'Best Parameters': best_param,\n",
    "            'Best CV Score': best_cv_score\n",
    "        }\n",
    "        \n",
    "        # Plot the residuals\n",
    "        ax.scatter(y_true, residuals, c='blue', alpha=0.5, s=10)\n",
    "        ax.axhline(0, color='red', lw=2)\n",
    "        ax.text(0.05, 0.95, f'MSE: {mse_value:.6f}\\nR^2: {r2_value:.2f}\\nBest CV: {best_cv_score:.4f}', \n",
    "                transform=ax.transAxes, verticalalignment='top')\n",
    "        ax.set_title(f'{region_name}\\n{best_param}')\n",
    "        ax.set_xlabel('True Values')\n",
    "        ax.set_ylabel('Residuals')\n",
    "        \n",
    "        # Hide axes for subplots that are not used (if num_regions < rows*cols)\n",
    "        if idx >= num_regions:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224c1a8-8798-47e2-948f-a03fb4c51ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_performance_metrics = assess_model_performance_all_regions(ds, gradient_boosting_models, best_params, best_scores, scaler_data, predictor_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e8ecb-11c5-41a6-8818-e99123f72e1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compare Permutation Importance of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd8172-1b1f-4bc1-8c7b-b9ff32b52d68",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Compare LR test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5b647-7ce1-429d-b450-7bc710888ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_permutation_importance(permutation_importances_train, permutation_importances_test, performance_metrics_train, performance_metrics_test, predictor_vars):\n",
    "    comparison_results = {}\n",
    "\n",
    "    for region in permutation_importances_train.keys():\n",
    "        mean_importance_train = pd.Series(permutation_importances_train[region].mean(axis=1), index=predictor_vars)\n",
    "        mean_importance_test = pd.Series(permutation_importances_test[region].mean(axis=1), index=predictor_vars)\n",
    "\n",
    "        # Rank the variables, excluding negative importances\n",
    "        rank_train = mean_importance_train.rank(method='dense', ascending=False).where(mean_importance_train >= 0, np.nan)\n",
    "        rank_test = mean_importance_test.rank(method='dense', ascending=False).where(mean_importance_test >= 0, np.nan)\n",
    "\n",
    "        # Special rank for zero importance in both training and test\n",
    "        zero_importance = (mean_importance_train == 0) & (mean_importance_test == 0)\n",
    "        max_rank = max(rank_train.max(), rank_test.max()) + 1\n",
    "        rank_train[zero_importance] = max_rank\n",
    "        rank_test[zero_importance] = max_rank\n",
    "\n",
    "        # Calculate agreement\n",
    "        valid_indices = (mean_importance_train >= 0) | (mean_importance_test >= 0)\n",
    "        agreement = np.mean(rank_train[valid_indices] == rank_test[valid_indices]) * 100\n",
    "\n",
    "        # Prepare data for dataframe\n",
    "        data = {\n",
    "            'Variable': predictor_vars,\n",
    "            'Train_Rank': rank_train,\n",
    "            'Test_Rank': rank_test,\n",
    "            'Train_Mean_Importance': mean_importance_train,\n",
    "            'Test_Mean_Importance': mean_importance_test,\n",
    "            'Train_R2': performance_metrics_train[region]['R2'],\n",
    "            'Test_R2': performance_metrics_test[region]['R2'],\n",
    "            'Agreement (%)': agreement\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data).sort_values(by='Train_Rank')\n",
    "        comparison_results[region] = df\n",
    "\n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6841e-4031-4f58-be5f-27bafd7f8711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_permutation_importance(permutation_importances_train, permutation_importances_test, performance_metrics_train, performance_metrics_test, predictor_vars, zero_threshold=0.001):\n",
    "    comparison_results = {}\n",
    "\n",
    "    for region in permutation_importances_train.keys():\n",
    "        mean_importance_train = pd.Series(permutation_importances_train[region].mean(axis=1), index=predictor_vars)\n",
    "        mean_importance_test = pd.Series(permutation_importances_test[region].mean(axis=1), index=predictor_vars)\n",
    "\n",
    "        # Separate zero and non-zero importance variables\n",
    "        is_zero_train = mean_importance_train.abs() <= zero_threshold\n",
    "        is_zero_test = mean_importance_test.abs() <= zero_threshold\n",
    "\n",
    "        # Rank the variables, treating near-zero importance variables separately\n",
    "        rank_train = mean_importance_train.rank(method='dense', ascending=False, na_option='bottom').astype('Int64')\n",
    "        rank_test = mean_importance_test.rank(method='dense', ascending=False, na_option='bottom').astype('Int64')\n",
    "\n",
    "        # Adjust ranks for zero importance variables\n",
    "        max_rank = max(rank_train.max(), rank_test.max()) + 1\n",
    "        rank_train[is_zero_train & is_zero_test] = max_rank\n",
    "        rank_test[is_zero_train & is_zero_test] = max_rank\n",
    "\n",
    "        # Calculate agreement\n",
    "        agreement = np.mean(rank_train == rank_test) * 100\n",
    "\n",
    "        # Prepare data for dataframe\n",
    "        data = {\n",
    "            'Variable': predictor_vars,\n",
    "            'Train_Rank': rank_train,\n",
    "            'Test_Rank': rank_test,\n",
    "            'Train_Mean_Importance': mean_importance_train,\n",
    "            'Test_Mean_Importance': mean_importance_test,\n",
    "            'Train_R2': performance_metrics_train[region]['R2'],\n",
    "            'Test_R2': performance_metrics_test[region]['R2'],\n",
    "            'Agreement (%)': agreement\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data).sort_values(by='Train_Rank')\n",
    "        comparison_results[region] = df\n",
    "\n",
    "    return comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc27797b-f7a8-4706-9f7d-f8bb4a8ce2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "comparison_results = compare_permutation_importance(permutation_importances_train_lr, permutation_importances_test_lr, performance_metrics_train_lr, performance_metrics_test_lr, predictor_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f09ee-b3eb-455d-9b94-642b27625abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(comparison_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54323b-2015-40c1-815d-a597cbf5ff76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying the results for one region as an example\n",
    "region_number = 8\n",
    "print(list(comparison_results.keys())[region_number])\n",
    "comparison_results[list(comparison_results.keys())[region_number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bf976-55dc-44c9-959a-e6f650d87d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean overall agreement and r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95257d65-7dc2-4c22-9431-27fd9af6287c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_agreement_metrics(comparison_results):\n",
    "    overall_agreement = []\n",
    "    first_rank_agreement = []\n",
    "\n",
    "    for region, df in comparison_results.items():\n",
    "        # Calculate overall agreement for the region\n",
    "        agreement = df['Agreement (%)'].iloc[0]\n",
    "        overall_agreement.append(agreement)\n",
    "\n",
    "        # Check if the top-ranked variable is the same in training and test data\n",
    "        top_train = df[df['Train_Rank'] == 1.0]['Variable'].iloc[0] if any(df['Train_Rank'] == 1.0) else None\n",
    "        top_test = df[df['Test_Rank'] == 1.0]['Variable'].iloc[0] if any(df['Test_Rank'] == 1.0) else None\n",
    "        first_rank_agreement.append(top_train == top_test)\n",
    "\n",
    "    # Calculate average agreement\n",
    "    avg_overall_agreement = sum(overall_agreement) / len(overall_agreement)\n",
    "    avg_first_rank_agreement = sum(first_rank_agreement) / len(first_rank_agreement) * 100\n",
    "\n",
    "    return avg_overall_agreement, avg_first_rank_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77cea22-a82d-4138-8ab2-8152a86c87db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_overall_agreement, avg_first_rank_agreement = compute_agreement_metrics(comparison_results)\n",
    "print(\"Average Overall Agreement:\", avg_overall_agreement)\n",
    "print(\"Average Agreement on First Rank:\", avg_first_rank_agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a8b8e-607a-4c89-bf82-abab6ae8990a",
   "metadata": {},
   "source": [
    "##### Compare xgb test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb73b00-5f9f-4e39-b5e0-bc143879a077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "comparison_results_xgb = compare_permutation_importance(permutation_importances_train_xgb, permutation_importances_test_xgb, performance_metrics_train_xgb, performance_metrics_test_xgb, predictor_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7522d9-e451-4858-8f70-44099726bf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying the results for one region as an example\n",
    "region_number = 15\n",
    "print(list(comparison_results_xgb.keys())[region_number])\n",
    "comparison_results_xgb[list(comparison_results_xgb.keys())[region_number]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2c6ba-83d6-406c-b456-dd40cc2a9230",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_overall_agreement, avg_first_rank_agreement = compute_agreement_metrics(comparison_results_xgb)\n",
    "print(\"Average Overall Agreement:\", avg_overall_agreement)\n",
    "print(\"Average Agreement on First Rank:\", avg_first_rank_agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1087570-0785-456d-acc5-182c27251f82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Compare xgb and lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f6cb3-f735-4d31-b002-ef91db448173",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build Gaussian Processes model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76996ca-c3bf-493f-9910-68861753f0d5",
   "metadata": {},
   "source": [
    "Probabilistic Outputs: GPs not only provide a prediction for each data point but also give a measure of uncertainty (variance) associated with that prediction. This can help in understanding the confidence of the model in different regions of the input space.\n",
    "\n",
    "Non-Linear Relationships: GPs, with the right choice of kernel, can model complex non-linear relationships between inputs and outputs, making them more flexible than traditional linear regression models.\n",
    "\n",
    "Kernel Flexibility: The kernel in a GP defines the relationship between data points. By selecting or designing a kernel that captures the underlying structure of the data, GPs can be adapted to various types of data patterns.\n",
    "\n",
    "Finally, regarding variable importance: In the context of GPs, interpreting variable importance is not as straightforward as in linear regression. However, one common approach is to examine the sensitivity of the GP's predictions to changes in each input variable. The Automatic Relevance Determination (ARD) kernel, for instance, can adapt its length scale for each dimension of the input space, which can give an indication of the relative importance of each input variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea48e9e-6c48-442b-8981-68199cac085a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_data_for_gp(ds, region_index):\n",
    "    # Extract data for the given region\n",
    "    region_data = ds.sel(region=region_index)\n",
    "    \n",
    "    # Prepare predictor and target variables\n",
    "    X = region_data[['pr', 'vpd', 'evspsbl', 'mrro', 'mrso', 'tran', 'lai', 'gpp']].to_array().transpose('lat', 'lon', 'variable')\n",
    "    y = region_data['bgws'].stack(z=(\"lat\", \"lon\"))\n",
    "    \n",
    "    # Convert X to a 2D array\n",
    "    X = X.stack(z=(\"lat\", \"lon\")).transpose('z', 'variable').values\n",
    "    \n",
    "    # Create a mask where either X or y has NaN values\n",
    "    mask = ~np.isnan(y) & ~np.any(np.isnan(X), axis=1)\n",
    "    \n",
    "    # Filter out rows using the mask\n",
    "    X_filtered = X[mask, :]\n",
    "    y_filtered = y[mask].values  # Convert to numpy array\n",
    "    \n",
    "    return X_filtered, y_filtered\n",
    "\n",
    "def train_gp_for_region(ds, region_name):\n",
    "    # Prepare data\n",
    "    X, y = prepare_data_for_gp(ds, region_name)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X_standardized = scaler.transform(X)\n",
    "    \n",
    "    # Define the kernel: RBF kernel with ARD + constant term + white noise term for model noise\n",
    "    # Kernel = Covarianzfunction:\n",
    "    # Defines relation between input variables\n",
    "    # \n",
    "    kernel = C(1.0, (1e-3, 1e3)) * RBF(np.ones(8), (1e-2, 1e2)) + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "    \n",
    "    # Initialize and train GP regressor\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, normalize_y=True)\n",
    "    gp.fit(X_standardized, y)\n",
    "    \n",
    "    return gp, scaler\n",
    "\n",
    "def predict_with_gp(gp, scaler, X):\n",
    "    # Standardize the features\n",
    "    X_standardized = scaler.transform(X)\n",
    "    \n",
    "    # Predict using the GP regressor\n",
    "    y_pred, y_std = gp.predict(X_standardized, return_std=True)\n",
    "    \n",
    "    return y_pred, y_std\n",
    "\n",
    "def train_and_predict_for_all_regions(ds):\n",
    "    region_indices = ds.region.values\n",
    "    region_names = ds.names.values\n",
    "    gp_models = {}\n",
    "    scalers = {}\n",
    "    predictions = {}\n",
    "    std_devs = {}\n",
    "    \n",
    "    for i, region_index in enumerate(region_indices):\n",
    "        region_name = region_names[i]\n",
    "        gp, scaler = train_gp_for_region(ds, region_index)\n",
    "        X, y = prepare_data_for_gp(ds, region_index)\n",
    "        \n",
    "        y_pred, y_std = predict_with_gp(gp, scaler, X)\n",
    "        \n",
    "        gp_models[region_name] = gp\n",
    "        scalers[region_name] = scaler\n",
    "        predictions[region_name] = y_pred\n",
    "        std_devs[region_name] = y_std\n",
    "    \n",
    "    return gp_models, scalers, predictions, std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28ef89-e109-485e-b4e9-bcc08d62e320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gp_models, scalers, predictions, std_devs = train_and_predict_for_all_regions(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0011b-1124-448e-ac82-b97467d1a07f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cc546-460e-45f0-a48d-4586b9ef1428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "def assess_model_performance_all_regions(ds, predictions, std_devs):\n",
    "    region_names = ds.names.values\n",
    "    region_indices = ds.region.values\n",
    "    \n",
    "    # Determine the number of rows and columns for the subplots based on the number of regions\n",
    "    num_regions = len(region_names)\n",
    "    cols = 3  # Assuming you'd like 3 columns\n",
    "    rows = math.ceil(num_regions / cols)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    \n",
    "    for i, region_index in enumerate(region_indices):\n",
    "        region_name = region_names[i]\n",
    "        \n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Extract true values\n",
    "        _, y_true = prepare_data_for_gp(ds, region_index)\n",
    "        \n",
    "        # Extract predicted values and standard deviations for the region\n",
    "        y_pred = predictions[region_name]\n",
    "        y_std = std_devs[region_name]\n",
    "        \n",
    "        # Calculate residuals\n",
    "        residuals = y_pred - y_true\n",
    "        \n",
    "        # Calculate the RMSE\n",
    "        mse_value = mean_squared_error(y_true, y_pred)\n",
    "        r2_s = r2_score(y_true, y_pred)\n",
    "        \n",
    "        # Plot\n",
    "        ax = axs[row, col]\n",
    "        ax.scatter(y_true, residuals, c='blue', alpha=0.5, s=10)\n",
    "        ax.fill_between(y_true, residuals - y_std, residuals + y_std, color='gray', alpha=0.2)\n",
    "        ax.axhline(0, color='red', lw=2)\n",
    "        ax.text(0.05, 0.95, f'MSE: {mse_value:.6f}', transform=ax.transAxes, verticalalignment='top')\n",
    "        ax.text(0.05, 0.9, f'R2 score: {r2_s:.2f}', transform=ax.transAxes, verticalalignment='top')\n",
    "        ax.set_title(region_name)\n",
    "        ax.set_xlabel('True Values')\n",
    "        ax.set_ylabel('Residuals')\n",
    "        \n",
    "    # Create legend with explicit handles in the last subplot\n",
    "    if num_regions < rows * cols:\n",
    "        last_ax = axs.flatten()[-1]\n",
    "        last_ax.axis('off')\n",
    "        legend_elements = [mlines.Line2D([0], [0], color='blue', marker='o', markersize=10, label='Residuals (Observed - Predicted)', linestyle='None'),\n",
    "                           mlines.Line2D([0], [0], color='gray', alpha=0.2, linewidth=10, label='Prediction Uncertainty (±1 Std. Dev.)'),\n",
    "                           mlines.Line2D([0], [0], color='red', lw=2, label='Zero Residual Line')]\n",
    "        last_ax.legend(handles=legend_elements, loc='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee7fb3-e0e6-478a-bf69-07cf13d8299e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "assess_model_performance_all_regions(ds, predictions, std_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc9c73-d454-470a-aa9d-b6f0263815ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a119068a-e003-4c1d-be14-bd4ece7f3ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432b4713-6a18-44bc-858c-5326c84f2f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5c8f9-d806-4510-817f-0a792542cbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1b0fb-5031-497b-8929-1f6e53f1985e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a75213-ca64-4d5f-8d74-8442e001845a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e7582-e89f-4fc7-9133-9a6e948896ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f566e4-514c-482e-bc54-5574851968bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def assess_variable_importance_all_regions(ds, gp_models, variable_names):\n",
    "    region_names = ds.names.values\n",
    "    region_indices = ds.region.values\n",
    "    \n",
    "    # Determine the number of rows and columns for the subplots based on the number of regions\n",
    "    num_regions = len(region_names)\n",
    "    cols = 3  # Assuming you'd like 3 columns\n",
    "    rows = math.ceil(num_regions / cols)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    \n",
    "    for i, region_index in enumerate(region_indices):\n",
    "        region_name = region_names[i]\n",
    "        \n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        ax = axs[row, col]\n",
    "        \n",
    "        # Extract the ARD kernel length scales from the trained GP model for the region\n",
    "        length_scales = gp_models[region_name].kernel_.k1.k2.length_scale\n",
    "        \n",
    "        # Plot\n",
    "        ax.bar(variable_names, length_scales)\n",
    "        ax.set_title(region_name)\n",
    "        ax.set_xlabel('Variable Name')\n",
    "        ax.set_ylabel('Length Scale')\n",
    "        ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better visibility\n",
    "        \n",
    "    # Remove empty subplots\n",
    "    for i in range(num_regions, rows*cols):\n",
    "        fig.delaxes(axs.flatten()[i])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a364539-eb02-46a0-a1e2-50de4bca458a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call the function\n",
    "variable_names = ['pr', 'vpd', 'evspsbl', 'mrro', 'mrso', 'tran', 'lai', 'gpp']\n",
    "\n",
    "assess_variable_importance_all_regions(ds, gp_models, variable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9838d6-ae01-4537-8873-3af90f298aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def assess_permutation_importance(ds, gp_models, variable_names, predictions, n_repeats=30):\n",
    "    \"\"\"\n",
    "    Assess the permutation importance of features for all regions.\n",
    "\n",
    "    Parameters:\n",
    "    - ds: Dataset containing region names, indices, and bgws values.\n",
    "    - gp_models: Dictionary containing trained GP models for each region.\n",
    "    - variable_names: List of variable names.\n",
    "    - predictions: Predicted values for each region.\n",
    "    - n_repeats: Number of times to permute a feature.\n",
    "\n",
    "    Returns:\n",
    "    - None. Plots the importance.\n",
    "    \"\"\"\n",
    "    \n",
    "    region_names = ds.names.values\n",
    "    region_indices = ds.region.values\n",
    "    y = ds.bgws.values  # Extracting target values from ds\n",
    "    \n",
    "    # Determine the number of rows and columns for the subplots based on the number of regions\n",
    "    num_regions = len(region_names)\n",
    "    cols = 3  # Assuming you'd like 3 columns\n",
    "    rows = math.ceil(num_regions / cols)\n",
    "    \n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    \n",
    "    for region_name in region_names:\n",
    "        region_index = (ds['region'].values == region_name)\n",
    "\n",
    "        # Assuming ds has columns for each predictor variable and they are named consistently\n",
    "        # Extract all predictor variables for this region\n",
    "        X_region = ds[variable_names][region_index]\n",
    "\n",
    "        y_region = y[region_index]  \n",
    "        result = permutation_importance(gp_models[region_name], X_region, y_region, n_repeats=n_repeats)\n",
    "\n",
    "        # Sort variables by importance\n",
    "        sorted_idx = result.importances_mean.argsort()\n",
    "        \n",
    "        # Plot\n",
    "        ax.boxplot(result.importances[sorted_idx].T,\n",
    "                   vert=False, labels=np.array(variable_names)[sorted_idx])\n",
    "        ax.set_title(region_name)\n",
    "        ax.set_xlabel('Importance Score')\n",
    "        \n",
    "    # Remove empty subplots\n",
    "    for i in range(num_regions, rows*cols):\n",
    "        fig.delaxes(axs.flatten()[i])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460149fd-d33d-4757-a98e-b5b2c54f8460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "assess_permutation_importance(ds, gp_models, variable_names, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed10b1-abad-4a67-8141-3058bbc83928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "739efcc9-d79d-48c1-b8eb-823cc66ad9d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54190025-097b-495b-96e4-a240ea3a7450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assess_model_performance_all_regions(ds_change, ds_hist, regression_models, test_data, performance_metrics, predictor_vars, residuals, cv_scores):\n",
    "    region_names = ds_change.names.values\n",
    "    region_indices = ds_change.region.values\n",
    "    \n",
    "    num_regions = len(region_names)\n",
    "    plots_per_region = 3  # Number of plots per region\n",
    "    total_plots = num_regions * plots_per_region\n",
    "    cols = 3  # Number of columns (one for each type of plot)\n",
    "    rows = math.ceil(total_plots / cols)  # Calculate the total number of rows needed\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(20, rows * 5), squeeze=False)\n",
    "\n",
    "    plot_idx = 0  # Initialize plot index\n",
    "    for region in region_indices:\n",
    "        region_name = ds_change.names.sel(region=region).values.item()\n",
    "        X_test, y_test = test_data[region_name]\n",
    "        model = regression_models[region_name]\n",
    "        y_pred = model.predict(X_test)\n",
    "        resids = residuals[region_name]\n",
    "\n",
    "        mse_value = performance_metrics[region_name]['MSE']\n",
    "        r2_value = performance_metrics[region_name]['R2']\n",
    "        cv_score = np.mean(cv_scores[region_name])  # Average CV score\n",
    "\n",
    "        # Plot 1: Residuals\n",
    "        ax_resid = axs[plot_idx // cols, plot_idx % cols]\n",
    "        ax_resid.scatter(y_test, resids, c='blue', alpha=0.5, s=10, label='Residuals')\n",
    "        ax_resid.axhline(0, color='red', lw=2, label='Zero Residual')\n",
    "        ax_resid.set_xlabel('True Values')\n",
    "        ax_resid.set_ylabel('Residuals')\n",
    "        ax_resid.set_title(f\"{region_name} - Residuals\")\n",
    "        ax_resid.legend()\n",
    "        plot_idx += 1\n",
    "\n",
    "        # Plot 2: Predictions vs True Values\n",
    "        ax_pred = axs[plot_idx // cols, plot_idx % cols]\n",
    "        ax_pred.scatter(y_test, y_pred, c='green', alpha=0.5, s=10, label='Predictions')\n",
    "        ax_pred.plot(y_test, y_test, color='orange', label='Ideal Prediction')\n",
    "        ax_pred.set_xlabel('True Values')\n",
    "        ax_pred.set_ylabel('Predicted Values')\n",
    "        ax_pred.set_title(f\"{region_name} - Predictions\")\n",
    "        ax_pred.legend()\n",
    "        plot_idx += 1\n",
    "\n",
    "        # Plot 3: Density Plot\n",
    "        ax_density = axs[plot_idx // cols, plot_idx % cols]\n",
    "        sns.kdeplot(y_test, ax=ax_density, label='Actual Values', fill=True)\n",
    "        sns.kdeplot(y_pred, ax=ax_density, label='Predicted Values', fill=True)\n",
    "        ax_density.set_xlabel('Values')\n",
    "        ax_density.set_title(f\"{region_name} - Density Plot\")\n",
    "        ax_density.legend()\n",
    "        plot_idx += 1\n",
    "\n",
    "        # Include performance metrics in the text or title\n",
    "        ax_density.text(0.05, 0.95, f'MSE: {mse_value:.6f}\\nR^2: {r2_value:.2f}\\nCV: {cv_score:.2f}', transform=ax_density.transAxes, verticalalignment='top')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f195a9-76c9-44b0-86d8-a4de4b9cab52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# relative change scaled\n",
    "assess_model_performance_all_regions(ds, ds_hist_ensemble_metric, regression_models, test_data, performance_metrics, predictor_vars, residuals, cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fe453-5ea1-48f6-840f-23c70db2fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assess_model_performance_all_regions(ds, ds_hist_ensemble_metric, regression_models, test_data, performance_metrics, predictor_vars, residuals, cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd280fe-f3ee-4897-89d8-efa39f1fc9de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assess_model_performance_all_regions(ds, ds_hist_ensemble_metric, regression_models, test_data, performance_metrics, predictor_vars, residuals, cv_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20765f-92f2-446a-8b9e-364243a61bd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test optimal variable subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4446c6-b0ce-473f-a625-da48b9ac8f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef977dfd-2fde-4c63-bdb7-70ec7c241c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_combinations = list(all_subsets(predictor_vars)) \n",
    "print(f\"Number of variable combinations with at least 4 variables: {len(all_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a18c3-2755-49f6-8409-be67142163b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_subsets(ss, min_length=4):\n",
    "    \"\"\"Generate all combinations of the elements in `ss` with a minimum length of `min_length`.\"\"\"\n",
    "    return chain(*map(lambda x: combinations(ss, x), range(min_length, len(ss)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df62cd-c63b-4ad1-91d0-ea3a0ad34d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_variable_combinations(ds, all_vars, predictant):\n",
    "    # Get all possible combinations of predictor variables with at least 4 variables\n",
    "    all_combinations = list(all_subsets(all_vars))\n",
    "    print(f\"Number of variable combinations: {len(all_combinations)}\")\n",
    "\n",
    "    # Prepare a list to store the performance metrics\n",
    "    performance_list = []\n",
    "\n",
    "    for combination in all_combinations:\n",
    "        # Convert the tuple to a list of variables for this combination\n",
    "        current_vars = list(combination)\n",
    "\n",
    "        # Train the models using the current combination of variables\n",
    "        _, regression_models, _, _, _, _ = train_multivariate_models(ds, current_vars, predictant)\n",
    "       \n",
    "        # Assess model performance for all regions\n",
    "        for region in ds.region.values:\n",
    "            region_name = ds.names.sel(region=region).values.item()\n",
    "            \n",
    "            # Prepare the data for the region\n",
    "            df = ds.sel(region=region).to_dataframe().dropna()\n",
    "            X = df[current_vars]\n",
    "            y_true = df[predictant].values\n",
    "\n",
    "            # Standardize the predictor variables\n",
    "            scaler = StandardScaler()\n",
    "            X_standardized = scaler.fit_transform(X) # standarized using this method might be wrong cause we need the direction. Standarize \n",
    "            #with mean \n",
    "            \n",
    "            # Predict using the trained model\n",
    "            model = regression_models[region_name]\n",
    "            y_pred = model.predict(X_standardized)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            \n",
    "            # Append the performance metrics for this region and variable combination to the list\n",
    "            performance_list.append({\n",
    "                'Variables': ', '.join(current_vars),\n",
    "                'MSE': mse,\n",
    "                'R^2': r2\n",
    "            })\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    performance_summary = pd.DataFrame(performance_list)\n",
    "    \n",
    "    # Calculate the aggregated performance for each variable combination across all regions\n",
    "    aggregated_performance = performance_summary.groupby('Variables').agg(['mean', 'min', 'max']).reset_index()\n",
    "    aggregated_performance.columns = [' '.join(col).strip() for col in aggregated_performance.columns.values]\n",
    "\n",
    "    # Sort the results by Mean MSE and Mean R^2\n",
    "    aggregated_performance.sort_values(by=['MSE mean', 'R^2 mean'], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Select and rename the columns to only include the required statistics\n",
    "    final_table = aggregated_performance[['Variables', 'MSE mean', 'MSE min', 'MSE max', 'R^2 mean', 'R^2 min', 'R^2 max']]\n",
    "    final_table.rename(columns={\n",
    "        'MSE mean': 'Mean MSE',\n",
    "        'MSE min': 'Min MSE',\n",
    "        'MSE max': 'Max MSE',\n",
    "        'R^2 mean': 'Mean R^2',\n",
    "        'R^2 min': 'Min R^2',\n",
    "        'R^2 max': 'Max R^2'\n",
    "    }, inplace=True)\n",
    "\n",
    "    return final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a331d62-6de2-41bf-99b5-45dc25417f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "pd.set_option('display.max_rows', None)  \n",
    "test_variable_combinations(ds, predictor_vars, 'bgws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccddc8ef-a7e1-4fcb-bf29-1d75cc216562",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Cluster regions based on regression coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8df60-5047-4cbb-9413-f6661a0850d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def cluster_regions(coefficients_df, max_clusters=40):\n",
    "    \"\"\"\n",
    "    This function finds the optimal number of clusters using the elbow method\n",
    "    and clusters regions based on their coefficients.\n",
    "    \n",
    "    :param coefficients_df: A pandas DataFrame containing the coefficients with regions as the index.\n",
    "    :param max_clusters: The maximum number of clusters to test for the elbow method.\n",
    "    :return: A tuple of pandas DataFrames with the first containing the coefficients and an additional\n",
    "             column 'Cluster', and the second containing the centroids of each cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the optimal number of clusters using the elbow method\n",
    "    sum_of_squared_distances = []\n",
    "    K = range(1, max_clusters + 1)\n",
    "    for k in K:\n",
    "        km = KMeans(n_clusters=k,  n_init=10, random_state=42)\n",
    "        km = km.fit(coefficients_df)\n",
    "        sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "    # Plot the elbow curve\n",
    "    plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Sum of squared distances')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()\n",
    "\n",
    "    # Ask user for the optimal number of clusters\n",
    "    n_clusters = int(input(\"Enter the optimal number of clusters: \"))\n",
    "    \n",
    "    # Use the KMeans algorithm to find clusters with the optimal number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    kmeans.fit(coefficients_df)\n",
    "\n",
    "    # Assign the clusters to each region\n",
    "    clusters = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # Calculate the distance of each region's coefficients to the centroid of its cluster\n",
    "    distances_to_centroid = cdist(coefficients_df, centroids, 'euclidean')\n",
    "    min_distances = distances_to_centroid.min(axis=1)\n",
    "\n",
    "    # Add the cluster labels and distances to the DataFrame\n",
    "    df = coefficients_df.copy()\n",
    "    df['Cluster'] = clusters\n",
    "    df['Distance_to_Centroid'] = (min_distances * 100).round(decimals=2)\n",
    "    df.index.name = 'Region'\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # Order the dataframe by cluster label and distance to centroid\n",
    "    clustered_df = df.sort_values(['Cluster', 'Distance_to_Centroid'])\n",
    "\n",
    "    # Get the centroids\n",
    "    centroids_df = pd.DataFrame(centroids, columns=coefficients_df.columns)\n",
    "    centroids_df['Cluster'] = range(n_clusters)\n",
    "\n",
    "    return clustered_df, centroids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc9390a-3f10-4f89-b5da-97baaf850f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster_regions(coefficients_df, max_clusters=40):\n",
    "    \"\"\"\n",
    "    This function finds the optimal number of clusters using the elbow method\n",
    "    and clusters regions based on their coefficients.\n",
    "\n",
    "    :param coefficients_df: A pandas DataFrame containing the coefficients with regions as the index.\n",
    "    :param max_clusters: The maximum number of clusters to test for the elbow method.\n",
    "    :return: A pandas DataFrame with an additional column 'Cluster' indicating the cluster for each region.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the optimal number of clusters using the elbow method\n",
    "    sum_of_squared_distances = []\n",
    "    K = range(1, max_clusters + 1)\n",
    "    for k in K:\n",
    "        km = KMeans(n_clusters=k,  n_init=10, random_state=42)\n",
    "        km = km.fit(coefficients_df)\n",
    "        sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "    # Plot the elbow curve\n",
    "    plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Sum of squared distances')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()\n",
    "\n",
    "    # Ask user for the optimal number of clusters\n",
    "    n_clusters = int(input(\"Enter the optimal number of clusters: \"))\n",
    "    \n",
    "    # Use the KMeans algorithm to find clusters with the optimal number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    kmeans.fit(coefficients_df)\n",
    "\n",
    "    # Assign the clusters to each region\n",
    "    clusters = kmeans.labels_\n",
    "\n",
    "    # Add the cluster labels to the DataFrame\n",
    "    df = coefficients_df.copy()\n",
    "    df['Cluster'] = clusters\n",
    "    df.index.name = 'Region'\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # Order the dataframe by cluster label\n",
    "    clustered_df = df.sort_values('Cluster')\n",
    "\n",
    "    return clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbe0b8-664c-48cf-bcab-6b7c784f39e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "def custom_distance(u, v):\n",
    "    # Custom distance metric:\n",
    "    # If any signs differ, the distance is increased\n",
    "    sign_diff = np.sign(u) != np.sign(v)\n",
    "    if sign_diff.any():  # If any signs differ, apply the penalty\n",
    "        return np.linalg.norm(u - v) * 1\n",
    "    else:\n",
    "        return np.linalg.norm(u - v)\n",
    "    \n",
    "def cluster_regions(coefficients_df, n_clusters=12):\n",
    "    # Create a new DataFrame for clustering to avoid modifying the original data\n",
    "    X = coefficients_df.copy()\n",
    "\n",
    "    # Compute the custom distance matrix\n",
    "    dist_matrix = distance_matrix(X.values, X.values, p=2)\n",
    "    for i in range(dist_matrix.shape[0]):\n",
    "        for j in range(dist_matrix.shape[1]):\n",
    "            if i != j:  # No need to penalize the diagonal\n",
    "                dist_matrix[i, j] = custom_distance(X.values[i], X.values[j])\n",
    "\n",
    "    # Perform Agglomerative Clustering with the precomputed distance matrix\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='complete')\n",
    "    clusters = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "    # Assign the clusters to each region\n",
    "    coefficients_df['Cluster'] = clusters\n",
    "    \n",
    "    # Order the dataframe by cluster label\n",
    "    clustered_df = coefficients_df.sort_values('Cluster')\n",
    "    clustered_df.index.name = 'Region'\n",
    "    clustered_df.reset_index(inplace=True)\n",
    "    \n",
    "    return clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1060349-0757-4abb-9b5f-c8450a86daec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clustered_df, centroids_df = cluster_regions(coefficients_df)\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b338d45-d31e-4f18-9a27-5e6bbdcee56b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Plot clusters on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac1398-83d2-405a-a467-9b8ba965f461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors = [(34/255, 139/255, 34/255), (1, 1, 1), (60/255, 145/255, 230/255)]  # Green -> White -> Blue\n",
    "n_bins = [3]  # Discretizes the interpolation into bins\n",
    "cmap_name = 'custom_div_cmap'\n",
    "\n",
    "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "\n",
    "# To test and display the colormap\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "ax.set_title('Custom Diverging Colormap')\n",
    "plt.imshow(np.linspace(0, 1, 256).reshape(1, -1), aspect='auto', cmap=cm)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6bb7a-ed6a-4c0f-9566-beb8f4af6cad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import regionmask\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956d530-fad6-429d-9af7-17147c713db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "def split_polygon(polygon, meridian=180):\n",
    "    \"\"\"\n",
    "    Splits a Shapely polygon into two polygons at a specified meridian\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    if maxx > meridian and minx < -meridian:\n",
    "        # Polygon crosses the antimeridian\n",
    "        left_poly = []\n",
    "        right_poly = []\n",
    "        for x, y in polygon.exterior.coords:\n",
    "            if x >= meridian:\n",
    "                right_poly.append((x - 360, y))  # Wraparound for the right side\n",
    "            else:\n",
    "                left_poly.append((x, y))\n",
    "        return [Polygon(left_poly), Polygon(right_poly)]\n",
    "    else:\n",
    "        return [polygon]  # Wrap the single polygon in a list for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da892dc0-63f5-4868-8d2f-c222339ab036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_clusters_and_regions(ds_ensmed_glob, ds, clustered_df):\n",
    "    # Initialize the plot with a cartopy projection\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax_main = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    \n",
    "    # Plot the 'bgws' variable from the dataset\n",
    "    ds_ensmed_glob['bgws'].plot(ax=ax_main, vmin=-0.2, vmax=0.2, cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False)\n",
    "    \n",
    "    # Add coastlines and gridlines\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 18}\n",
    "    gridlines.ylabel_style = {'size': 18}\n",
    "    \n",
    "    # Get region bounds using regionmask\n",
    "    land_regions = regionmask.defined_regions.ar6.land\n",
    "    \n",
    "    # Create a mapping from region names to region numbers\n",
    "    region_name_to_number = dict(zip(ds.names.values, ds.region.values))\n",
    "    \n",
    "    # Map the region names to the same order as ds.names.values\n",
    "    region_to_cluster_map = dict(zip(clustered_df['Region'], clustered_df['Cluster']))\n",
    "\n",
    "    # Now create a new column in ds that maps the region names to cluster numbers\n",
    "    # This assumes ds.names.values has the same region names as in clustered_df['Region']\n",
    "    ds['Cluster'] = [region_to_cluster_map[name] for name in ds.names.values]\n",
    "\n",
    "    # Convert the 'Cluster' DataArray to a NumPy array and get unique values\n",
    "    unique_clusters = np.unique(ds['Cluster'].values)\n",
    "\n",
    "    # Prepare colors for clusters - this assumes a finite number of clusters\n",
    "    cluster_colors = plt.cm.tab20b(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "\n",
    "    # Loop over the regions and plot the cluster numbers with abbreviations\n",
    "    for region_name, cluster_number in zip(ds.names.values, ds['Cluster']):\n",
    "        reg_num = region_name_to_number[region_name]\n",
    "        region_polygons = land_regions[reg_num].polygon\n",
    "        \n",
    "        region_abbr = ds.abbrevs.values[ds.region.values == reg_num][0]  # Assuming this gives us the correct abbreviation\n",
    "        cluster_color = cluster_colors[cluster_number]  # Get the color for the cluster\n",
    "        \n",
    "        # Fetch the polygon or polygons for this region\n",
    "        region_obj = land_regions[reg_num]\n",
    "        if hasattr(region_obj, 'polygons'):\n",
    "            # If the attribute is 'polygons', we assume it's iterable (e.g., a list of Polygon objects)\n",
    "            region_polygons = region_obj.polygons\n",
    "        elif hasattr(region_obj, 'polygon'):\n",
    "            # If there's only one Polygon, we wrap it in a list to make it iterable\n",
    "            region_polygons = [region_obj.polygon]\n",
    "        else:\n",
    "            raise AttributeError(f\"The region object does not have 'polygons' or 'polygon' attribute.\")\n",
    "\n",
    "        for region_polygon in region_polygons:\n",
    "            # If the polygon crosses the antimeridian, split it\n",
    "            split_polys = split_polygon(region_polygon)\n",
    "\n",
    "            # Handle both Polygon and MultiPolygon types after splitting\n",
    "            for poly in split_polys:\n",
    "                if isinstance(poly, Polygon):\n",
    "                    features_to_plot = [poly]\n",
    "                elif isinstance(poly, MultiPolygon):\n",
    "                    features_to_plot = list(poly.geoms)\n",
    "                else:\n",
    "                    raise TypeError(f\"Unhandled geometry type: {type(poly)}\")\n",
    "\n",
    "                for feature_poly in features_to_plot:\n",
    "                    feature = ShapelyFeature([feature_poly], ccrs.PlateCarree(), edgecolor=cluster_color, facecolor='none', linewidth=2)\n",
    "                    ax_main.add_feature(feature)\n",
    "\n",
    "            # Calculate the centroid for text placement using features_to_plot\n",
    "            centroids = [feature_poly.centroid for feature_poly in features_to_plot]\n",
    "    \n",
    "            text_lon, text_lat = max(centroids, key=lambda c: c.x).coords[0]  # Use the easternmost centroid\n",
    "        \n",
    "            # Ensure cluster_number is a plain integer if it's a single-item array or DataArray\n",
    "            if isinstance(cluster_number, np.ndarray) and cluster_number.size == 1:\n",
    "                cluster_number = cluster_number.item()  # Converts a one-element array to a scalar\n",
    "            elif isinstance(cluster_number, xr.DataArray) and cluster_number.ndim == 0:\n",
    "                cluster_number = cluster_number.values.item()  # Gets the scalar value from a 0-dim DataArray\n",
    "\n",
    "            # Annotate the cluster number for each region\n",
    "            ax_main.text(text_lon, text_lat, f\"{region_abbr}\\n{cluster_number}\",\n",
    "                         horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(),\n",
    "                         fontsize=20, bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71db8b-8bee-4dd8-bf6c-15673089129a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_clusters_and_regions(ds_ensmed_glob, ds, clustered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03c495-fab5-4094-8cf2-b66258c891eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a242050-5cba-4f75-b7f6-4f9e9fb1a321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_simple_map(ds_ensmed_glob, projection, save_fig=False):\n",
    "    fig = plt.figure(figsize=(30, 15))\n",
    "    ax_main = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "    \n",
    "    # Plot the 'bgws' variable from the dataset\n",
    "    img = ds_ensmed_glob['bgws'].plot(ax=ax_main, vmin=-0.6, vmax=0.6,  cmap=cm, transform=ccrs.PlateCarree(), add_colorbar=False) \n",
    "    \n",
    "    # Add coastlines and gridlines\n",
    "    ax_main.coastlines()\n",
    "    ax_main.tick_params(axis='both', which='major', labelsize=20)\n",
    "    gridlines = ax_main.gridlines(draw_labels=True, color='black', alpha=0.2, linestyle='--')\n",
    "    gridlines.top_labels = gridlines.right_labels = False\n",
    "    gridlines.xlabel_style = {'size': 18}\n",
    "    gridlines.ylabel_style = {'size': 18}\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar_ax = fig.add_axes([0.314, 0.1, 0.4, 0.025]) #left, bottom, width, height\n",
    "    cbar = fig.colorbar(img, cax=cbar_ax, extend='both', orientation='horizontal')\n",
    "    cbar.set_label(\"Blue-Green Water Share\", fontsize=22, weight='bold', labelpad=15) \n",
    "    cbar.ax.tick_params(labelsize=18)\n",
    "   \n",
    "    plt.show()\n",
    "    \n",
    "    # Safe figure\n",
    "    if save_fig:\n",
    "        savepath = os.path.join('../..', 'results', 'CMIP6', 'historical', 'time', 'median', 'bgws')\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        filename = f'Ensemble_median.1985-2014.bgws.historical.pdf'\n",
    "        filepath = os.path.join(savepath, filename)\n",
    "        fig.savefig(filepath, dpi=600, bbox_inches='tight', format='pdf')\n",
    "    else:\n",
    "        filepath = 'Figure not saved. If you want to save the figure add save_fig=True to the function call'\n",
    "        \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830683f-e43c-47f4-8feb-b877525d64e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_simple_map(ds_ensmed_glob, ccrs.Robinson(), save_fig=True) # Robinson PlateCarree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890934ec-5181-4729-b988-5b7ac0321d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_simple_map(ds_ensmed_glob, ccrs.PlateCarree(), save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449211a-b442-4503-a52b-98fc8ee19228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8086c-985e-4034-a804-b89739c06e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy3",
   "language": "python",
   "name": "mypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
